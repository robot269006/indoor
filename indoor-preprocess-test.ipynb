{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport json\nimport glob\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport plotly.graph_objs as go\n\nfrom PIL import Image, ImageOps\nfrom skimage import io\nfrom skimage.color import rgba2rgb, rgb2xyz\nfrom tqdm import tqdm\nfrom dataclasses import dataclass\nfrom math import floor, ceil\nimport random\n\n# Train data generation\nimport collections\nimport csv\nfrom pathlib import Path\nfrom typing import List, Tuple, Any\n\nimport time\nimport re\nfrom sklearn import preprocessing\nimport lightgbm as lgb\n\nimport multiprocessing\nfrom multiprocessing import Pool\n\npd.set_option(\"display.max_columns\", 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preprocess\n\n# Check out each file. Content, images\n\nroot_path = \"../input/indoor-location-navigation/\"\ntrain_paths = glob.glob(root_path + \"train\" + \"/*/*/*\")\ntest_paths = glob.glob(root_path + \"test\" + \"/*\")\nmetafiles = glob.glob(root_path + \"metadata\" + \"/*\")\n\nprint(\"No. Files in Train: {:,}\".format(len(train_paths)), \"\\n\" +\n      \"No. Files in Test: {:,}\".format(len(test_paths)), \"\\n\" +\n      \"No. of metadata files: {:,}\".format(len(metafiles)))\n\n# Reading in 1 file\ndef pick_example(max_range, paths):\n    ex = random.randint(0, max_range)\n    example_path = paths[ex]\n    path = f\"{example_path}\"\n    paths = path.split(\"/\")\n    site = paths[4]\n    floorNo = paths[5]\n    floor_plan_filename = f\"{root_path}metadata/{site}/{floorNo}/floor_image.png\"\n    json_plan_filename = f\"{root_path}metadata/{site}/{floorNo}/floor_info.json\"\n    with open(json_plan_filename) as json_file:\n        json_data = json.load(json_file)\n    width_meter = json_data[\"map_info\"][\"width\"]\n    height_meter = json_data[\"map_info\"][\"height\"]\n    return path, site, floorNo, floor_plan_filename, json_plan_filename, width_meter, height_meter\n\npath, site, floorNo, floor_plan_filename, \\\njson_plan_filename, width_meter, height_meter = pick_example(len(train_paths), train_paths)\nprint(\"example path: \", path)\nprint(\"site: \", site)\nprint(\"floorNo: \", floorNo)\nprint(\"floor_plan_filename: \", floor_plan_filename)\nprint(\"json_plan_filename: \", json_plan_filename)\nprint(\"width: {}, height: {} \".format(width_meter, height_meter))\n\nwith open(path) as p:\n    lines = p.readlines()\nprint(\"No. Lines in 1 example: {:,}\". format(len(lines)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get submission file\nsub_df = pd.read_csv(\"/kaggle/input/indoor-location-navigation/sample_submission.csv\")\nsub_df = sub_df[\"site_path_timestamp\"].apply(lambda x: pd.Series(x.split(\"_\")))\nsub_df.columns = [\"site\", \"file\", \"timestamp\"]\ndisplay(sub_df.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train number setting\n# train_num = len(train_paths) - 1\n# train_num = round(len(train_paths) / 2)\n# train_num = 3000\n\n# 200 train paths come out with ~1000 examples, so multiply train examples by 5 to extract similar no. of examples\n# test_num = train_num * 5\n# test_num = 300\ntest_num = len(sub_df) - 1\n# test_num = round(len(sub_df) / 2)\nprint(test_num)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for line in lines[:200]:\n#     print(line)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using github repo in kaggle kernels\n# https://www.kaggle.com/getting-started/71642\n!cp -r ../input/indoorlocationcompetition20master/indoor-location-competition-20-master/* ./","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import custom function from the repository\nfrom io_f import read_data_file\n\n# Read in 1 random example\npath, site, floorNo, floor_plan_filename, \\\njson_plan_filename, width_meter, height_meter = pick_example(len(train_paths), train_paths)\nsample_file = read_data_file(path)\n\n# You can access the information for each variable:\n# Each data is split for time\n# Metadata is expressed with \"#\"\n\n# for i in sample_file.acce[:, [0]]:\n#     print(i)\n#     print(int(i))\n\n# print(\"~~~ Example ~~~\")\n# print(\"acce: {}\".format(sample_file.acce), \"\\n\" +\n#       \"acce shape: {}\".format(sample_file.acce.shape), \"\\n\" +\n#       \"acacce_uncalice: {}\".format(sample_file.acce_uncali), \"\\n\" +\n#       \"acacce_uncalice shape: {}\".format(sample_file.acce_uncali.shape), \"\\n\" +\n#       \"ahrs: {}\".format(sample_file.ahrs), \"\\n\" +\n#       \"ahrs shape: {}\".format(sample_file.ahrs.shape), \"\\n\" +\n#       \"gyro: {}\".format(sample_file.gyro), \"\\n\" +\n#       \"gyro shape: {}\".format(sample_file.gyro.shape), \"\\n\" +\n#       \"gyro_uncali: {}\".format(sample_file.gyro_uncali), \"\\n\" +\n#       \"gyro_uncali shape: {}\".format(sample_file.gyro_uncali.shape), \"\\n\" +\n#       \"ibeacon: {}\".format(sample_file.ibeacon), \"\\n\" +\n#       \"ibeacon shape: {}\".format(sample_file.ibeacon.shape), \"\\n\" +\n#       \"magn: {}\".format(sample_file.magn), \"\\n\" +\n#       \"magn shape: {}\".format(sample_file.magn.shape), \"\\n\" +\n#       \"magn_uncali: {}\".format(sample_file.magn_uncali), \"\\n\" +\n#       \"magn_uncali shape: {}\".format(sample_file.magn_uncali.shape), \"\\n\" +\n#       \"waypoint: {}\".format(sample_file.waypoint), \"\\n\" +\n#       \"waypoint shape: {}\".format(sample_file.waypoint.shape), \"\\n\" +\n#       \"wifi: {}\".format(sample_file.wifi), \"\\n\" +\n#       \"wifi shape: {}\".format(sample_file.wifi.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_site_png(root_path, site):\n    floor_paths = glob.glob(root_path + \"metadata/\" + site + \"/*/floor_image.png\")\n    n = len(floor_paths)\n    print(\"No. of floor paths: \", n)\n\n    # Create the custom number of rows & columns\n    ncols = [ceil(n / 3) if n > 4 else 4][0]\n    nrows = [ceil(n / ncols) if n > 4 else 1][0]\n\n    plt.figure(figsize=(16, 10))\n    plt.suptitle(f\"Site no. '{site}'\", fontsize=18)\n\n    # Plot image for each floor\n    for k, floor in enumerate(floor_paths):\n        # plt.subplot(nrows, ncols, k+1)\n        plt.subplot(ncols, nrows, k+1)\n        plt.rcParams[\"figure.facecolor\"] = \"white\"\n\n        image = Image.open(floor)\n\n        plt.imshow(image)\n        plt.axis(\"off\")\n        title = floor.split(\"/\")[5]\n        plt.title(title, fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path, site, floorNo, floor_plan_filename, json_plan_filename, width_meter, height_meter = pick_example(len(train_paths), train_paths)\nshow_site_png(root_path, site=site)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the floor number distribution\n\nall_floors = glob.glob(\"../input/indoor-location-navigation/metadata/*/*\")\nall_sites = glob.glob(\"../input/indoor-location-navigation/metadata/*\")\nfloor_no = []\nfloor_counts = []\n\n# Floor count\nfor site in all_sites:\n    floor_count = len([name for name in os.listdir(site)])\n    floor_counts.append(floor_count)\n\nfloor_counts_df = pd.DataFrame(floor_counts, columns=[\"F_Count\"])\nfloor_counts_df = floor_counts_df[\"F_Count\"].value_counts().reset_index()\nfloor_counts_df = floor_counts_df.sort_values(\"index\", ascending=True)\n\n# Extract only the floor number\nfor floor in all_floors:\n    no = floor.split(\"/\")[5]\n    floor_no.append(no)\n    \nfloor_no = pd.DataFrame(floor_no, columns=[\"No\"])\nfloor_no = floor_no[\"No\"].value_counts().reset_index()\nfloor_no = floor_no.sort_values(\"No\", ascending=False)\n\n# ToDo: Floor expressions need to be fixed\n# 1F -> F1, L1 -> F1, G -> F1 etc\n\n# Plot\n# display(floor_counts_df.head(10))\n\nfig, axes = plt.subplots(ncols=2, figsize=(16, 10))\naxes[0] = sns.barplot(data=floor_counts_df, x=\"index\", y=\"F_Count\", palette=\"viridis\", saturation=0.4, ax=axes[0])\naxes[0].set_title(\"Floor Count Distribution\", size = 26, weight=\"bold\")\naxes[0].set_xlabel(\"\")\naxes[0].set_ylabel(\"Floor Count\", size = 18, weight=\"bold\")\n\naxes[1] = sns.barplot(data=floor_no, x=\"No\", y=\"index\", palette=\"viridis\", saturation=0.4, ax=axes[1])\naxes[1].set_title(\"Frequency of Floors\", size = 26, weight=\"bold\")\naxes[1].set_xlabel(\"\")\naxes[1].set_ylabel(\"Floor No.\", size = 18, weight=\"bold\")\n\nplt.xticks([])\nplt.yticks(fontsize=11)\nsns.despine(left=True, bottom=True);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Metadata checking (GeoJSON)\n# This is a vector representation of floor map\ngeojson_paths = glob.glob(\"../input/indoor-location-navigation/metadata/*/*/geojson_map.json\")\nprint(\"No. of geojson file: {}\".format(len(geojson_paths)))\n\n# Print one example\nex = random.randint(0, len(geojson_paths))\ngeojson_file_name = geojson_paths[ex]\nwith open(geojson_file_name) as json_file:\n    paths = geojson_file_name.split(\"/\")\n    site_id = paths[4]\n    floor = paths[5]\n    json_data = json.load(json_file)\n    json_properties = json_data[\"features\"][0][\"properties\"]\n    print(\"File path: {}\".format(geojson_file_name))\n    print(\"SiteID: {}\".format(site_id))\n    print(\"Floor: {}\".format(floor))\n    print(\"Floor info: {}\".format(json_properties))\n\n# create id and floor number matching file\nsite_ids = []\nfloor_no = []\nfloor_no_json = []\n\nfor i in range(0, len(geojson_paths)):\n    with open(geojson_paths[i]) as f:\n        paths = geojson_paths[i].split(\"/\")\n        site_id = paths[4]\n        floor = paths[5]\n        site_ids.append(site_id)\n        floor_no.append(floor)\n        d = json.load(f)\n        try:\n            floor_no_json.append(d[\"features\"][0][\"properties\"][\"floor_num\"])\n        except:\n            floor_no_json.append(np.nan)\n\nfloor_num_df = pd.DataFrame(\n    {\"site_id\": site_ids,\n     \"floor_no\": floor_no,\n     \"floor_no_json\": floor_no_json,\n    })\n\ndisplay(\"floor_num_df length: {}\".format(len(floor_num_df)))\ndisplay(floor_num_df.head())\n\n# Get floormap dict to be used later\nfloor_map_pairs = list(zip(floor_num_df[\"floor_no\"], floor_num_df[\"floor_no_json\"]))\nfloor_map_pairs = np.unique(floor_map_pairs, axis=0) # get unique pair\n# print(floor_map_pairs) # to be used as floor_map later\n\n# Plot distribution\nfloor_num_count_df = floor_num_df[\"floor_no_json\"].value_counts().reset_index()\nfloor_num_count_df = floor_num_count_df.sort_values(\"floor_no_json\", ascending=False)\n# display(floor_num_count_df)\n# print(len(floor_num_count_df[\"floor_no_json\"] == np.nan))\n\nfig = plt.figure()\nax = plt.subplots(figsize=(16, 10))\nsns.barplot(data=floor_num_count_df, x=\"index\", y=\"floor_no_json\", palette=\"viridis\", saturation=0.4)\nfig.show()\n\n# Just in case: Need for altitude info in geoJSON\n# from pyproj import Proj, transform\n# print(transform(Proj(init='epsg:4326'), Proj(init='epsg:3857'), -0.1285907, 51.50809))  # longitude first, latitude second.\n# output (meters east of 0, meters north of 0): (-14314.651244750548, 6711665.883938471)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# More viz on accelerometers, wifi etc in one go\nfrom visualize_f import visualize_trajectory, visualize_heatmap\nfrom main import extract_wifi_rssi, extract_wifi_count\nfrom main import calibrate_magnetic_wifi_ibeacon_to_position\nfrom main import extract_magnetic_strength\nfrom main import extract_ibeacon_rssi\n\n# Visualizing magnetic strength\npath, site, floorNo, floor_plan_filename, \\\njson_plan_filename, width_meter, height_meter = pick_example(len(train_paths), train_paths)\n\n# extract mag, wifi, beacon of one example\nmwi_datas = calibrate_magnetic_wifi_ibeacon_to_position([path])\nmagnetic_strength = extract_magnetic_strength(mwi_datas)\nwifi_rssi = extract_wifi_rssi(mwi_datas)\nwifi_counts = extract_wifi_count(mwi_datas)\nibeacon_rssi = extract_ibeacon_rssi(mwi_datas)\nibeacon_ummids = list(ibeacon_rssi.keys())\ntarget_ibeacon = ibeacon_ummids[0]\n\n# positions for heatmap\nheat_positions = np.array(list(magnetic_strength.keys()))\nheat_values = np.array(list(magnetic_strength.values()))\nheat_positions_wifi = np.array(list(wifi_counts.keys()))\nheat_values_wifi = np.array(list(wifi_counts.values()))\nheat_positions_bc = np.array(list(ibeacon_rssi[target_ibeacon].keys()))\nheat_values_bc = np.array(list(ibeacon_rssi[target_ibeacon].values()))[:, 0]\n\n# filter out positions that no wifi detected\nmask = heat_values_wifi != 0\nheat_positions_wifi = heat_positions_wifi[mask]\nheat_values_wifi = heat_values_wifi[mask]\n\n# get trajectory\nexample = read_data_file(path)\ntrajectory = example.waypoint # Returns timestamp, x, y values\nprint(f\"Waypoints: {trajectory}\")\ntrajectory = trajectory[:, 1:3] # Removes timestamp (we only need the coordinates)\n\n# Plot trajectory\nvisualize_trajectory(trajectory = trajectory,\n                     floor_plan_filename = floor_plan_filename,\n                     width_meter = width_meter,\n                     height_meter = height_meter,\n                     title = \"Example of Waypoint\",)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Try working out step_positions for 1 trace file\nfrom compute_f import compute_step_positions, compute_steps, \\\ncompute_headings, compute_stride_length, compute_step_heading, compute_rel_positions, split_ts_seq\n\npath_datas = read_data_file(path)\nacce_datas = path_datas.acce\nmagn_datas = path_datas.magn\nahrs_datas = path_datas.ahrs\nwifi_datas = path_datas.wifi\nibeacon_datas = path_datas.ibeacon\nposi_datas = path_datas.waypoint # not to be used\n\n# Feature candidate\n# You can't get the waypoint in test, so use acce and ahrs data to calculate relative positions\ndef calc_rel_positions(acce_datas, ahrs_datas):\n    step_timestamps, step_indexs, step_acce_max_mins = compute_steps(acce_datas)\n    headings = compute_headings(ahrs_datas)\n    stride_lengths = compute_stride_length(step_acce_max_mins)\n    step_headings = compute_step_heading(step_timestamps, headings)\n    rel_positions = compute_rel_positions(stride_lengths, step_headings)\n    # only use del if we don't need timestamps\n    # rel_positions_del = np.delete(rel_positions, 0, 1)\n    return rel_positions\n\nrel_positions = calc_rel_positions(acce_datas, ahrs_datas)\nprint(acce_datas[0])\nprint(rel_positions[0])\n\n# # For accelerometer and ahrs coordinates visualization\n# step_positions = compute_step_positions(acce_datas, ahrs_datas, posi_datas)\n# step_positions_del = np.delete(step_positions, 0, 1)\n# temp_values = np.ones((step_positions.shape[0]))\n\n# # Feature candidate\n# # Calculate relative position from magnetic strengths and wifi\n# def calc_mag_positions(magn_datas):\n#     sep_tss = np.unique(magn_datas[:, 0].astype(float))\n#     magn_datas_list = split_ts_seq(magn_datas, sep_tss)\n#     return magn_datas_list\n\n# mag_positions = calc_mag_positions(magn_datas)\n# print(magn_datas)\n# print(mag_positions)\n# print(len(mag_positions))\n\n# # Feature candidate\n# # Calculate relative position from wifi and beacon\n# def calc_wifi_positions():","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Methods for preprocessing train data\n\ndef find_diff_ts(ts, data):\n    data_ts = data[0]\n    diff_ts = int(data_ts) - int(ts)\n    return diff_ts\n\ndef find_start_ts(path):\n    with open(path, 'r', encoding='utf-8') as file:\n        lines = file.readlines()\n\n    for line_data in lines:\n        line_data = line_data.strip()\n        m = re.search(r\"(?<=startTime.)(.*)\", line_data)\n        start_ts = m.groups(0)\n        if m:\n            return (start_ts[0])\n\ndef find_smallest_diff(t, data):\n    data_ts = data[:, [0]]\n    diff = []\n    for ts in data_ts:\n        diff.append(abs(int(t) - int(ts)))\n    closest_index = np.argmin(diff) # if multiple records have the same value..?\n    return data[closest_index]\n\ndef split_axis(data):\n    data_ts = data[0]\n    x_axis = data[1]\n    y_axis = data[2]\n    z_axis = data[3]\n    try:\n        accuracy = data[4]\n    except IndexError:\n        accuracy = np.nan\n    return [data_ts, x_axis, y_axis, z_axis, accuracy]\n\ndef split_wifi(data):\n    data_ts = data[0]\n    ssid = data[1]\n    bssid = data[2]\n    rssi = data[3]\n    if len(data) > 5:\n        freq = data[4]\n        last_seen_ts = data[5]\n    else:\n        freq = np.nan\n        last_seen_ts = data[-1]\n    return [data_ts, ssid, bssid, rssi, freq, last_seen_ts]\n\ndef extract_path(path, floor_map):\n    # split path\n    try:\n        ex_path = f\"{path}\"\n        ex_paths = ex_path.split(\"/\")\n        site_id = ex_paths[4]\n        floor = ex_paths[5]\n        f = floor_map[floor]\n        file_id = ex_paths[6].split(\".\")[0]\n        return [site_id, file_id, f, floor]\n    except:\n        print(\"path extraction error\")\n\n# Definitely needs to be refactored\ndef extract_data(path):\n    # get data\n    try:\n        start_ts = find_start_ts(path)\n        path_datas = read_data_file(path)\n        acce = path_datas.acce\n        ahrs = path_datas.ahrs\n        magn = path_datas.magn\n        wifi = path_datas.wifi\n        wps = path_datas.waypoint\n        # ibeacon_datas = path_datas.ibeacon\n        # add uncalibrated data if needed\n\n        # If we need more data by generating fake x and y, change this part to the latter\n        ts = np.unique(wps[:, [0]])\n        # ts = np.unique(acce_datas[0])\n        # print(acce.shape, ahrs.shape, magn.shape, wifi.shape, wps, ts)\n\n        # extract data for each timestamp of waypoints\n        res = []\n        for i, t in enumerate(ts):\n            wp = wps[i]\n            x = wp[1]\n            y = wp[2]\n            diff_start_ts = int(t) - int(start_ts)\n            acce_closest = split_axis(find_smallest_diff(t, acce))\n            ahrs_closest = split_axis(find_smallest_diff(t, ahrs))\n            magn_closest = split_axis(find_smallest_diff(t, magn))\n            wifi_closest = split_wifi(find_smallest_diff(t, wifi))\n            diff_start_ts_all = []\n            for d in [acce_closest, ahrs_closest, magn_closest, wifi_closest]:\n                diff_ts = find_diff_ts(start_ts, d)\n                diff_start_ts_all.append(diff_ts)\n#             print(diff_start_ts_all)\n#             print(\"t:{}\".format(t))\n#             print(\"acce: \", acce_closest)\n#             print(\"ahrs: \", ahrs_closest)\n#             print(\"magn: \", magn_closest)\n#             print(\"wifi: \", wifi_closest)\n            res.append([t, x, y, start_ts, diff_start_ts] + acce_closest +\\\n                        ahrs_closest + magn_closest + wifi_closest + diff_start_ts_all)\n        return res\n    except:\n        print(\"data extraction error\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %%timeit\n\n# 5.55 ms ± 1.76 ms per loop\npath, site, floorNo, floor_plan_filename, \\\njson_plan_filename, width_meter, height_meter = pick_example(len(train_paths), train_paths)\n\n# for fixing floor expression\n# print(floor_map_pairs) # to be used as floor_map later\n# assign 1F to 1 rather than zero, just in case we want to use this as integer\nfloor_map = {\n    '1F': 1, '2F': 2, '3F': 3, '4F': 4, '5F': 5, '6F': 6, '7F': 7,\n    '8F': 8, '9F': 9, 'B': -1, 'B1': -1, 'B2': -2, 'B2': -3, 'B3': -3,\n    'BF': -1, 'BM': -1, 'F1': 1, 'F2': 2, 'F3': 3, 'F4': 4, 'F5': 5,\n    'F6': 6, 'F7': 7, 'F8': 8, 'F9': 9, 'F10': 10, 'G': -1, 'L1': 1, 'L2': 2,\n    'L3': 3, 'L3': 4, 'L4': 4, 'L4': 6, 'L5': 5, 'L6': 6, 'L7': 7, 'L8': 8,\n    'L9': 9, 'L10': 10, 'L11': 11, 'LG1': -1, 'LG2': -2,\n    'LM': np.nan, 'M': np.nan, 'P1': np.nan, 'P2': np.nan}\n\n# 433 ms ± 159 ms per loop\ndef one_trace_to_rows(path, floor_map):\n    try:\n        path_info = extract_path(path, floor_map)\n        data = extract_data(path)\n        # create rows\n        rows = []\n        for d in data:\n            row = path_info + d\n            rows.append(row)\n            # print(\"row: \", row)\n        return rows\n    except:\n        print(\"data generation error\")\n\nprint(\"path: \", path)\npath_info = extract_path(path, floor_map)\nrows = one_trace_to_rows(path, floor_map)\nprint(\"rows: \", rows)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Run row making function for all training paths\n# # print(train_paths[:10])\n# import time\n# start = time.time()\n\n# all_rows = []\n# for train_path in train_paths[:10]:\n#     rows = one_trace_to_rows(train_path, floor_map)\n#     all_rows.extend(rows)\n\n# one_trace_df = pd.DataFrame(all_rows)\n# display(len(one_trace_df))\n\n# # without Pool\n# # 10 -> 1.64 sec\n# # 100 -> 28.12 sec\n# # 1000 -> 286.67 sec\n# # to process training (~26,000 files) -> ~7500 sec (~2hours)\n# print(time.time() - start)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import multiprocessing\n# from multiprocessing import Pool\n\n# # with Pool\n# # no need for wrapper with pool.starmap -> https://qiita.com/okiyuki99/items/a54797cb44eb4ae571f6\n\n# num_cores = multiprocessing.cpu_count()\n# print(f\"num_cores={num_cores}\")\n# args = [(p, floor_map) for p in train_paths[:train_num]]\n# pool = Pool(num_cores)\n\n# # column names\n# # extract_path -> [site_id, file_id, f, floor]\n# # extract_data -> [t, x, y, start_ts, diff_start_ts] + acce_closest + ahrs_closest + magn_closest + wifi_closest\n# # axis: [x_axis, y_axis, z_axis, accuracy]\n# # wifi: [ssid, bssid, rssi, freq, last_seen_ts]\n# col_names = [\"site_id\", \"file_id\", \"floor_converted\", \"floor\", \\\n#              \"ts\", \"x\", \"y\", \"start_ts\", \"diff_start_ts\", \"acce_ts\", \\\n#              \"acce_x\", \"acce_y\", \"acce_z\", \"acce_acc\", \\\n#              \"ahrs_ts\", \"ahrs_x\", \"ahrs_y\", \"ahrs_z\", \"ahrs_acc\", \\\n#              \"magn_ts\", \"magn_x\", \"magn_y\", \"magn_z\", \"magn_acc\", \\\n#              \"wifi_ts\", \"wifi_ssid\", \"wifi_bssid\", \"wifi_rssi\", \"wifi_freq\", \"wifi_last_seen_ts\", \\\n#              \"diff_acce_ts_start_ts\", \"diff_ahrs_ts_start_ts\", \\\n#              \"diff_magn_ts_start_ts\", \"diff_wifi_ts_start_ts\"\n#             ]\n\n# # with Pool\n# # 10 -> 1.09 sec\n# # 100 -> 12.35 sec\n# # 1000 -> 113.87 sec\n# # to process training (~26,000 files) -> ~3000 sec (~50min)\n# start = time.time()\n# res = pool.starmap(one_trace_to_rows, args)\n# df_train = pd.DataFrame(res[0], columns=col_names)\n# for r in res[1:]:\n#     df = pd.DataFrame(r, columns=col_names)\n#     df_train = df_train.append(df)\n\n# print(\"train_path count\", len(train_paths[:train_num]))\n# print(\"time to process\", time.time() - start)\n# print(\"length of df made\", len(df_train))\n# display(df_train.head(10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # can read_data_file method read test data\n# print(test_paths[0])\n# test_path = test_paths[0]\n#read_data_file(test_path)\n# find_start_ts(test_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generate test data\n\ndef extract_test_data(df):\n    test_rows = []\n    for index, row in df.iterrows():\n        test_site = row[\"site\"]\n        file_name = row[\"file\"]\n        test_ts = row[\"timestamp\"]\n\n        test_path = root_path + \"test/\" + file_name + \".txt\" # get test_path from file name\n        start_ts = find_start_ts(test_path)\n        diff_start_ts = int(test_ts) - int(start_ts)\n        path_datas = read_data_file(test_path)\n        acce = path_datas.acce\n        ahrs = path_datas.ahrs\n        magn = path_datas.magn\n        wifi = path_datas.wifi\n        # ibeacon_datas = path_datas.ibeacon\n        # print(acce.shape, ahrs.shape, magn.shape, wifi.shape)\n\n        # extract data for each timestamp of waypoints\n        res = []\n        acce_closest = split_axis(find_smallest_diff(test_ts, acce))\n        ahrs_closest = split_axis(find_smallest_diff(test_ts, ahrs))\n        magn_closest = split_axis(find_smallest_diff(test_ts, magn))\n        wifi_closest = split_wifi(find_smallest_diff(test_ts, wifi))\n        # diff_wifi_last_ts = int(test_ts) - int(wifi_closest[5])\n        # diff_wifi_last_start_ts = int(wifi_closest[5]) - int(start_ts)\n        # print(\"t:{}\".format(t))\n        # print(\"acce: \", acce_closest)\n        # print(\"ahrs: \", ahrs_closest)\n        # print(\"magn: \", magn_closest)\n        # print(\"wifi: \", wifi_closest)\n        test_rows.append([test_site, file_name, np.nan, np.nan, test_ts, np.nan, np.nan, start_ts, diff_start_ts] + \\\n                          acce_closest + ahrs_closest + magn_closest + wifi_closest + \\\n                         [acce_closest[0], ahrs_closest[0], magn_closest[0], wifi_closest[0]])\n    return test_rows\n# extract_data -> [t, x, y, start_ts, diff_start_ts] + acce_closest + ahrs_closest + magn_closest + wifi_closest\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# try generating one test data\n# test_ex = sub_df.iloc[0, :]\n# test_site = test_ex[\"site\"]\n# file_name = test_ex[\"file\"]\n# test_ts = test_ex[\"timestamp\"]\n# test_one = extract_test_data(test_site, file_name, test_ts)\n# print(test_one)\n\n# test_rows = extract_test_data(sub_df.iloc[:10, :])\n# print(test_rows)\n# tes_df = pd.DataFrame(test_rows)\n# display(tes_df.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Pool for test data\n\ndef apply_pool_to_df(df, f, pool, num_cores):\n    result = pool.map(f, [d for d in np.array_split(df, num_cores)])\n    pool.close()\n    return result\n\nnum_cores = multiprocessing.cpu_count()\npool = Pool(num_cores)\n\nstart = time.time()\nres = apply_pool_to_df(sub_df.iloc[:test_num, :], extract_test_data, pool, num_cores)\n\ncol_names = [\"site_id\", \"file_id\", \"floor_converted\", \"floor\", \\\n             \"ts\", \"x\", \"y\", \"start_ts\", \"diff_start_ts\", \"acce_ts\", \\\n             \"acce_x\", \"acce_y\", \"acce_z\", \"acce_acc\", \\\n             \"ahrs_ts\", \"ahrs_x\", \"ahrs_y\", \"ahrs_z\", \"ahrs_acc\", \\\n             \"magn_ts\", \"magn_x\", \"magn_y\", \"magn_z\", \"magn_acc\", \\\n             \"wifi_ts\", \"wifi_ssid\", \"wifi_bssid\", \"wifi_rssi\", \"wifi_freq\", \"wifi_last_seen_ts\", \\\n             \"diff_acce_ts_start_ts\", \"diff_ahrs_ts_start_ts\", \\\n             \"diff_magn_ts_start_ts\", \"diff_wifi_ts_start_ts\"\n            ]\n\ndf_test = pd.DataFrame(res[0], columns=col_names)\nfor r in res[1:]:\n    df = pd.DataFrame(r, columns=col_names)\n    df_test = df_test.append(df)\n\n# process 1000 records -> 173.9 sec -> all test records are ~10,000 -> 1740 sec (~29min)\nprint(\"test_path count\", len(test_paths[:test_num]))\nprint(\"time to process\", time.time() - start)\nprint(\"length of df made\", len(df_test))\ndisplay(df_test.head(10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualizing timestamp distribution\n\n# Explore\n# print(df_train[\"ts\"].dtype)\n# print(df_test[\"ts\"].dtype)\n\n# LabelEncode site_id, file_id, floor_converted, ssid, bssid\ndef col_encode(df, cols):\n    for col in cols:\n        le = preprocessing.LabelEncoder()\n        df[\"%s_le\"%col] = le.fit_transform(df[col])\n\ncol_enc = [\"site_id\", \"file_id\", \"floor_converted\", \"wifi_ssid\", \"wifi_bssid\"]\n# col_encode(df_train, col_enc)\ncol_encode(df_test, col_enc)\n\n# convert data types of certain columns\ndef convert_dtypes(df, col_list, dtype):\n    for col in col_list:\n        df[col] = df[col].astype(dtype)\n\n# convert_dtypes(df_train, [\"ts\", \"start_ts\", \"diff_start_ts\", \"acce_ts\", \"ahrs_ts\", \"magn_ts\", \\\n#                           \"wifi_ts\", \"wifi_rssi\", \"wifi_freq\", \"wifi_last_seen_ts\", \\\n#                           \"diff_acce_ts_start_ts\", \"diff_ahrs_ts_start_ts\", \\\n#                           \"diff_magn_ts_start_ts\", \"diff_wifi_ts_start_ts\"], float)\n\nconvert_dtypes(df_test, [\"ts\", \"start_ts\", \"diff_start_ts\", \"acce_ts\", \"ahrs_ts\", \"magn_ts\", \\\n                          \"wifi_ts\", \"wifi_rssi\", \"wifi_freq\", \"wifi_last_seen_ts\", \\\n                          \"diff_acce_ts_start_ts\", \"diff_ahrs_ts_start_ts\", \\\n                          \"diff_magn_ts_start_ts\", \"diff_wifi_ts_start_ts\"], float)\n\n# convert ts and wifi_last_see_ts to dates\nfor df in [df_test]:\n    for col in [\"ts\", \"wifi_last_seen_ts\"]:\n        df[\"%s_date\"%col] = pd.to_datetime(df[col],unit=\"ms\")\n        df[\"%s_day\"%col] = df[\"%s_date\"%col].dt.floor(\"d\")\n        df[\"%s_hour\"%col] = df[\"%s_date\"%col].dt.floor(\"h\")\n        df[\"%s_minute\"%col] = df[\"%s_date\"%col].values.astype(\"<M8[m]\")\n\n# Check\n# display(df_train.head())\ndisplay(df_test.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save the file in parquet\n# https://www.kaggle.com/pedrocouto39/fast-reading-w-pickle-feather-parquet-jay\n# https://www.kaggle.com/prmohanty/python-how-to-save-and-load-ml-models\nimport pickle\n\n# Saving train data\n# train_file_name = \"indoor_train.pkl\"\ntest_file_name = \"indoor_test.pkl\"\n\n# with open(train_file_name, \"wb\") as file:\n#     pickle.dump(df_train, file)\n\nwith open(test_file_name, \"wb\") as file:\n    pickle.dump(df_test, file)\n\n# Save them to output\n# df_train.to_csv('df_train.csv',index=False)\ndf_test.to_csv('df_test.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}