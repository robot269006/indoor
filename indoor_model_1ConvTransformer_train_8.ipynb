{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "indoor_model_1ConvTransformer_train_8.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_deO9NH18_Kb"
      },
      "source": [
        "# Mounting GCS to colab\n",
        "# https://stackoverflow.com/questions/51715268/how-to-import-data-from-google-cloud-storage-to-google-colab\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_w17mjH-0gh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69aaf747-9c04-4800-8852-c58abf73c96e"
      },
      "source": [
        "!echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n",
        "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n",
        "!apt -qq update\n",
        "!apt -qq install gcsfuse"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  2537  100  2537    0     0   103k      0 --:--:-- --:--:-- --:--:--  103k\n",
            "OK\n",
            "79 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "gcsfuse is already the newest version (0.34.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 79 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoG6QV8P_FC3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c448278-f71c-40a3-c423-e21ab1a40525"
      },
      "source": [
        "!mkdir colab_indoor\n",
        "!gcsfuse indoor-data colab_indoor\n",
        "# !mkdir colab_indoor/train_4\n",
        "# !gcsfuse indoor-data/train_4 colab_indoor/train_4\n",
        "# !mkdir colab_indoor/test_4\n",
        "# !gcsfuse indoor-data/test_4 colab_indoor/test_4"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021/04/22 03:53:55.906575 Using mount point: /content/colab_indoor\n",
            "2021/04/22 03:53:55.916061 Opening GCS connection...\n",
            "2021/04/22 03:53:56.179461 Mounting file system \"indoor-data\"...\n",
            "2021/04/22 03:53:56.198688 File system has been successfully mounted.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LLEkzgi_hq9",
        "outputId": "a51f7e8d-299b-4fef-b819-f15c54d9262d"
      },
      "source": [
        "!ls -la -h ./colab_indoor/train_4_colcut"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 1.2G\n",
            "-rw-r--r-- 1 root root  43M Apr 14 21:07 5a0546857ecc773753327266_train.csv\n",
            "-rw-r--r-- 1 root root  46M Apr 14 21:07 5c3c44b80379370013e0fd2b_train.csv\n",
            "-rw-r--r-- 1 root root 113M Apr 14 21:08 5d27075f03f801723c2e360f_train.csv\n",
            "-rw-r--r-- 1 root root  43M Apr 14 21:08 5d27096c03f801723c31e5e0_train.csv\n",
            "-rw-r--r-- 1 root root  50M Apr 14 21:08 5d27097f03f801723c320d97_train.csv\n",
            "-rw-r--r-- 1 root root  12M Apr 14 21:08 5d27099f03f801723c32511d_train.csv\n",
            "-rw-r--r-- 1 root root  17M Apr 14 21:08 5d2709a003f801723c3251bf_train.csv\n",
            "-rw-r--r-- 1 root root  72M Apr 14 21:09 5d2709b303f801723c327472_train.csv\n",
            "-rw-r--r-- 1 root root  81M Apr 14 21:09 5d2709bb03f801723c32852c_train.csv\n",
            "-rw-r--r-- 1 root root  48M Apr 14 21:09 5d2709c303f801723c3299ee_train.csv\n",
            "-rw-r--r-- 1 root root  48M Apr 14 21:09 5d2709d403f801723c32bd39_train.csv\n",
            "-rw-r--r-- 1 root root  51M Apr 14 21:09 5d2709e003f801723c32d896_train.csv\n",
            "-rw-r--r-- 1 root root 3.9M Apr 14 21:10 5da138274db8ce0c98bbd3d2_train.csv\n",
            "-rw-r--r-- 1 root root  41M Apr 14 21:10 5da1382d4db8ce0c98bbe92e_train.csv\n",
            "-rw-r--r-- 1 root root  38M Apr 14 21:10 5da138314db8ce0c98bbf3a0_train.csv\n",
            "-rw-r--r-- 1 root root 6.7M Apr 14 21:10 5da138364db8ce0c98bc00f1_train.csv\n",
            "-rw-r--r-- 1 root root  63M Apr 14 21:10 5da1383b4db8ce0c98bc11ab_train.csv\n",
            "-rw-r--r-- 1 root root  35M Apr 14 21:10 5da138754db8ce0c98bca82f_train.csv\n",
            "-rw-r--r-- 1 root root  45M Apr 14 21:10 5da138764db8ce0c98bcaa46_train.csv\n",
            "-rw-r--r-- 1 root root  13M Apr 14 21:11 5da1389e4db8ce0c98bd0547_train.csv\n",
            "-rw-r--r-- 1 root root  82M Apr 14 21:11 5da138b74db8ce0c98bd4774_train.csv\n",
            "-rw-r--r-- 1 root root  71M Apr 14 21:11 5da958dd46f8266d0737457b_train.csv\n",
            "-rw-r--r-- 1 root root  76M Apr 14 21:11 5dbc1d84c1eb61796cf7c010_train.csv\n",
            "-rw-r--r-- 1 root root  75M Apr 14 21:12 5dc8cea7659e181adb076a3f_train.csv\n",
            "drwxr-xr-x 1 root root    0 Apr 22 03:53 .ipynb_checkpoints\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zxo_gtclkLZo",
        "outputId": "8998a987-4cee-4426-eebc-c3b84c858a3c"
      },
      "source": [
        "import random\n",
        "from random import sample\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.ndimage.filters import uniform_filter1d\n",
        "from scipy.interpolate import interp1d\n",
        "import time\n",
        "from collections import defaultdict\n",
        "import seaborn as sns\n",
        "\n",
        "import scipy.stats as stats\n",
        "from pathlib import Path\n",
        "import glob\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import os\n",
        "import copy\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import multiprocessing\n",
        "import math\n",
        "\n",
        "EPOCH = 200 # default at 50\n",
        "BATCH_SIZE = 32\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "FOLDS = 5\n",
        "\n",
        "NUM_CORES = multiprocessing.cpu_count()\n",
        "print(NUM_CORES)\n",
        "\n",
        "OUTPUT_NAME = \"train_8_colcut_DLSTM\"\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "set_seed()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImcyWYeuWJEP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "8c4a8624-54df-4577-c4ca-35d6cab81047"
      },
      "source": [
        "# train paths and test paths\n",
        "train_files = sorted(glob.glob(\"./colab_indoor/train_4_colcut/*\"))\n",
        "test_files = sorted(glob.glob(\"./colab_indoor/test_4_colcut/*\"))\n",
        "\n",
        "# load submission file\n",
        "sub_df = pd.read_csv(\"./colab_indoor/sample_submission.csv\", index_col=0)\n",
        "# sub_df[[\"site\", \"file\", \"timestamp\"]] = sub_df[\"site_path_timestamp\"].apply(lambda x: pd.Series(x.split(\"_\")))\n",
        "display(sub_df.head())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>floor</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>site_path_timestamp</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5a0546857ecc773753327266_046cfa46be49fc10834815c6_0000000000009</th>\n",
              "      <td>0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>75.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5a0546857ecc773753327266_046cfa46be49fc10834815c6_0000000009017</th>\n",
              "      <td>0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>75.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5a0546857ecc773753327266_046cfa46be49fc10834815c6_0000000015326</th>\n",
              "      <td>0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>75.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5a0546857ecc773753327266_046cfa46be49fc10834815c6_0000000018763</th>\n",
              "      <td>0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>75.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5a0546857ecc773753327266_046cfa46be49fc10834815c6_0000000022328</th>\n",
              "      <td>0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>75.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    floor     x     y\n",
              "site_path_timestamp                                                  \n",
              "5a0546857ecc773753327266_046cfa46be49fc10834815...      0  75.0  75.0\n",
              "5a0546857ecc773753327266_046cfa46be49fc10834815...      0  75.0  75.0\n",
              "5a0546857ecc773753327266_046cfa46be49fc10834815...      0  75.0  75.0\n",
              "5a0546857ecc773753327266_046cfa46be49fc10834815...      0  75.0  75.0\n",
              "5a0546857ecc773753327266_046cfa46be49fc10834815...      0  75.0  75.0"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "B2jyhARLkpkk",
        "outputId": "5966ec31-3bc2-41bc-b0e2-32b71787af50"
      },
      "source": [
        "# Load train csv and test csv\n",
        "train_df = pd.read_csv(train_files[10])\n",
        "test_df = pd.read_csv(test_files[10])\n",
        "display(train_df.head())\n",
        "display(test_df.head())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wifi_ts</th>\n",
              "      <th>wps_diff</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>floor</th>\n",
              "      <th>floor_int</th>\n",
              "      <th>file_id</th>\n",
              "      <th>site_id</th>\n",
              "      <th>b1847b7279f12430b70cf177ae9419b2c6563c7e</th>\n",
              "      <th>e78f6a70bb684764884bf5bfc22876354dc4978f</th>\n",
              "      <th>7f92c838def910dc333d6ec1785cc9de7c428514</th>\n",
              "      <th>49baf7f0e5495ee2926baa0e941d265d725dbdd5</th>\n",
              "      <th>9419ecb5700d351a0ca4c6f6dc4f7804c5800ebe</th>\n",
              "      <th>6c598641414c17dfca87a3acc982507ba08902cb</th>\n",
              "      <th>bf8984bf3344f3267b1fb3cb5dc95ddf7e2117d3</th>\n",
              "      <th>24a2a9c3edd47eb479f05d4067368c9e14b8964b</th>\n",
              "      <th>2b3f7594cc8ab2b0413d45d6eea1149a9a7809a7</th>\n",
              "      <th>1cecf9fc6a1ceba0ad7063fdb5816ec43e90e94f</th>\n",
              "      <th>018a066872b67d5b33570ddeb6142c602a22e451</th>\n",
              "      <th>55ee0fec7b7be3e76132b20fca01e8486743a3f6</th>\n",
              "      <th>4f32282342971b17eb8611ac5f145d0b8768f62d</th>\n",
              "      <th>ee2a7ce46e83e2de489c9f78f4e550156d57f484</th>\n",
              "      <th>606fc3f5664630412548bbd099f9c8ad1dc5acb6</th>\n",
              "      <th>40ab9973a268cc79a4a8210e67f9b912723ed8c3</th>\n",
              "      <th>c81b745f26735105787cf9e7b547a7c37a65a851</th>\n",
              "      <th>832743c77af1c7eb12fcd909c438dcf39b6008f3</th>\n",
              "      <th>7b42d018fdfe2ab118d8ec85bcf1d6983750750c</th>\n",
              "      <th>ef99ef623422c284a774e35fc1b1cf3e721dbd03</th>\n",
              "      <th>c1591135c00bca7a723a49df8c9d8de34326fbd3</th>\n",
              "      <th>3956907df9b51fae849a7afced246f127f259504</th>\n",
              "      <th>1359034ef247ed40bf5b3723915b9fc60cc74837</th>\n",
              "      <th>2a5b0895595bcf131a0b5c3e5dc4b9f39e06bd3f</th>\n",
              "      <th>ca7a7877b1dbad8f6ef696b1e88f34dc6f635b0d</th>\n",
              "      <th>396640532a81255d6b75b41e7a184c1393b74ee4</th>\n",
              "      <th>aebc6ae6f9dfe7b548779e39cc9fd03c60a67ecc</th>\n",
              "      <th>70e578e027d0ab0bfeb5959e18f3c8045a32236d</th>\n",
              "      <th>07ccdba1f0a266adf501c867319ac7007e65d290</th>\n",
              "      <th>d7b2ba98b972b65650af520075c9712a3d8994a7</th>\n",
              "      <th>2b844704051b64e47b4800e1d6e932bbdd5356b6</th>\n",
              "      <th>1c390c87d362e628cebc103eb247d2b7aa813542</th>\n",
              "      <th>...</th>\n",
              "      <th>46e35eba345a6366234c028567bbb91c99b872e5</th>\n",
              "      <th>298e1870fda64fe8018ec79e835cf308f81181fa</th>\n",
              "      <th>31b0561e7e9a03156b248da215d7ab7bf8d6d8c8</th>\n",
              "      <th>3ab6773bc6bce7fb154b3d46f6058f0192bfd01b</th>\n",
              "      <th>41d0c04a20a77e8daaba6c585f083ca0ef57affc</th>\n",
              "      <th>a3dfc65c01d171a671cd615236b79c61810de354</th>\n",
              "      <th>06028150b43acb7e11121888ab434cdd5f679f1d</th>\n",
              "      <th>f7853f850bbb98d20bb2b4dd6380c071b5a1cb02</th>\n",
              "      <th>078a75dfda9e932f608fca0837610b97d11d3dd7</th>\n",
              "      <th>fc8fd87104388e513937ac13696b6f72af2add53</th>\n",
              "      <th>422765063ea5b0e5667a240e3b802041ab93b6e3</th>\n",
              "      <th>6cfaf9601b6e2587a321d3b803c20f9eb05fd452</th>\n",
              "      <th>35c0ef8cb2af11a81092979d55c4324b8101332f</th>\n",
              "      <th>764cbb8b20a46c411fe5807df9867b92c0935c08</th>\n",
              "      <th>78209eb1032640dd8f611e310c8619ab2c9cb071</th>\n",
              "      <th>1fc19e52666a95169b365f5ad1352d9369cb045a</th>\n",
              "      <th>14d3489b6de7d970babc8a951bf6ed5bd289dea0</th>\n",
              "      <th>6646a9365ace5164d2ef3dfb39b88a8a924568d3</th>\n",
              "      <th>a7ac17ed71cc594bed820bfbbca833f3f9972592</th>\n",
              "      <th>976e778d614b1e8e9efa8bc7eeaf552b7fe5ccb5</th>\n",
              "      <th>5749b4541786aea857ff1552dfac8cf292044c29</th>\n",
              "      <th>b1f4814d1a8c7885960118015e2c8f47fcdd0f4f</th>\n",
              "      <th>75df7c8888ddbf148407aa76c3d6b72406bc4c27</th>\n",
              "      <th>fc88f6a4f0351f8a2b34d256fcda35579d9e0ead</th>\n",
              "      <th>21f079033442b71f1a870ca0988fa9afcc7dc810</th>\n",
              "      <th>3f8321ce0dd6348fa440eb25acae2be996c3b2e7</th>\n",
              "      <th>9054af7ed2ceb6b130b4fd2a09f36b9b1f611f11</th>\n",
              "      <th>77de2f0f3005949e35e2e2aef7af1ddc5d164695</th>\n",
              "      <th>588f35babb83fab68a9c539567140ba5c17284c7</th>\n",
              "      <th>68962923d8621f6868a762b2344ce1ab8209ecdd</th>\n",
              "      <th>7abbb83f5b877ce5c1c9e835422365cd8bac3b0d</th>\n",
              "      <th>acb4abc93968ad51368a0351fa7fda5401598069</th>\n",
              "      <th>f20fed9f248d4352def744d9a8262b49042ee7f3</th>\n",
              "      <th>437d45cd7c45b040b95abdb483b02d601c761d7d</th>\n",
              "      <th>b083b8279418c48d60a05cff039b0536339a1e4d</th>\n",
              "      <th>fa0d8c168b62f11f34fdf314d81cebdf1ca9ebd0</th>\n",
              "      <th>955eb46cfdee70adab1de9ce909f0cb059fd29d2</th>\n",
              "      <th>48d751207622a3606df95184fd58b32347057af3</th>\n",
              "      <th>5238e869a2d0d2a851ba1f9484c874c57419148e</th>\n",
              "      <th>63781517942f8b63c2189c376cc0cf3db1d27ed1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1573789444679</td>\n",
              "      <td>1918</td>\n",
              "      <td>88.03561</td>\n",
              "      <td>109.90122</td>\n",
              "      <td>B1</td>\n",
              "      <td>-1</td>\n",
              "      <td>5dce2cf294e4900006124d2a</td>\n",
              "      <td>5d2709d403f801723c32bd39</td>\n",
              "      <td>-76</td>\n",
              "      <td>-74</td>\n",
              "      <td>-76</td>\n",
              "      <td>-999</td>\n",
              "      <td>-73</td>\n",
              "      <td>-89</td>\n",
              "      <td>-77</td>\n",
              "      <td>-999</td>\n",
              "      <td>-49</td>\n",
              "      <td>-999</td>\n",
              "      <td>-73</td>\n",
              "      <td>-87</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-46</td>\n",
              "      <td>-66</td>\n",
              "      <td>-75</td>\n",
              "      <td>-84</td>\n",
              "      <td>-999</td>\n",
              "      <td>-76</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-84</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-80</td>\n",
              "      <td>...</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1573789446609</td>\n",
              "      <td>3848</td>\n",
              "      <td>88.03561</td>\n",
              "      <td>109.90122</td>\n",
              "      <td>B1</td>\n",
              "      <td>-1</td>\n",
              "      <td>5dce2cf294e4900006124d2a</td>\n",
              "      <td>5d2709d403f801723c32bd39</td>\n",
              "      <td>-79</td>\n",
              "      <td>-79</td>\n",
              "      <td>-83</td>\n",
              "      <td>-999</td>\n",
              "      <td>-73</td>\n",
              "      <td>-89</td>\n",
              "      <td>-77</td>\n",
              "      <td>-999</td>\n",
              "      <td>-44</td>\n",
              "      <td>-88</td>\n",
              "      <td>-78</td>\n",
              "      <td>-87</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-59</td>\n",
              "      <td>-66</td>\n",
              "      <td>-75</td>\n",
              "      <td>-89</td>\n",
              "      <td>-999</td>\n",
              "      <td>-76</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-84</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-80</td>\n",
              "      <td>...</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1573789448539</td>\n",
              "      <td>5298</td>\n",
              "      <td>91.62208</td>\n",
              "      <td>108.70687</td>\n",
              "      <td>B1</td>\n",
              "      <td>-1</td>\n",
              "      <td>5dce2cf294e4900006124d2a</td>\n",
              "      <td>5d2709d403f801723c32bd39</td>\n",
              "      <td>-68</td>\n",
              "      <td>-67</td>\n",
              "      <td>-67</td>\n",
              "      <td>-78</td>\n",
              "      <td>-73</td>\n",
              "      <td>-89</td>\n",
              "      <td>-78</td>\n",
              "      <td>-85</td>\n",
              "      <td>-46</td>\n",
              "      <td>-88</td>\n",
              "      <td>-78</td>\n",
              "      <td>-87</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-48</td>\n",
              "      <td>-66</td>\n",
              "      <td>-75</td>\n",
              "      <td>-89</td>\n",
              "      <td>-999</td>\n",
              "      <td>-76</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-84</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-80</td>\n",
              "      <td>...</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1573789450452</td>\n",
              "      <td>3385</td>\n",
              "      <td>91.62208</td>\n",
              "      <td>108.70687</td>\n",
              "      <td>B1</td>\n",
              "      <td>-1</td>\n",
              "      <td>5dce2cf294e4900006124d2a</td>\n",
              "      <td>5d2709d403f801723c32bd39</td>\n",
              "      <td>-73</td>\n",
              "      <td>-73</td>\n",
              "      <td>-77</td>\n",
              "      <td>-78</td>\n",
              "      <td>-73</td>\n",
              "      <td>-89</td>\n",
              "      <td>-74</td>\n",
              "      <td>-91</td>\n",
              "      <td>-55</td>\n",
              "      <td>-84</td>\n",
              "      <td>-77</td>\n",
              "      <td>-87</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-42</td>\n",
              "      <td>-66</td>\n",
              "      <td>-75</td>\n",
              "      <td>-89</td>\n",
              "      <td>-999</td>\n",
              "      <td>-76</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-84</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-83</td>\n",
              "      <td>...</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1573789452370</td>\n",
              "      <td>1467</td>\n",
              "      <td>91.62208</td>\n",
              "      <td>108.70687</td>\n",
              "      <td>B1</td>\n",
              "      <td>-1</td>\n",
              "      <td>5dce2cf294e4900006124d2a</td>\n",
              "      <td>5d2709d403f801723c32bd39</td>\n",
              "      <td>-72</td>\n",
              "      <td>-71</td>\n",
              "      <td>-70</td>\n",
              "      <td>-78</td>\n",
              "      <td>-73</td>\n",
              "      <td>-76</td>\n",
              "      <td>-81</td>\n",
              "      <td>-91</td>\n",
              "      <td>-48</td>\n",
              "      <td>-84</td>\n",
              "      <td>-77</td>\n",
              "      <td>-78</td>\n",
              "      <td>-76</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-47</td>\n",
              "      <td>-66</td>\n",
              "      <td>-75</td>\n",
              "      <td>-89</td>\n",
              "      <td>-999</td>\n",
              "      <td>-77</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-86</td>\n",
              "      <td>-84</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-89</td>\n",
              "      <td>...</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 999 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         wifi_ts  ...  63781517942f8b63c2189c376cc0cf3db1d27ed1\n",
              "0  1573789444679  ...                                      -999\n",
              "1  1573789446609  ...                                      -999\n",
              "2  1573789448539  ...                                      -999\n",
              "3  1573789450452  ...                                      -999\n",
              "4  1573789452370  ...                                      -999\n",
              "\n",
              "[5 rows x 999 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>site_path_timestamp</th>\n",
              "      <th>correct_wps_ts</th>\n",
              "      <th>wifi_ts</th>\n",
              "      <th>wps_diff</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>floor</th>\n",
              "      <th>floor_int</th>\n",
              "      <th>file_id</th>\n",
              "      <th>site_id</th>\n",
              "      <th>b1847b7279f12430b70cf177ae9419b2c6563c7e</th>\n",
              "      <th>e78f6a70bb684764884bf5bfc22876354dc4978f</th>\n",
              "      <th>7f92c838def910dc333d6ec1785cc9de7c428514</th>\n",
              "      <th>49baf7f0e5495ee2926baa0e941d265d725dbdd5</th>\n",
              "      <th>9419ecb5700d351a0ca4c6f6dc4f7804c5800ebe</th>\n",
              "      <th>6c598641414c17dfca87a3acc982507ba08902cb</th>\n",
              "      <th>bf8984bf3344f3267b1fb3cb5dc95ddf7e2117d3</th>\n",
              "      <th>24a2a9c3edd47eb479f05d4067368c9e14b8964b</th>\n",
              "      <th>2b3f7594cc8ab2b0413d45d6eea1149a9a7809a7</th>\n",
              "      <th>1cecf9fc6a1ceba0ad7063fdb5816ec43e90e94f</th>\n",
              "      <th>018a066872b67d5b33570ddeb6142c602a22e451</th>\n",
              "      <th>55ee0fec7b7be3e76132b20fca01e8486743a3f6</th>\n",
              "      <th>4f32282342971b17eb8611ac5f145d0b8768f62d</th>\n",
              "      <th>ee2a7ce46e83e2de489c9f78f4e550156d57f484</th>\n",
              "      <th>606fc3f5664630412548bbd099f9c8ad1dc5acb6</th>\n",
              "      <th>40ab9973a268cc79a4a8210e67f9b912723ed8c3</th>\n",
              "      <th>c81b745f26735105787cf9e7b547a7c37a65a851</th>\n",
              "      <th>832743c77af1c7eb12fcd909c438dcf39b6008f3</th>\n",
              "      <th>7b42d018fdfe2ab118d8ec85bcf1d6983750750c</th>\n",
              "      <th>ef99ef623422c284a774e35fc1b1cf3e721dbd03</th>\n",
              "      <th>c1591135c00bca7a723a49df8c9d8de34326fbd3</th>\n",
              "      <th>3956907df9b51fae849a7afced246f127f259504</th>\n",
              "      <th>1359034ef247ed40bf5b3723915b9fc60cc74837</th>\n",
              "      <th>2a5b0895595bcf131a0b5c3e5dc4b9f39e06bd3f</th>\n",
              "      <th>ca7a7877b1dbad8f6ef696b1e88f34dc6f635b0d</th>\n",
              "      <th>396640532a81255d6b75b41e7a184c1393b74ee4</th>\n",
              "      <th>aebc6ae6f9dfe7b548779e39cc9fd03c60a67ecc</th>\n",
              "      <th>70e578e027d0ab0bfeb5959e18f3c8045a32236d</th>\n",
              "      <th>07ccdba1f0a266adf501c867319ac7007e65d290</th>\n",
              "      <th>d7b2ba98b972b65650af520075c9712a3d8994a7</th>\n",
              "      <th>...</th>\n",
              "      <th>46e35eba345a6366234c028567bbb91c99b872e5</th>\n",
              "      <th>298e1870fda64fe8018ec79e835cf308f81181fa</th>\n",
              "      <th>31b0561e7e9a03156b248da215d7ab7bf8d6d8c8</th>\n",
              "      <th>3ab6773bc6bce7fb154b3d46f6058f0192bfd01b</th>\n",
              "      <th>41d0c04a20a77e8daaba6c585f083ca0ef57affc</th>\n",
              "      <th>a3dfc65c01d171a671cd615236b79c61810de354</th>\n",
              "      <th>06028150b43acb7e11121888ab434cdd5f679f1d</th>\n",
              "      <th>f7853f850bbb98d20bb2b4dd6380c071b5a1cb02</th>\n",
              "      <th>078a75dfda9e932f608fca0837610b97d11d3dd7</th>\n",
              "      <th>fc8fd87104388e513937ac13696b6f72af2add53</th>\n",
              "      <th>422765063ea5b0e5667a240e3b802041ab93b6e3</th>\n",
              "      <th>6cfaf9601b6e2587a321d3b803c20f9eb05fd452</th>\n",
              "      <th>35c0ef8cb2af11a81092979d55c4324b8101332f</th>\n",
              "      <th>764cbb8b20a46c411fe5807df9867b92c0935c08</th>\n",
              "      <th>78209eb1032640dd8f611e310c8619ab2c9cb071</th>\n",
              "      <th>1fc19e52666a95169b365f5ad1352d9369cb045a</th>\n",
              "      <th>14d3489b6de7d970babc8a951bf6ed5bd289dea0</th>\n",
              "      <th>6646a9365ace5164d2ef3dfb39b88a8a924568d3</th>\n",
              "      <th>a7ac17ed71cc594bed820bfbbca833f3f9972592</th>\n",
              "      <th>976e778d614b1e8e9efa8bc7eeaf552b7fe5ccb5</th>\n",
              "      <th>5749b4541786aea857ff1552dfac8cf292044c29</th>\n",
              "      <th>b1f4814d1a8c7885960118015e2c8f47fcdd0f4f</th>\n",
              "      <th>75df7c8888ddbf148407aa76c3d6b72406bc4c27</th>\n",
              "      <th>fc88f6a4f0351f8a2b34d256fcda35579d9e0ead</th>\n",
              "      <th>21f079033442b71f1a870ca0988fa9afcc7dc810</th>\n",
              "      <th>3f8321ce0dd6348fa440eb25acae2be996c3b2e7</th>\n",
              "      <th>9054af7ed2ceb6b130b4fd2a09f36b9b1f611f11</th>\n",
              "      <th>77de2f0f3005949e35e2e2aef7af1ddc5d164695</th>\n",
              "      <th>588f35babb83fab68a9c539567140ba5c17284c7</th>\n",
              "      <th>68962923d8621f6868a762b2344ce1ab8209ecdd</th>\n",
              "      <th>7abbb83f5b877ce5c1c9e835422365cd8bac3b0d</th>\n",
              "      <th>acb4abc93968ad51368a0351fa7fda5401598069</th>\n",
              "      <th>f20fed9f248d4352def744d9a8262b49042ee7f3</th>\n",
              "      <th>437d45cd7c45b040b95abdb483b02d601c761d7d</th>\n",
              "      <th>b083b8279418c48d60a05cff039b0536339a1e4d</th>\n",
              "      <th>fa0d8c168b62f11f34fdf314d81cebdf1ca9ebd0</th>\n",
              "      <th>955eb46cfdee70adab1de9ce909f0cb059fd29d2</th>\n",
              "      <th>48d751207622a3606df95184fd58b32347057af3</th>\n",
              "      <th>5238e869a2d0d2a851ba1f9484c874c57419148e</th>\n",
              "      <th>63781517942f8b63c2189c376cc0cf3db1d27ed1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5d2709d403f801723c32bd39_06882da3694b7160c0f10...</td>\n",
              "      <td>1.573706e+12</td>\n",
              "      <td>1573705854189</td>\n",
              "      <td>5859</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>06882da3694b7160c0f105f5</td>\n",
              "      <td>5d2709d403f801723c32bd39</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-87</td>\n",
              "      <td>-999</td>\n",
              "      <td>-78</td>\n",
              "      <td>-999</td>\n",
              "      <td>-91</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>...</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-80</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-76</td>\n",
              "      <td>-85</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-88</td>\n",
              "      <td>-70</td>\n",
              "      <td>-68</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-89</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-68</td>\n",
              "      <td>-999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5d2709d403f801723c32bd39_06882da3694b7160c0f10...</td>\n",
              "      <td>1.573706e+12</td>\n",
              "      <td>1573705854189</td>\n",
              "      <td>174</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>06882da3694b7160c0f105f5</td>\n",
              "      <td>5d2709d403f801723c32bd39</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-87</td>\n",
              "      <td>-999</td>\n",
              "      <td>-78</td>\n",
              "      <td>-999</td>\n",
              "      <td>-91</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>...</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-80</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-76</td>\n",
              "      <td>-85</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-88</td>\n",
              "      <td>-70</td>\n",
              "      <td>-68</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-89</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-68</td>\n",
              "      <td>-999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5d2709d403f801723c32bd39_06882da3694b7160c0f10...</td>\n",
              "      <td>1.573706e+12</td>\n",
              "      <td>1573705856155</td>\n",
              "      <td>67</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>06882da3694b7160c0f105f5</td>\n",
              "      <td>5d2709d403f801723c32bd39</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-87</td>\n",
              "      <td>-999</td>\n",
              "      <td>-80</td>\n",
              "      <td>-999</td>\n",
              "      <td>-91</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>...</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-80</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-76</td>\n",
              "      <td>-85</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-89</td>\n",
              "      <td>-70</td>\n",
              "      <td>-68</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-90</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-68</td>\n",
              "      <td>-999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5d2709d403f801723c32bd39_06882da3694b7160c0f10...</td>\n",
              "      <td>1.573706e+12</td>\n",
              "      <td>1573705862090</td>\n",
              "      <td>898</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>06882da3694b7160c0f105f5</td>\n",
              "      <td>5d2709d403f801723c32bd39</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-87</td>\n",
              "      <td>-999</td>\n",
              "      <td>-68</td>\n",
              "      <td>-999</td>\n",
              "      <td>-91</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>...</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-73</td>\n",
              "      <td>-91</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-89</td>\n",
              "      <td>-70</td>\n",
              "      <td>-68</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-89</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5d2709d403f801723c32bd39_06882da3694b7160c0f10...</td>\n",
              "      <td>1.573706e+12</td>\n",
              "      <td>1573705869915</td>\n",
              "      <td>720</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>06882da3694b7160c0f105f5</td>\n",
              "      <td>5d2709d403f801723c32bd39</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-89</td>\n",
              "      <td>-999</td>\n",
              "      <td>-71</td>\n",
              "      <td>-999</td>\n",
              "      <td>-87</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>...</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-73</td>\n",
              "      <td>-91</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-89</td>\n",
              "      <td>-70</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-91</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-74</td>\n",
              "      <td>-999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1001 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 site_path_timestamp  ...  63781517942f8b63c2189c376cc0cf3db1d27ed1\n",
              "0  5d2709d403f801723c32bd39_06882da3694b7160c0f10...  ...                                      -999\n",
              "1  5d2709d403f801723c32bd39_06882da3694b7160c0f10...  ...                                      -999\n",
              "2  5d2709d403f801723c32bd39_06882da3694b7160c0f10...  ...                                      -999\n",
              "3  5d2709d403f801723c32bd39_06882da3694b7160c0f10...  ...                                      -999\n",
              "4  5d2709d403f801723c32bd39_06882da3694b7160c0f10...  ...                                      -999\n",
              "\n",
              "[5 rows x 1001 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "id": "oaMr1ftymrUB",
        "outputId": "ae898bf0-824d-4e64-fb09-eeff342fcea3"
      },
      "source": [
        "# Match train and test columns\n",
        "all_train_cols = list(train_df.columns)\n",
        "all_test_cols = list(test_df.columns)\n",
        "print(\"all train cols: \", len(all_train_cols), \"\\n\", \"all test cols: \", len(all_test_cols))\n",
        "\n",
        "# get all non-overlapping columns\n",
        "no_overlap_col = list(set(all_train_cols) ^ set(all_test_cols))\n",
        "no_overlap_col += [\"floor\", \"file_id\", \"site_id\"] # add other columns to exclude\n",
        "train_cols = [x for x in all_train_cols if x not in no_overlap_col]\n",
        "test_cols = [x for x in all_test_cols if x not in no_overlap_col]\n",
        "# test_cols += [\"site_path_timestamp\"] # test_df needs to keep \"site_path_timestamp\"\n",
        "\n",
        "# filter out the df by the columns to leave\n",
        "train_df = train_df[train_cols]\n",
        "test_df = test_df[test_cols]\n",
        "\n",
        "# # Drop some columns not necessary as a feature\n",
        "# drop_cols = [\"wifi_ts\", \"floor\", \"file_id\", \"site_id\"]\n",
        "# for df in [train_df, test_df]:\n",
        "#     df = df.drop(columns=drop_cols, inplace=True)\n",
        "\n",
        "# Convert df object columns to integers and then the whole thing to tensors\n",
        "for df in [train_df, test_df]:\n",
        "    obj_col = list(df.select_dtypes(include=['object']).columns)\n",
        "    for col in obj_col:\n",
        "        le = LabelEncoder()\n",
        "        df[col] = le.fit_transform(df[col].values)\n",
        "\n",
        "# # Try without using scalers for now. \n",
        "# # Apply MinMaxScaler to each IMU columns\n",
        "# current_cols = list(train_df.columns)\n",
        "# imu_cols = current_cols[:23]\n",
        "# exception_columns = [\"wps_diff\", \"x\", \"y\", \"floor_int\", \"rel_diff\", \"rel_x\", \"rel_y\"]\n",
        "# imu_cols = [x for x in imu_cols if x not in exception_columns]\n",
        "# print(\"imu_cols: \", imu_cols)\n",
        "# for col in imu_cols:\n",
        "#     ss_scaler = StandardScaler()\n",
        "#     train_df[col] = ss_scaler.fit_transform(train_df[col].values.reshape(-1, 1))\n",
        "#     test_df[col] = ss_scaler.transform(test_df[col].values.reshape(-1, 1))\n",
        "\n",
        "print(len(train_df.columns))\n",
        "print(len(test_df.columns))\n",
        "print(len(train_df))\n",
        "print(len(test_df))\n",
        "print(\"object dtype columns in train\", train_df.select_dtypes(include=['object']).columns)\n",
        "print(\"object dtype columns in test\", test_df.select_dtypes(include=['object']).columns)\n",
        "display(train_df.head())\n",
        "display(test_df.head())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "all train cols:  999 \n",
            " all test cols:  1001\n",
            "996\n",
            "996\n",
            "10027\n",
            "1223\n",
            "object dtype columns in train Index([], dtype='object')\n",
            "object dtype columns in test Index([], dtype='object')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wifi_ts</th>\n",
              "      <th>wps_diff</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>floor_int</th>\n",
              "      <th>b1847b7279f12430b70cf177ae9419b2c6563c7e</th>\n",
              "      <th>e78f6a70bb684764884bf5bfc22876354dc4978f</th>\n",
              "      <th>7f92c838def910dc333d6ec1785cc9de7c428514</th>\n",
              "      <th>49baf7f0e5495ee2926baa0e941d265d725dbdd5</th>\n",
              "      <th>9419ecb5700d351a0ca4c6f6dc4f7804c5800ebe</th>\n",
              "      <th>6c598641414c17dfca87a3acc982507ba08902cb</th>\n",
              "      <th>bf8984bf3344f3267b1fb3cb5dc95ddf7e2117d3</th>\n",
              "      <th>24a2a9c3edd47eb479f05d4067368c9e14b8964b</th>\n",
              "      <th>2b3f7594cc8ab2b0413d45d6eea1149a9a7809a7</th>\n",
              "      <th>1cecf9fc6a1ceba0ad7063fdb5816ec43e90e94f</th>\n",
              "      <th>018a066872b67d5b33570ddeb6142c602a22e451</th>\n",
              "      <th>55ee0fec7b7be3e76132b20fca01e8486743a3f6</th>\n",
              "      <th>4f32282342971b17eb8611ac5f145d0b8768f62d</th>\n",
              "      <th>ee2a7ce46e83e2de489c9f78f4e550156d57f484</th>\n",
              "      <th>606fc3f5664630412548bbd099f9c8ad1dc5acb6</th>\n",
              "      <th>40ab9973a268cc79a4a8210e67f9b912723ed8c3</th>\n",
              "      <th>c81b745f26735105787cf9e7b547a7c37a65a851</th>\n",
              "      <th>832743c77af1c7eb12fcd909c438dcf39b6008f3</th>\n",
              "      <th>7b42d018fdfe2ab118d8ec85bcf1d6983750750c</th>\n",
              "      <th>ef99ef623422c284a774e35fc1b1cf3e721dbd03</th>\n",
              "      <th>c1591135c00bca7a723a49df8c9d8de34326fbd3</th>\n",
              "      <th>3956907df9b51fae849a7afced246f127f259504</th>\n",
              "      <th>1359034ef247ed40bf5b3723915b9fc60cc74837</th>\n",
              "      <th>2a5b0895595bcf131a0b5c3e5dc4b9f39e06bd3f</th>\n",
              "      <th>ca7a7877b1dbad8f6ef696b1e88f34dc6f635b0d</th>\n",
              "      <th>396640532a81255d6b75b41e7a184c1393b74ee4</th>\n",
              "      <th>aebc6ae6f9dfe7b548779e39cc9fd03c60a67ecc</th>\n",
              "      <th>70e578e027d0ab0bfeb5959e18f3c8045a32236d</th>\n",
              "      <th>07ccdba1f0a266adf501c867319ac7007e65d290</th>\n",
              "      <th>d7b2ba98b972b65650af520075c9712a3d8994a7</th>\n",
              "      <th>2b844704051b64e47b4800e1d6e932bbdd5356b6</th>\n",
              "      <th>1c390c87d362e628cebc103eb247d2b7aa813542</th>\n",
              "      <th>6d70c76ca1d2e44f634d98810313c1c91b07ffa3</th>\n",
              "      <th>ec097c076cbcdbbcda43d0eb6372101151a914e0</th>\n",
              "      <th>eb61afa796d2ebdf9ec651593837743dc6c3ef11</th>\n",
              "      <th>...</th>\n",
              "      <th>46e35eba345a6366234c028567bbb91c99b872e5</th>\n",
              "      <th>298e1870fda64fe8018ec79e835cf308f81181fa</th>\n",
              "      <th>31b0561e7e9a03156b248da215d7ab7bf8d6d8c8</th>\n",
              "      <th>3ab6773bc6bce7fb154b3d46f6058f0192bfd01b</th>\n",
              "      <th>41d0c04a20a77e8daaba6c585f083ca0ef57affc</th>\n",
              "      <th>a3dfc65c01d171a671cd615236b79c61810de354</th>\n",
              "      <th>06028150b43acb7e11121888ab434cdd5f679f1d</th>\n",
              "      <th>f7853f850bbb98d20bb2b4dd6380c071b5a1cb02</th>\n",
              "      <th>078a75dfda9e932f608fca0837610b97d11d3dd7</th>\n",
              "      <th>fc8fd87104388e513937ac13696b6f72af2add53</th>\n",
              "      <th>422765063ea5b0e5667a240e3b802041ab93b6e3</th>\n",
              "      <th>6cfaf9601b6e2587a321d3b803c20f9eb05fd452</th>\n",
              "      <th>35c0ef8cb2af11a81092979d55c4324b8101332f</th>\n",
              "      <th>764cbb8b20a46c411fe5807df9867b92c0935c08</th>\n",
              "      <th>78209eb1032640dd8f611e310c8619ab2c9cb071</th>\n",
              "      <th>1fc19e52666a95169b365f5ad1352d9369cb045a</th>\n",
              "      <th>14d3489b6de7d970babc8a951bf6ed5bd289dea0</th>\n",
              "      <th>6646a9365ace5164d2ef3dfb39b88a8a924568d3</th>\n",
              "      <th>a7ac17ed71cc594bed820bfbbca833f3f9972592</th>\n",
              "      <th>976e778d614b1e8e9efa8bc7eeaf552b7fe5ccb5</th>\n",
              "      <th>5749b4541786aea857ff1552dfac8cf292044c29</th>\n",
              "      <th>b1f4814d1a8c7885960118015e2c8f47fcdd0f4f</th>\n",
              "      <th>75df7c8888ddbf148407aa76c3d6b72406bc4c27</th>\n",
              "      <th>fc88f6a4f0351f8a2b34d256fcda35579d9e0ead</th>\n",
              "      <th>21f079033442b71f1a870ca0988fa9afcc7dc810</th>\n",
              "      <th>3f8321ce0dd6348fa440eb25acae2be996c3b2e7</th>\n",
              "      <th>9054af7ed2ceb6b130b4fd2a09f36b9b1f611f11</th>\n",
              "      <th>77de2f0f3005949e35e2e2aef7af1ddc5d164695</th>\n",
              "      <th>588f35babb83fab68a9c539567140ba5c17284c7</th>\n",
              "      <th>68962923d8621f6868a762b2344ce1ab8209ecdd</th>\n",
              "      <th>7abbb83f5b877ce5c1c9e835422365cd8bac3b0d</th>\n",
              "      <th>acb4abc93968ad51368a0351fa7fda5401598069</th>\n",
              "      <th>f20fed9f248d4352def744d9a8262b49042ee7f3</th>\n",
              "      <th>437d45cd7c45b040b95abdb483b02d601c761d7d</th>\n",
              "      <th>b083b8279418c48d60a05cff039b0536339a1e4d</th>\n",
              "      <th>fa0d8c168b62f11f34fdf314d81cebdf1ca9ebd0</th>\n",
              "      <th>955eb46cfdee70adab1de9ce909f0cb059fd29d2</th>\n",
              "      <th>48d751207622a3606df95184fd58b32347057af3</th>\n",
              "      <th>5238e869a2d0d2a851ba1f9484c874c57419148e</th>\n",
              "      <th>63781517942f8b63c2189c376cc0cf3db1d27ed1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1573789444679</td>\n",
              "      <td>1918</td>\n",
              "      <td>88.03561</td>\n",
              "      <td>109.90122</td>\n",
              "      <td>-1</td>\n",
              "      <td>-76</td>\n",
              "      <td>-74</td>\n",
              "      <td>-76</td>\n",
              "      <td>-999</td>\n",
              "      <td>-73</td>\n",
              "      <td>-89</td>\n",
              "      <td>-77</td>\n",
              "      <td>-999</td>\n",
              "      <td>-49</td>\n",
              "      <td>-999</td>\n",
              "      <td>-73</td>\n",
              "      <td>-87</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-46</td>\n",
              "      <td>-66</td>\n",
              "      <td>-75</td>\n",
              "      <td>-84</td>\n",
              "      <td>-999</td>\n",
              "      <td>-76</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-84</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-80</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>...</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1573789446609</td>\n",
              "      <td>3848</td>\n",
              "      <td>88.03561</td>\n",
              "      <td>109.90122</td>\n",
              "      <td>-1</td>\n",
              "      <td>-79</td>\n",
              "      <td>-79</td>\n",
              "      <td>-83</td>\n",
              "      <td>-999</td>\n",
              "      <td>-73</td>\n",
              "      <td>-89</td>\n",
              "      <td>-77</td>\n",
              "      <td>-999</td>\n",
              "      <td>-44</td>\n",
              "      <td>-88</td>\n",
              "      <td>-78</td>\n",
              "      <td>-87</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-59</td>\n",
              "      <td>-66</td>\n",
              "      <td>-75</td>\n",
              "      <td>-89</td>\n",
              "      <td>-999</td>\n",
              "      <td>-76</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-84</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-80</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>...</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1573789448539</td>\n",
              "      <td>5298</td>\n",
              "      <td>91.62208</td>\n",
              "      <td>108.70687</td>\n",
              "      <td>-1</td>\n",
              "      <td>-68</td>\n",
              "      <td>-67</td>\n",
              "      <td>-67</td>\n",
              "      <td>-78</td>\n",
              "      <td>-73</td>\n",
              "      <td>-89</td>\n",
              "      <td>-78</td>\n",
              "      <td>-85</td>\n",
              "      <td>-46</td>\n",
              "      <td>-88</td>\n",
              "      <td>-78</td>\n",
              "      <td>-87</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-48</td>\n",
              "      <td>-66</td>\n",
              "      <td>-75</td>\n",
              "      <td>-89</td>\n",
              "      <td>-999</td>\n",
              "      <td>-76</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-84</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-80</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>...</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1573789450452</td>\n",
              "      <td>3385</td>\n",
              "      <td>91.62208</td>\n",
              "      <td>108.70687</td>\n",
              "      <td>-1</td>\n",
              "      <td>-73</td>\n",
              "      <td>-73</td>\n",
              "      <td>-77</td>\n",
              "      <td>-78</td>\n",
              "      <td>-73</td>\n",
              "      <td>-89</td>\n",
              "      <td>-74</td>\n",
              "      <td>-91</td>\n",
              "      <td>-55</td>\n",
              "      <td>-84</td>\n",
              "      <td>-77</td>\n",
              "      <td>-87</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-42</td>\n",
              "      <td>-66</td>\n",
              "      <td>-75</td>\n",
              "      <td>-89</td>\n",
              "      <td>-999</td>\n",
              "      <td>-76</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-84</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-83</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>...</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1573789452370</td>\n",
              "      <td>1467</td>\n",
              "      <td>91.62208</td>\n",
              "      <td>108.70687</td>\n",
              "      <td>-1</td>\n",
              "      <td>-72</td>\n",
              "      <td>-71</td>\n",
              "      <td>-70</td>\n",
              "      <td>-78</td>\n",
              "      <td>-73</td>\n",
              "      <td>-76</td>\n",
              "      <td>-81</td>\n",
              "      <td>-91</td>\n",
              "      <td>-48</td>\n",
              "      <td>-84</td>\n",
              "      <td>-77</td>\n",
              "      <td>-78</td>\n",
              "      <td>-76</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-47</td>\n",
              "      <td>-66</td>\n",
              "      <td>-75</td>\n",
              "      <td>-89</td>\n",
              "      <td>-999</td>\n",
              "      <td>-77</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-86</td>\n",
              "      <td>-84</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-89</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>...</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 996 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         wifi_ts  ...  63781517942f8b63c2189c376cc0cf3db1d27ed1\n",
              "0  1573789444679  ...                                      -999\n",
              "1  1573789446609  ...                                      -999\n",
              "2  1573789448539  ...                                      -999\n",
              "3  1573789450452  ...                                      -999\n",
              "4  1573789452370  ...                                      -999\n",
              "\n",
              "[5 rows x 996 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wifi_ts</th>\n",
              "      <th>wps_diff</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>floor_int</th>\n",
              "      <th>b1847b7279f12430b70cf177ae9419b2c6563c7e</th>\n",
              "      <th>e78f6a70bb684764884bf5bfc22876354dc4978f</th>\n",
              "      <th>7f92c838def910dc333d6ec1785cc9de7c428514</th>\n",
              "      <th>49baf7f0e5495ee2926baa0e941d265d725dbdd5</th>\n",
              "      <th>9419ecb5700d351a0ca4c6f6dc4f7804c5800ebe</th>\n",
              "      <th>6c598641414c17dfca87a3acc982507ba08902cb</th>\n",
              "      <th>bf8984bf3344f3267b1fb3cb5dc95ddf7e2117d3</th>\n",
              "      <th>24a2a9c3edd47eb479f05d4067368c9e14b8964b</th>\n",
              "      <th>2b3f7594cc8ab2b0413d45d6eea1149a9a7809a7</th>\n",
              "      <th>1cecf9fc6a1ceba0ad7063fdb5816ec43e90e94f</th>\n",
              "      <th>018a066872b67d5b33570ddeb6142c602a22e451</th>\n",
              "      <th>55ee0fec7b7be3e76132b20fca01e8486743a3f6</th>\n",
              "      <th>4f32282342971b17eb8611ac5f145d0b8768f62d</th>\n",
              "      <th>ee2a7ce46e83e2de489c9f78f4e550156d57f484</th>\n",
              "      <th>606fc3f5664630412548bbd099f9c8ad1dc5acb6</th>\n",
              "      <th>40ab9973a268cc79a4a8210e67f9b912723ed8c3</th>\n",
              "      <th>c81b745f26735105787cf9e7b547a7c37a65a851</th>\n",
              "      <th>832743c77af1c7eb12fcd909c438dcf39b6008f3</th>\n",
              "      <th>7b42d018fdfe2ab118d8ec85bcf1d6983750750c</th>\n",
              "      <th>ef99ef623422c284a774e35fc1b1cf3e721dbd03</th>\n",
              "      <th>c1591135c00bca7a723a49df8c9d8de34326fbd3</th>\n",
              "      <th>3956907df9b51fae849a7afced246f127f259504</th>\n",
              "      <th>1359034ef247ed40bf5b3723915b9fc60cc74837</th>\n",
              "      <th>2a5b0895595bcf131a0b5c3e5dc4b9f39e06bd3f</th>\n",
              "      <th>ca7a7877b1dbad8f6ef696b1e88f34dc6f635b0d</th>\n",
              "      <th>396640532a81255d6b75b41e7a184c1393b74ee4</th>\n",
              "      <th>aebc6ae6f9dfe7b548779e39cc9fd03c60a67ecc</th>\n",
              "      <th>70e578e027d0ab0bfeb5959e18f3c8045a32236d</th>\n",
              "      <th>07ccdba1f0a266adf501c867319ac7007e65d290</th>\n",
              "      <th>d7b2ba98b972b65650af520075c9712a3d8994a7</th>\n",
              "      <th>2b844704051b64e47b4800e1d6e932bbdd5356b6</th>\n",
              "      <th>1c390c87d362e628cebc103eb247d2b7aa813542</th>\n",
              "      <th>6d70c76ca1d2e44f634d98810313c1c91b07ffa3</th>\n",
              "      <th>ec097c076cbcdbbcda43d0eb6372101151a914e0</th>\n",
              "      <th>eb61afa796d2ebdf9ec651593837743dc6c3ef11</th>\n",
              "      <th>...</th>\n",
              "      <th>46e35eba345a6366234c028567bbb91c99b872e5</th>\n",
              "      <th>298e1870fda64fe8018ec79e835cf308f81181fa</th>\n",
              "      <th>31b0561e7e9a03156b248da215d7ab7bf8d6d8c8</th>\n",
              "      <th>3ab6773bc6bce7fb154b3d46f6058f0192bfd01b</th>\n",
              "      <th>41d0c04a20a77e8daaba6c585f083ca0ef57affc</th>\n",
              "      <th>a3dfc65c01d171a671cd615236b79c61810de354</th>\n",
              "      <th>06028150b43acb7e11121888ab434cdd5f679f1d</th>\n",
              "      <th>f7853f850bbb98d20bb2b4dd6380c071b5a1cb02</th>\n",
              "      <th>078a75dfda9e932f608fca0837610b97d11d3dd7</th>\n",
              "      <th>fc8fd87104388e513937ac13696b6f72af2add53</th>\n",
              "      <th>422765063ea5b0e5667a240e3b802041ab93b6e3</th>\n",
              "      <th>6cfaf9601b6e2587a321d3b803c20f9eb05fd452</th>\n",
              "      <th>35c0ef8cb2af11a81092979d55c4324b8101332f</th>\n",
              "      <th>764cbb8b20a46c411fe5807df9867b92c0935c08</th>\n",
              "      <th>78209eb1032640dd8f611e310c8619ab2c9cb071</th>\n",
              "      <th>1fc19e52666a95169b365f5ad1352d9369cb045a</th>\n",
              "      <th>14d3489b6de7d970babc8a951bf6ed5bd289dea0</th>\n",
              "      <th>6646a9365ace5164d2ef3dfb39b88a8a924568d3</th>\n",
              "      <th>a7ac17ed71cc594bed820bfbbca833f3f9972592</th>\n",
              "      <th>976e778d614b1e8e9efa8bc7eeaf552b7fe5ccb5</th>\n",
              "      <th>5749b4541786aea857ff1552dfac8cf292044c29</th>\n",
              "      <th>b1f4814d1a8c7885960118015e2c8f47fcdd0f4f</th>\n",
              "      <th>75df7c8888ddbf148407aa76c3d6b72406bc4c27</th>\n",
              "      <th>fc88f6a4f0351f8a2b34d256fcda35579d9e0ead</th>\n",
              "      <th>21f079033442b71f1a870ca0988fa9afcc7dc810</th>\n",
              "      <th>3f8321ce0dd6348fa440eb25acae2be996c3b2e7</th>\n",
              "      <th>9054af7ed2ceb6b130b4fd2a09f36b9b1f611f11</th>\n",
              "      <th>77de2f0f3005949e35e2e2aef7af1ddc5d164695</th>\n",
              "      <th>588f35babb83fab68a9c539567140ba5c17284c7</th>\n",
              "      <th>68962923d8621f6868a762b2344ce1ab8209ecdd</th>\n",
              "      <th>7abbb83f5b877ce5c1c9e835422365cd8bac3b0d</th>\n",
              "      <th>acb4abc93968ad51368a0351fa7fda5401598069</th>\n",
              "      <th>f20fed9f248d4352def744d9a8262b49042ee7f3</th>\n",
              "      <th>437d45cd7c45b040b95abdb483b02d601c761d7d</th>\n",
              "      <th>b083b8279418c48d60a05cff039b0536339a1e4d</th>\n",
              "      <th>fa0d8c168b62f11f34fdf314d81cebdf1ca9ebd0</th>\n",
              "      <th>955eb46cfdee70adab1de9ce909f0cb059fd29d2</th>\n",
              "      <th>48d751207622a3606df95184fd58b32347057af3</th>\n",
              "      <th>5238e869a2d0d2a851ba1f9484c874c57419148e</th>\n",
              "      <th>63781517942f8b63c2189c376cc0cf3db1d27ed1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1573705854189</td>\n",
              "      <td>5859</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-87</td>\n",
              "      <td>-999</td>\n",
              "      <td>-78</td>\n",
              "      <td>-999</td>\n",
              "      <td>-91</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>...</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-80</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-76</td>\n",
              "      <td>-85</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-88</td>\n",
              "      <td>-70</td>\n",
              "      <td>-68</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-89</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-68</td>\n",
              "      <td>-999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1573705854189</td>\n",
              "      <td>174</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-87</td>\n",
              "      <td>-999</td>\n",
              "      <td>-78</td>\n",
              "      <td>-999</td>\n",
              "      <td>-91</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>...</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-80</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-76</td>\n",
              "      <td>-85</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-88</td>\n",
              "      <td>-70</td>\n",
              "      <td>-68</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-89</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-68</td>\n",
              "      <td>-999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1573705856155</td>\n",
              "      <td>67</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-87</td>\n",
              "      <td>-999</td>\n",
              "      <td>-80</td>\n",
              "      <td>-999</td>\n",
              "      <td>-91</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>...</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-80</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-76</td>\n",
              "      <td>-85</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-89</td>\n",
              "      <td>-70</td>\n",
              "      <td>-68</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-90</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-68</td>\n",
              "      <td>-999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1573705862090</td>\n",
              "      <td>898</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-87</td>\n",
              "      <td>-999</td>\n",
              "      <td>-68</td>\n",
              "      <td>-999</td>\n",
              "      <td>-91</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>...</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-73</td>\n",
              "      <td>-91</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-89</td>\n",
              "      <td>-70</td>\n",
              "      <td>-68</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-89</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1573705869915</td>\n",
              "      <td>720</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-89</td>\n",
              "      <td>-999</td>\n",
              "      <td>-71</td>\n",
              "      <td>-999</td>\n",
              "      <td>-87</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>...</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-73</td>\n",
              "      <td>-91</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-89</td>\n",
              "      <td>-70</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-91</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-74</td>\n",
              "      <td>-999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 996 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         wifi_ts  ...  63781517942f8b63c2189c376cc0cf3db1d27ed1\n",
              "0  1573705854189  ...                                      -999\n",
              "1  1573705854189  ...                                      -999\n",
              "2  1573705856155  ...                                      -999\n",
              "3  1573705862090  ...                                      -999\n",
              "4  1573705869915  ...                                      -999\n",
              "\n",
              "[5 rows x 996 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnDOQsyFny1q"
      },
      "source": [
        "# # Use when we need to consider timetamps\n",
        "\n",
        "# # get timestamp and sort by time\n",
        "# test_df[[\"site\", \"file\", \"timestamp\"]] = test_df[\"site_path_timestamp\"].apply(lambda x: pd.Series(x.split(\"_\")))\n",
        "# test_df = test_df.drop(columns=[\"site_path_timestamp\", \"site\", \"file\"])\n",
        "# test_df[\"timestamp\"] = test_df[\"timestamp\"].astype(int)\n",
        "# # display(test_df.head())\n",
        "\n",
        "# # sort by time\n",
        "# train_df = train_df.sort_values(by=[\"file_id\", \"wifi_ts\"])\n",
        "# test_df = test_df.sort_values(by=[\"file_id\", \"timestamp\"])\n",
        "# # display(train_df.head(20))\n",
        "# # display(test_df.head(20))\n",
        "# # print(len(test_df.columns))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ePebfXPvPui"
      },
      "source": [
        "---\n",
        "## 1Conv + Transformer Implementation\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNgXfNr2rnyk"
      },
      "source": [
        "class IndoorDataset(Dataset):\n",
        "    def __init__(self, data, flag=\"train\"):\n",
        "        self.flag = flag\n",
        "        self.data = data\n",
        "\n",
        "        all_cols = list(data.columns)\n",
        "        target_cols = [\"x\", \"y\", \"floor_int\"]\n",
        "        non_target_cols = [col for col in all_cols if col not in target_cols]\n",
        "        self.features = data[non_target_cols]\n",
        "\n",
        "        if self.flag == \"train\":\n",
        "            self.x = data.loc[:, \"x\"]\n",
        "            self.y = data.loc[:, \"y\"]\n",
        "            # self.f = data.loc[:, \"floor_int\"]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def feat_width(self):\n",
        "        return self.features.shape[1]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        features = self.features.iloc[index, :]\n",
        "        features_out = torch.tensor(features.to_numpy())\n",
        "        if self.flag == \"train\":\n",
        "            x = self.x[index]\n",
        "            y = self.y[index]\n",
        "            # f = self.f[index]\n",
        "            x_out = torch.tensor(x)\n",
        "            y_out = torch.tensor(y)\n",
        "            # f_out = torch.tensor(f)\n",
        "            return features_out, x_out, y_out\n",
        "        else:\n",
        "            return features_out"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZNpNu_psGuE",
        "outputId": "1a9a927a-4a41-423a-ba05-47b4e48f1205"
      },
      "source": [
        "# Create train and test Dataset\n",
        "train_ds = IndoorDataset(train_df)\n",
        "test_ds = IndoorDataset(test_df, flag=\"test\")\n",
        "\n",
        "one_train_ds = train_ds.__getitem__(1000)\n",
        "print(\"train ds len: \", train_ds.__len__())\n",
        "# print(\"train ds features: \", one_train_ds[0])\n",
        "print(\"train ds x: \", one_train_ds[1])\n",
        "print(\"train ds y: \", one_train_ds[2])\n",
        "# print(\"train ds f: \", one_train_ds[3])\n",
        "\n",
        "one_test_ds = test_ds.__getitem__(0)\n",
        "print(\"test ds len: \", test_ds.__len__())\n",
        "# print(\"test ds features: \", one_test_ds[0])\n",
        "# print(\"test ds: \", one_test_ds)\n",
        "\n",
        "print(train_ds.feat_width())\n",
        "print(test_ds.feat_width())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train ds len:  10027\n",
            "train ds x:  tensor(104.6150, dtype=torch.float64)\n",
            "train ds y:  tensor(83.2759, dtype=torch.float64)\n",
            "test ds len:  1223\n",
            "993\n",
            "993\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsDBm9wbv8JS"
      },
      "source": [
        "# Create Dataloader\n",
        "train_dataloader = DataLoader(train_ds, batch_size=BATCH_SIZE)\n",
        "test_dataloader = DataLoader(test_ds, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51XdnWYay8SP"
      },
      "source": [
        "class Conv1dMaxPool(nn.Module):\n",
        "    def __init__(self, in_channels, kernel_size, stride, padding):\n",
        "        super(Conv1dMaxPool, self).__init__()\n",
        "        self.conv_11 = nn.Conv1d(in_channels, 16, kernel_size, stride, padding)\n",
        "        self.conv_12 = nn.Conv1d(16, 16, kernel_size, stride, padding)\n",
        "        self.max_pool_1 = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
        "        self.conv_21 = nn.Conv1d(16, 32, kernel_size, stride, padding)\n",
        "        self.conv_22 = nn.Conv1d(32, 32, kernel_size, stride, padding)\n",
        "        self.max_pool_2 = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
        "        self.conv_31 = nn.Conv1d(32, 64, kernel_size, stride, padding)\n",
        "        self.conv_32 = nn.Conv1d(64, 64, kernel_size, stride, padding)\n",
        "        self.max_pool_3 = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
        "        self.fc_encoder = nn.Linear(64*2, 512)\n",
        "        self.batch_norm = nn.BatchNorm1d(512)\n",
        "        self.out_encoder = nn.Linear(512, 64)\n",
        "\n",
        "    def forward(self, x, prints=False):\n",
        "        x = x.unsqueeze(0)\n",
        "        x = torch.transpose(x, 0, 1)\n",
        "        if prints: print(\"before conv 1: \", x.shape)\n",
        "        x = F.relu(self.conv_11(x))\n",
        "        x = F.relu(self.conv_12(x))\n",
        "        x = self.max_pool_1(x)\n",
        "        if prints: print(\"after conv & max_pool 1: \", x.shape)\n",
        "\n",
        "        x = F.relu(self.conv_21(x))\n",
        "        x = F.relu(self.conv_22(x))\n",
        "        x = self.max_pool_2(x)\n",
        "        if prints: print(\"after conv & max_pool 2: \", x.shape)\n",
        "\n",
        "        x = F.relu(self.conv_31(x))\n",
        "        x = F.relu(self.conv_32(x))\n",
        "        x = self.max_pool_3(x)\n",
        "        if prints: print(\"after conv & max_pool 3: \", x.shape)\n",
        "\n",
        "        # if prints: print(\"checking reshaping: \", x[0])\n",
        "        x = x.view(x.size(0), -1) # flatten last two dimensions\n",
        "        # if prints: print(\"checking reshaping: \", x[0])\n",
        "        if prints: print(\"flatten last two dims: \", x.shape)\n",
        "        x = self.batch_norm(self.fc_encoder(x))\n",
        "        x = self.out_encoder(x)\n",
        "        if prints: print(\"final output: \", x.shape)\n",
        "        return x"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJPs3O4323xO",
        "outputId": "88ff66a5-d1a3-4c96-c7b2-dccb709996b1"
      },
      "source": [
        "train_length = train_ds.__len__()\n",
        "train_width = train_ds.feat_width()\n",
        "\n",
        "model = Conv1dMaxPool(in_channels=1, kernel_size=3, stride=2, padding=1).to(DEVICE)\n",
        "print(model)\n",
        "\n",
        "# input_size = num of features, so length of columns\n",
        "# sequence_length = 5\n",
        "\n",
        "# Check if it works\n",
        "train_batch_sample = next(iter(train_dataloader))\n",
        "print(\"feature shape: \", train_batch_sample[0].shape)\n",
        "print(\"x shape: \", train_batch_sample[1].shape)\n",
        "print(\"y shape: \", train_batch_sample[2].shape)\n",
        "train_batch_sample = train_batch_sample[0]\n",
        "print(\"input shape: \", train_batch_sample.shape)\n",
        "outputs = model(train_batch_sample.float(), prints=True)\n",
        "print(\"final output shape: \", outputs.shape)\n",
        "print(\"final output: \", outputs)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Conv1dMaxPool(\n",
            "  (conv_11): Conv1d(1, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
            "  (conv_12): Conv1d(16, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
            "  (max_pool_1): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (conv_21): Conv1d(16, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
            "  (conv_22): Conv1d(32, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
            "  (max_pool_2): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (conv_31): Conv1d(32, 64, kernel_size=(3,), stride=(2,), padding=(1,))\n",
            "  (conv_32): Conv1d(64, 64, kernel_size=(3,), stride=(2,), padding=(1,))\n",
            "  (max_pool_3): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (fc_encoder): Linear(in_features=128, out_features=512, bias=True)\n",
            "  (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (out_encoder): Linear(in_features=512, out_features=64, bias=True)\n",
            ")\n",
            "feature shape:  torch.Size([32, 993])\n",
            "x shape:  torch.Size([32])\n",
            "y shape:  torch.Size([32])\n",
            "input shape:  torch.Size([32, 993])\n",
            "before conv 1:  torch.Size([32, 1, 993])\n",
            "after conv & max_pool 1:  torch.Size([32, 16, 125])\n",
            "after conv & max_pool 2:  torch.Size([32, 32, 16])\n",
            "after conv & max_pool 3:  torch.Size([32, 64, 2])\n",
            "flatten last two dims:  torch.Size([32, 128])\n",
            "final output:  torch.Size([32, 64])\n",
            "final output shape:  torch.Size([32, 64])\n",
            "final output:  tensor([[-0.2118, -1.0763,  0.1976,  ...,  0.4317, -0.5047,  0.3585],\n",
            "        [ 0.0506, -0.8020,  0.1623,  ...,  0.2870, -0.4521,  0.4604],\n",
            "        [ 0.0528, -0.8078,  0.1612,  ...,  0.2819, -0.4476,  0.4646],\n",
            "        ...,\n",
            "        [-0.1432,  1.8369, -0.2775,  ..., -0.7710,  0.8783, -0.8489],\n",
            "        [-0.2504,  1.8940, -0.2268,  ..., -0.7627,  0.8945, -0.8242],\n",
            "        [-0.2365,  1.8369, -0.2619,  ..., -0.8064,  0.9350, -0.8586]],\n",
            "       grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IREBqLnPERaz"
      },
      "source": [
        "# Transformer: -> conv1d output -> pe -> (embed thru TransformerEncoderLayer)\n",
        "# -> encoder -> decoder\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, feature_dim, batch_len):\n",
        "        super(PositionalEncoding, self).__init__()       \n",
        "        pe = torch.zeros(batch_len, feature_dim)\n",
        "        position = torch.arange(0, batch_len, dtype=torch.float)\n",
        "        div_term = torch.exp(torch.arange(0, feature_dim, 2).float() * (-math.log(10000.0) / feature_dim))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        # pe.requires_grad = False\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:x.size(0), :]\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, feature_dim, batch_len, num_layers=1, dropout=0.1):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.src_mask = None\n",
        "        self.pos_encoder = PositionalEncoding(feature_dim, batch_len)\n",
        "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=feature_dim, nhead=2, dropout=dropout)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)        \n",
        "        self.decoder = nn.Linear(feature_dim, 2)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.kaiming_uniform_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.src_mask is None or self.src_mask.size(0) != len(x):\n",
        "            mask = self._generate_square_subsequent_mask(len(x)).to(DEVICE)\n",
        "            self.src_mask = mask\n",
        "\n",
        "        x = self.pos_encoder(x)\n",
        "        output = self.transformer_encoder(x, self.src_mask)#, self.src_mask)\n",
        "        output = self.decoder(output)\n",
        "        return output\n",
        "\n",
        "    def _generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "        return mask"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrgkU-Zlvw0D",
        "outputId": "c6d6ad65-dc9d-45f2-f1aa-399586e129d9"
      },
      "source": [
        "# testing transformer block\n",
        "Conv = Conv1dMaxPool(in_channels=1, kernel_size=3, stride=2, padding=1).to(DEVICE)\n",
        "\n",
        "# Check if it works\n",
        "train_batch_sample = next(iter(train_dataloader))\n",
        "train_batch_sample = train_batch_sample[0]\n",
        "conv_outputs = Conv(train_batch_sample.float(), prints=True)\n",
        "print(\"final output shape: \", conv_outputs.shape)\n",
        "print(\"final output: \", conv_outputs[0])\n",
        "print(conv_outputs.shape[1])\n",
        "\n",
        "# check pe\n",
        "batch_len = conv_outputs.shape[0]\n",
        "feature_dim = conv_outputs.shape[1]\n",
        "pe = PositionalEncoding(feature_dim, batch_len)\n",
        "pe_out = pe(conv_outputs)\n",
        "print(pe_out[0])\n",
        "print(pe_out.shape)\n",
        "\n",
        "# check transformer"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "before conv 1:  torch.Size([32, 1, 993])\n",
            "after conv & max_pool 1:  torch.Size([32, 16, 125])\n",
            "after conv & max_pool 2:  torch.Size([32, 32, 16])\n",
            "after conv & max_pool 3:  torch.Size([32, 64, 2])\n",
            "flatten last two dims:  torch.Size([32, 128])\n",
            "final output:  torch.Size([32, 64])\n",
            "final output shape:  torch.Size([32, 64])\n",
            "final output:  tensor([-6.2446e-04, -8.5820e-02,  4.1067e-03, -2.8668e-01,  4.3354e-01,\n",
            "         1.2378e-01, -8.0052e-02, -5.4131e-01, -7.2685e-01, -5.0350e-01,\n",
            "        -3.9273e-02, -4.2669e-01,  1.6611e-01,  4.9734e-01, -4.8735e-02,\n",
            "        -2.8986e-01, -1.8850e-01, -7.3890e-01,  2.4621e-01,  1.5182e-01,\n",
            "         5.0645e-01,  2.8820e-01,  2.6753e-01, -3.2872e-01, -2.4092e-01,\n",
            "         1.5652e-01,  6.0274e-01,  3.5113e-02,  5.3187e-01,  4.9030e-01,\n",
            "         2.4801e-02, -3.1241e-01,  1.0545e-01, -4.1399e-01,  4.4360e-01,\n",
            "         2.9593e-01, -1.1661e-01, -3.7843e-02, -7.0217e-01, -2.8671e-01,\n",
            "        -5.2176e-01,  1.3424e-01,  2.0693e-01,  1.7290e-02,  2.0763e-01,\n",
            "        -2.7005e-01,  2.9260e-01, -7.9096e-01,  2.4019e-01, -5.3623e-01,\n",
            "        -8.0667e-01,  1.3766e-02, -1.9722e-01, -2.8449e-01, -2.0607e-01,\n",
            "         2.7974e-01,  4.0466e-01, -6.8216e-02,  7.9201e-01, -2.6440e-01,\n",
            "         4.1221e-01,  1.7007e-01, -5.6338e-01, -5.6949e-01],\n",
            "       grad_fn=<SelectBackward>)\n",
            "64\n",
            "tensor([-6.2446e-04,  9.1418e-01,  6.8567e-01,  4.4508e-01,  1.3357e+00,\n",
            "         5.5525e-01,  8.7358e-01, -2.4034e-01,  2.2673e-01, -2.0236e-01,\n",
            "         8.8748e-01, -5.1027e-02,  1.0419e+00,  9.8012e-01,  7.5495e-01,\n",
            "         3.0519e-01,  5.2885e-01, -4.2197e-02,  8.7103e-01,  9.3258e-01,\n",
            "         1.0396e+00,  1.1342e+00,  7.1494e-01,  5.6561e-01,  1.2951e-01,\n",
            "         1.0854e+00,  9.0616e-01,  9.8797e-01,  7.7827e-01,  1.4595e+00,\n",
            "         2.2350e-01,  6.6765e-01,  2.6476e-01,  5.7324e-01,  5.7074e-01,\n",
            "         1.2878e+00, -1.5557e-02,  9.5704e-01, -6.2213e-01,  7.1008e-01,\n",
            "        -4.5856e-01,  1.1322e+00,  2.5671e-01,  1.0161e+00,  2.4674e-01,\n",
            "         7.2918e-01,  3.2327e-01,  2.0857e-01,  2.6419e-01,  4.6348e-01,\n",
            "        -7.8792e-01,  1.0136e+00, -1.8260e-01,  7.1540e-01, -1.9469e-01,\n",
            "         1.2797e+00,  4.1351e-01,  9.3174e-01,  7.9889e-01,  7.3557e-01,\n",
            "         4.1755e-01,  1.1701e+00, -5.5925e-01,  4.3050e-01],\n",
            "       grad_fn=<SelectBackward>)\n",
            "torch.Size([32, 64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wM_NRmwNpoyl",
        "outputId": "f1225c78-ce5f-4ded-953d-ace290cd15c8"
      },
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # default lr: 5e-3\n",
        "\n",
        "data_dict ={}\n",
        "best_loss = 1000\n",
        "best_epoch = 0\n",
        "model.train()\n",
        "\n",
        "for epoch in range(EPOCH):\n",
        "    print(\"epoch: \", epoch)\n",
        "    losses = []\n",
        "    for i, data in enumerate(train_dataloader):\n",
        "        features = data[0].to(DEVICE).float()\n",
        "        features = features.unsqueeze(0)\n",
        "        # print(\"imu shape: \", imu_features.shape)\n",
        "        x = data[1].to(DEVICE).float().unsqueeze(-1)\n",
        "        # print(\"x shape: \", x.shape)\n",
        "        y = data[2].to(DEVICE).float().unsqueeze(-1)\n",
        "        # print(\"y shape: \", y.shape)\n",
        "\n",
        "        output = model(features, prints=False)\n",
        "        # print(\"output\", output)\n",
        "        # print(\"output shape after concat: \", output.shape)\n",
        "        label = torch.cat([x, y], dim=-1)\n",
        "        # print(\"label\", label)\n",
        "        # print(\"label shape after concat: \", label.shape)\n",
        "        loss = criterion(output, label)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        losses.append(loss.item())\n",
        "        print(f\"loss:{np.mean(losses)} at iteration {i}\")\n",
        "\n",
        "print(\"Training finished\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:  0\n",
            "loss:14748.9716796875 at iteration 0\n",
            "loss:19016.71044921875 at iteration 1\n",
            "loss:20250.814127604168 at iteration 2\n",
            "loss:23082.885009765625 at iteration 3\n",
            "loss:21894.2283203125 at iteration 4\n",
            "loss:21164.056477864582 at iteration 5\n",
            "loss:23928.5478515625 at iteration 6\n",
            "loss:25268.248901367188 at iteration 7\n",
            "loss:24184.995659722223 at iteration 8\n",
            "loss:23305.26318359375 at iteration 9\n",
            "loss:23391.090287642044 at iteration 10\n",
            "loss:23031.801025390625 at iteration 11\n",
            "loss:22651.561072716348 at iteration 12\n",
            "loss:22653.868094308036 at iteration 13\n",
            "loss:22370.650455729166 at iteration 14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([32, 2])) that is different to the input size (torch.Size([1, 32, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss:22248.645446777344 at iteration 15\n",
            "loss:22196.848517922794 at iteration 16\n",
            "loss:22257.37060546875 at iteration 17\n",
            "loss:22668.483604029607 at iteration 18\n",
            "loss:22784.686181640624 at iteration 19\n",
            "loss:22536.874116443454 at iteration 20\n",
            "loss:22330.594859730114 at iteration 21\n",
            "loss:22617.75972316576 at iteration 22\n",
            "loss:22760.234415690105 at iteration 23\n",
            "loss:22393.765 at iteration 24\n",
            "loss:22455.152869591348 at iteration 25\n",
            "loss:22502.03146701389 at iteration 26\n",
            "loss:22327.60518973214 at iteration 27\n",
            "loss:22379.23114224138 at iteration 28\n",
            "loss:22215.886783854166 at iteration 29\n",
            "loss:22412.95425907258 at iteration 30\n",
            "loss:22676.427612304688 at iteration 31\n",
            "loss:22810.536280776516 at iteration 32\n",
            "loss:22826.026137408087 at iteration 33\n",
            "loss:22828.847544642857 at iteration 34\n",
            "loss:22928.60910373264 at iteration 35\n",
            "loss:22767.72994087838 at iteration 36\n",
            "loss:22947.195929276317 at iteration 37\n",
            "loss:23043.05659054487 at iteration 38\n",
            "loss:23304.0626953125 at iteration 39\n",
            "loss:23413.725752667684 at iteration 40\n",
            "loss:23524.38732328869 at iteration 41\n",
            "loss:23448.738099563954 at iteration 42\n",
            "loss:23756.41095525568 at iteration 43\n",
            "loss:23738.336024305554 at iteration 44\n",
            "loss:23647.91117527174 at iteration 45\n",
            "loss:23656.961145279256 at iteration 46\n",
            "loss:23719.965291341145 at iteration 47\n",
            "loss:23969.970703125 at iteration 48\n",
            "loss:23860.1780859375 at iteration 49\n",
            "loss:23723.004289215685 at iteration 50\n",
            "loss:23647.612530048078 at iteration 51\n",
            "loss:23683.46064268868 at iteration 52\n",
            "loss:23899.81228298611 at iteration 53\n",
            "loss:23805.91924715909 at iteration 54\n",
            "loss:23697.98503766741 at iteration 55\n",
            "loss:23643.236979166668 at iteration 56\n",
            "loss:23631.851192079743 at iteration 57\n",
            "loss:23536.916909427968 at iteration 58\n",
            "loss:23595.074739583335 at iteration 59\n",
            "loss:23587.867667776638 at iteration 60\n",
            "loss:23322.02667433216 at iteration 61\n",
            "loss:23049.55714440724 at iteration 62\n",
            "loss:22748.048049926758 at iteration 63\n",
            "loss:22489.5900390625 at iteration 64\n",
            "loss:22201.17745694247 at iteration 65\n",
            "loss:21963.096355381298 at iteration 66\n",
            "loss:21713.4946827608 at iteration 67\n",
            "loss:21455.342002094654 at iteration 68\n",
            "loss:21199.401513671874 at iteration 69\n",
            "loss:20989.266065140844 at iteration 70\n",
            "loss:20809.03867594401 at iteration 71\n",
            "loss:20586.470268354024 at iteration 72\n",
            "loss:20375.778102565455 at iteration 73\n",
            "loss:20185.409231770835 at iteration 74\n",
            "loss:19979.3788098787 at iteration 75\n",
            "loss:19779.748103946833 at iteration 76\n",
            "loss:19618.169878054887 at iteration 77\n",
            "loss:19425.22084528283 at iteration 78\n",
            "loss:19260.957611083984 at iteration 79\n",
            "loss:19071.68179132909 at iteration 80\n",
            "loss:18906.036454363566 at iteration 81\n",
            "loss:18728.381753576807 at iteration 82\n",
            "loss:18563.194405691964 at iteration 83\n",
            "loss:18389.924678308824 at iteration 84\n",
            "loss:18266.053972111193 at iteration 85\n",
            "loss:18121.797660739943 at iteration 86\n",
            "loss:17997.203152743252 at iteration 87\n",
            "loss:17930.49081043715 at iteration 88\n",
            "loss:17806.73148871528 at iteration 89\n",
            "loss:17677.606917496567 at iteration 90\n",
            "loss:17538.717237389606 at iteration 91\n",
            "loss:17413.273589759745 at iteration 92\n",
            "loss:17299.775312707778 at iteration 93\n",
            "loss:17179.703489925985 at iteration 94\n",
            "loss:17065.04751586914 at iteration 95\n",
            "loss:16937.47545002416 at iteration 96\n",
            "loss:16839.224081234057 at iteration 97\n",
            "loss:16703.95029888731 at iteration 98\n",
            "loss:16579.335327148438 at iteration 99\n",
            "loss:16446.217867709624 at iteration 100\n",
            "loss:16349.738977768842 at iteration 101\n",
            "loss:16259.535390909436 at iteration 102\n",
            "loss:16175.569629375752 at iteration 103\n",
            "loss:16099.2633765811 at iteration 104\n",
            "loss:15982.08894089033 at iteration 105\n",
            "loss:15891.312614084403 at iteration 106\n",
            "loss:15777.448531539352 at iteration 107\n",
            "loss:15689.448864858085 at iteration 108\n",
            "loss:15596.512824041192 at iteration 109\n",
            "loss:15521.949297930743 at iteration 110\n",
            "loss:15441.156215122768 at iteration 111\n",
            "loss:15356.926788060011 at iteration 112\n",
            "loss:15365.057321648848 at iteration 113\n",
            "loss:15384.487190047554 at iteration 114\n",
            "loss:15372.745365537447 at iteration 115\n",
            "loss:15350.655778412127 at iteration 116\n",
            "loss:15309.695705607786 at iteration 117\n",
            "loss:15267.232926569066 at iteration 118\n",
            "loss:15255.968933105469 at iteration 119\n",
            "loss:15269.300623870093 at iteration 120\n",
            "loss:15239.03167824667 at iteration 121\n",
            "loss:15224.18578109121 at iteration 122\n",
            "loss:15243.29595750378 at iteration 123\n",
            "loss:15291.77999609375 at iteration 124\n",
            "loss:15333.232045975943 at iteration 125\n",
            "loss:15366.010238527313 at iteration 126\n",
            "loss:15360.986492156982 at iteration 127\n",
            "loss:15335.444347292878 at iteration 128\n",
            "loss:15359.153248948318 at iteration 129\n",
            "loss:15333.384754442986 at iteration 130\n",
            "loss:15321.945190429688 at iteration 131\n",
            "loss:15281.681093603149 at iteration 132\n",
            "loss:15289.85839479361 at iteration 133\n",
            "loss:15302.66120876736 at iteration 134\n",
            "loss:15289.923415240119 at iteration 135\n",
            "loss:15277.348736171305 at iteration 136\n",
            "loss:15270.459681414175 at iteration 137\n",
            "loss:15272.835238449865 at iteration 138\n",
            "loss:15243.967044503348 at iteration 139\n",
            "loss:15213.681367048981 at iteration 140\n",
            "loss:15217.641598123899 at iteration 141\n",
            "loss:15222.367388958697 at iteration 142\n",
            "loss:15221.512244330512 at iteration 143\n",
            "loss:15202.86224070582 at iteration 144\n",
            "loss:15176.908808459973 at iteration 145\n",
            "loss:15168.555687313989 at iteration 146\n",
            "loss:15150.128282701648 at iteration 147\n",
            "loss:15162.635509516569 at iteration 148\n",
            "loss:15181.668929036457 at iteration 149\n",
            "loss:15187.50834605236 at iteration 150\n",
            "loss:15167.577652780634 at iteration 151\n",
            "loss:15173.805214077818 at iteration 152\n",
            "loss:15174.407997032265 at iteration 153\n",
            "loss:15150.196046496976 at iteration 154\n",
            "loss:15157.769440479768 at iteration 155\n",
            "loss:15189.590972706012 at iteration 156\n",
            "loss:15191.505800657635 at iteration 157\n",
            "loss:15177.825388782428 at iteration 158\n",
            "loss:15163.206265258788 at iteration 159\n",
            "loss:15181.32726671681 at iteration 160\n",
            "loss:15189.8905918451 at iteration 161\n",
            "loss:15189.236355085315 at iteration 162\n",
            "loss:15201.044531845466 at iteration 163\n",
            "loss:15177.366231652462 at iteration 164\n",
            "loss:15170.009850927147 at iteration 165\n",
            "loss:15183.181666939558 at iteration 166\n",
            "loss:15187.444612048921 at iteration 167\n",
            "loss:15160.826902852255 at iteration 168\n",
            "loss:15119.827682674633 at iteration 169\n",
            "loss:15084.283311631945 at iteration 170\n",
            "loss:15066.849473110466 at iteration 171\n",
            "loss:15047.638186416185 at iteration 172\n",
            "loss:15035.036935389728 at iteration 173\n",
            "loss:15019.139441964286 at iteration 174\n",
            "loss:14992.80557528409 at iteration 175\n",
            "loss:14972.864053672316 at iteration 176\n",
            "loss:14964.765290335323 at iteration 177\n",
            "loss:14955.606248908869 at iteration 178\n",
            "loss:14944.599289279515 at iteration 179\n",
            "loss:14943.645696650552 at iteration 180\n",
            "loss:14938.521098042582 at iteration 181\n",
            "loss:14887.23713925888 at iteration 182\n",
            "loss:14831.493023416271 at iteration 183\n",
            "loss:14776.050129328547 at iteration 184\n",
            "loss:14725.831611223119 at iteration 185\n",
            "loss:14657.383257697611 at iteration 186\n",
            "loss:14594.237992956283 at iteration 187\n",
            "loss:14551.79925698578 at iteration 188\n",
            "loss:14519.144932154606 at iteration 189\n",
            "loss:14475.585075977586 at iteration 190\n",
            "loss:14419.275969187418 at iteration 191\n",
            "loss:14378.55924774328 at iteration 192\n",
            "loss:14337.11502421271 at iteration 193\n",
            "loss:14273.73164813702 at iteration 194\n",
            "loss:14225.617252272003 at iteration 195\n",
            "loss:14174.237963991116 at iteration 196\n",
            "loss:14116.53225492227 at iteration 197\n",
            "loss:14064.045191779209 at iteration 198\n",
            "loss:14018.045305175781 at iteration 199\n",
            "loss:13968.022771882774 at iteration 200\n",
            "loss:13931.89542079208 at iteration 201\n",
            "loss:13879.476288292795 at iteration 202\n",
            "loss:13820.645905737783 at iteration 203\n",
            "loss:13765.515065858423 at iteration 204\n",
            "loss:13723.06051665371 at iteration 205\n",
            "loss:13675.227208234262 at iteration 206\n",
            "loss:13622.07505622277 at iteration 207\n",
            "loss:13574.946737043025 at iteration 208\n",
            "loss:13521.933026994977 at iteration 209\n",
            "loss:13490.995700926578 at iteration 210\n",
            "loss:13443.79143193083 at iteration 211\n",
            "loss:13397.640050180642 at iteration 212\n",
            "loss:13344.382351599006 at iteration 213\n",
            "loss:13302.759022983284 at iteration 214\n",
            "loss:13254.368643301505 at iteration 215\n",
            "loss:13220.600963961693 at iteration 216\n",
            "loss:13178.946569040281 at iteration 217\n",
            "loss:13141.511382081193 at iteration 218\n",
            "loss:13107.386554509943 at iteration 219\n",
            "loss:13060.17519133555 at iteration 220\n",
            "loss:13011.29203067814 at iteration 221\n",
            "loss:12969.295879825882 at iteration 222\n",
            "loss:12923.332511901855 at iteration 223\n",
            "loss:12879.555477430555 at iteration 224\n",
            "loss:12846.997921563883 at iteration 225\n",
            "loss:12805.371949855451 at iteration 226\n",
            "loss:12773.56614069353 at iteration 227\n",
            "loss:12731.179149111285 at iteration 228\n",
            "loss:12683.356655485733 at iteration 229\n",
            "loss:12644.905535545184 at iteration 230\n",
            "loss:12608.562209556843 at iteration 231\n",
            "loss:12572.632213150482 at iteration 232\n",
            "loss:12525.520003359541 at iteration 233\n",
            "loss:12475.802845796627 at iteration 234\n",
            "loss:12428.27431707867 at iteration 235\n",
            "loss:12387.873833121126 at iteration 236\n",
            "loss:12356.934803425765 at iteration 237\n",
            "loss:12329.877079025971 at iteration 238\n",
            "loss:12286.483503977457 at iteration 239\n",
            "loss:12250.289488733062 at iteration 240\n",
            "loss:12215.983128823525 at iteration 241\n",
            "loss:12170.545747482238 at iteration 242\n",
            "loss:12125.45385216885 at iteration 243\n",
            "loss:12093.19736801459 at iteration 244\n",
            "loss:12067.824626395373 at iteration 245\n",
            "loss:12040.996827901616 at iteration 246\n",
            "loss:12012.713328453803 at iteration 247\n",
            "loss:11979.077774721934 at iteration 248\n",
            "loss:11940.544072998047 at iteration 249\n",
            "loss:11901.765658800345 at iteration 250\n",
            "loss:11869.682215857127 at iteration 251\n",
            "loss:11837.904913257704 at iteration 252\n",
            "loss:11797.596523735467 at iteration 253\n",
            "loss:11764.818850289139 at iteration 254\n",
            "loss:11728.54750418663 at iteration 255\n",
            "loss:11690.574978483326 at iteration 256\n",
            "loss:11661.360230201899 at iteration 257\n",
            "loss:11631.18873743477 at iteration 258\n",
            "loss:11601.759684636043 at iteration 259\n",
            "loss:11573.122143040215 at iteration 260\n",
            "loss:11538.835849674604 at iteration 261\n",
            "loss:11512.502344631877 at iteration 262\n",
            "loss:11480.978924144398 at iteration 263\n",
            "loss:11445.090986834832 at iteration 264\n",
            "loss:11407.850190126806 at iteration 265\n",
            "loss:11379.821477197083 at iteration 266\n",
            "loss:11346.158900702178 at iteration 267\n",
            "loss:11321.05952833665 at iteration 268\n",
            "loss:11301.901840775101 at iteration 269\n",
            "loss:11272.236039615645 at iteration 270\n",
            "loss:11244.971006281236 at iteration 271\n",
            "loss:11212.434193593679 at iteration 272\n",
            "loss:11181.399243654127 at iteration 273\n",
            "loss:11155.07829345703 at iteration 274\n",
            "loss:11125.909034397291 at iteration 275\n",
            "loss:11103.323633297256 at iteration 276\n",
            "loss:11082.25229364848 at iteration 277\n",
            "loss:11051.185019872522 at iteration 278\n",
            "loss:11025.57799748012 at iteration 279\n",
            "loss:11008.154098565044 at iteration 280\n",
            "loss:10984.241245350939 at iteration 281\n",
            "loss:10952.764712923406 at iteration 282\n",
            "loss:10922.020542843242 at iteration 283\n",
            "loss:10902.61159089741 at iteration 284\n",
            "loss:10875.8848652873 at iteration 285\n",
            "loss:10850.721874276935 at iteration 286\n",
            "loss:10819.924846437243 at iteration 287\n",
            "loss:10794.25637405554 at iteration 288\n",
            "loss:10775.768803247913 at iteration 289\n",
            "loss:10752.47198108791 at iteration 290\n",
            "epoch:  1\n",
            "loss:9833.6669921875 at iteration 0\n",
            "loss:13288.36865234375 at iteration 1\n",
            "loss:14149.195638020834 at iteration 2\n",
            "loss:16685.120361328125 at iteration 3\n",
            "loss:15592.2966796875 at iteration 4\n",
            "loss:14980.38720703125 at iteration 5\n",
            "loss:17313.830496651786 at iteration 6\n",
            "loss:18418.706665039062 at iteration 7\n",
            "loss:17486.182725694445 at iteration 8\n",
            "loss:16733.830078125 at iteration 9\n",
            "loss:16760.01580255682 at iteration 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([16, 2])) that is different to the input size (torch.Size([1, 16, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss:16430.215006510418 at iteration 11\n",
            "loss:16104.50908954327 at iteration 12\n",
            "loss:16015.648995535714 at iteration 13\n",
            "loss:15739.420768229167 at iteration 14\n",
            "loss:15627.373107910156 at iteration 15\n",
            "loss:15531.55681295956 at iteration 16\n",
            "loss:15570.759494357639 at iteration 17\n",
            "loss:15897.887078536185 at iteration 18\n",
            "loss:15921.6265625 at iteration 19\n",
            "loss:15718.552641369048 at iteration 20\n",
            "loss:15510.034224076704 at iteration 21\n",
            "loss:15682.983823029892 at iteration 22\n",
            "loss:15773.520222981771 at iteration 23\n",
            "loss:15441.43015625 at iteration 24\n",
            "loss:15447.769981971154 at iteration 25\n",
            "loss:15428.52586082176 at iteration 26\n",
            "loss:15250.432547433036 at iteration 27\n",
            "loss:15259.931640625 at iteration 28\n",
            "loss:15107.534733072916 at iteration 29\n",
            "loss:15220.972876764114 at iteration 30\n",
            "loss:15384.814178466797 at iteration 31\n",
            "loss:15442.241447679924 at iteration 32\n",
            "loss:15418.829532398897 at iteration 33\n",
            "loss:15376.7892578125 at iteration 34\n",
            "loss:15427.69251844618 at iteration 35\n",
            "loss:15278.865287162162 at iteration 36\n",
            "loss:15372.465357730263 at iteration 37\n",
            "loss:15414.549178685897 at iteration 38\n",
            "loss:15572.974951171875 at iteration 39\n",
            "loss:15618.390672637195 at iteration 40\n",
            "loss:15667.876767113095 at iteration 41\n",
            "loss:15570.478038699128 at iteration 42\n",
            "loss:15772.257124467329 at iteration 43\n",
            "loss:15723.780967881945 at iteration 44\n",
            "loss:15613.31050441576 at iteration 45\n",
            "loss:15563.489611037234 at iteration 46\n",
            "loss:15589.345987955729 at iteration 47\n",
            "loss:15746.838050063776 at iteration 48\n",
            "loss:15640.79876953125 at iteration 49\n",
            "loss:15510.909466911764 at iteration 50\n",
            "loss:15432.088228665865 at iteration 51\n",
            "loss:15425.575305866745 at iteration 52\n",
            "loss:15554.952021846066 at iteration 53\n",
            "loss:15456.014044744317 at iteration 54\n",
            "loss:15333.464686802456 at iteration 55\n",
            "loss:15257.343852796053 at iteration 56\n",
            "loss:15203.033826104525 at iteration 57\n",
            "loss:15095.857123940677 at iteration 58\n",
            "loss:15099.881868489583 at iteration 59\n",
            "loss:15054.272685066599 at iteration 60\n",
            "loss:14851.815862840222 at iteration 61\n",
            "loss:14645.633802625867 at iteration 62\n",
            "loss:14426.82790184021 at iteration 63\n",
            "loss:14230.009775015023 at iteration 64\n",
            "loss:14023.437784830729 at iteration 65\n",
            "loss:13837.968864782533 at iteration 66\n",
            "loss:13651.277722526998 at iteration 67\n",
            "loss:13463.289052769758 at iteration 68\n",
            "loss:13284.217737688337 at iteration 69\n",
            "loss:13136.62657058071 at iteration 70\n",
            "loss:12985.528451707629 at iteration 71\n",
            "loss:12821.935445707139 at iteration 72\n",
            "loss:12667.754294730521 at iteration 73\n",
            "loss:12520.051534016928 at iteration 74\n",
            "loss:12371.545187699166 at iteration 75\n",
            "loss:12227.846862792969 at iteration 76\n",
            "loss:12101.146856063451 at iteration 77\n",
            "loss:11962.32583115976 at iteration 78\n",
            "loss:11841.497759246826 at iteration 79\n",
            "loss:11706.090706530913 at iteration 80\n",
            "loss:11580.96460928568 at iteration 81\n",
            "loss:11450.307464231928 at iteration 82\n",
            "loss:11322.85527256557 at iteration 83\n",
            "loss:11197.92164665671 at iteration 84\n",
            "loss:11104.84550582531 at iteration 85\n",
            "loss:10999.572264221893 at iteration 86\n",
            "loss:10901.323127053001 at iteration 87\n",
            "loss:10829.624375932672 at iteration 88\n",
            "loss:10731.691746690538 at iteration 89\n",
            "loss:10638.449885441707 at iteration 90\n",
            "loss:10535.434250541355 at iteration 91\n",
            "loss:10439.899954847111 at iteration 92\n",
            "loss:10346.276189276512 at iteration 93\n",
            "loss:10253.171214535361 at iteration 94\n",
            "loss:10164.668445587158 at iteration 95\n",
            "loss:10079.72373978133 at iteration 96\n",
            "loss:10003.864662637516 at iteration 97\n",
            "loss:9910.038130326704 at iteration 98\n",
            "loss:9819.456646118164 at iteration 99\n",
            "loss:9729.38155432975 at iteration 100\n",
            "loss:9651.524293188955 at iteration 101\n",
            "loss:9583.795731331538 at iteration 102\n",
            "loss:9515.960943368766 at iteration 103\n",
            "loss:9449.302479771206 at iteration 104\n",
            "loss:9370.630369942144 at iteration 105\n",
            "loss:9298.001650801329 at iteration 106\n",
            "loss:9223.304859302661 at iteration 107\n",
            "loss:9150.370240377724 at iteration 108\n",
            "loss:9077.744385875356 at iteration 109\n",
            "loss:9013.004004126196 at iteration 110\n",
            "loss:8949.421677725655 at iteration 111\n",
            "loss:8888.16757877316 at iteration 112\n",
            "loss:8874.647134345874 at iteration 113\n",
            "loss:8873.187830120583 at iteration 114\n",
            "loss:8846.553474163187 at iteration 115\n",
            "loss:8811.762660882412 at iteration 116\n",
            "loss:8762.373821711137 at iteration 117\n",
            "loss:8719.963018850118 at iteration 118\n",
            "loss:8703.259819539388 at iteration 119\n",
            "loss:8694.495380496192 at iteration 120\n",
            "loss:8653.271463362897 at iteration 121\n",
            "loss:8625.539295723767 at iteration 122\n",
            "loss:8615.932273618637 at iteration 123\n",
            "loss:8621.353932617187 at iteration 124\n",
            "loss:8634.843838161893 at iteration 125\n",
            "loss:8638.365683247725 at iteration 126\n",
            "loss:8622.224230766296 at iteration 127\n",
            "loss:8596.527111911035 at iteration 128\n",
            "loss:8593.808897047777 at iteration 129\n",
            "loss:8559.473391467378 at iteration 130\n",
            "loss:8530.514264655836 at iteration 131\n",
            "loss:8491.72609349301 at iteration 132\n",
            "loss:8484.230152642549 at iteration 133\n",
            "loss:8475.005842194734 at iteration 134\n",
            "loss:8456.227590224322 at iteration 135\n",
            "loss:8445.952726712192 at iteration 136\n",
            "loss:8430.367489137512 at iteration 137\n",
            "loss:8417.489072511522 at iteration 138\n",
            "loss:8391.018827601842 at iteration 139\n",
            "loss:8358.283243815104 at iteration 140\n",
            "loss:8342.06600995131 at iteration 141\n",
            "loss:8335.041899140899 at iteration 142\n",
            "loss:8333.379539489746 at iteration 143\n",
            "loss:8321.330262493266 at iteration 144\n",
            "loss:8300.945716335349 at iteration 145\n",
            "loss:8289.192707502923 at iteration 146\n",
            "loss:8264.188221699482 at iteration 147\n",
            "loss:8263.000048336567 at iteration 148\n",
            "loss:8261.980881347656 at iteration 149\n",
            "loss:8257.731861645023 at iteration 150\n",
            "loss:8239.899181968287 at iteration 151\n",
            "loss:8233.098363938674 at iteration 152\n",
            "loss:8222.927153352019 at iteration 153\n",
            "loss:8204.41498157132 at iteration 154\n",
            "loss:8189.011771177634 at iteration 155\n",
            "loss:8195.12696789784 at iteration 156\n",
            "loss:8182.941569267949 at iteration 157\n",
            "loss:8163.442249993858 at iteration 158\n",
            "loss:8135.762523651123 at iteration 159\n",
            "loss:8130.742471825262 at iteration 160\n",
            "loss:8119.649814181857 at iteration 161\n",
            "loss:8102.903142823763 at iteration 162\n",
            "loss:8094.709278385813 at iteration 163\n",
            "loss:8079.171377101089 at iteration 164\n",
            "loss:8071.412329248636 at iteration 165\n",
            "loss:8067.595088387678 at iteration 166\n",
            "loss:8057.631195794968 at iteration 167\n",
            "loss:8032.91609435674 at iteration 168\n",
            "loss:7999.236591653263 at iteration 169\n",
            "loss:7967.665215386285 at iteration 170\n",
            "loss:7942.247262644213 at iteration 171\n",
            "loss:7914.245980146992 at iteration 172\n",
            "loss:7893.365564806708 at iteration 173\n",
            "loss:7869.461522739955 at iteration 174\n",
            "loss:7837.37748371471 at iteration 175\n",
            "loss:7809.674517098119 at iteration 176\n",
            "loss:7788.099472903134 at iteration 177\n",
            "loss:7769.077550110204 at iteration 178\n",
            "loss:7747.021664089627 at iteration 179\n",
            "loss:7730.127277521798 at iteration 180\n",
            "loss:7711.019070468106 at iteration 181\n",
            "loss:7680.18838651063 at iteration 182\n",
            "loss:7646.457674772843 at iteration 183\n",
            "loss:7614.6847550675675 at iteration 184\n",
            "loss:7579.466905163181 at iteration 185\n",
            "loss:7541.437243782901 at iteration 186\n",
            "loss:7506.812478897419 at iteration 187\n",
            "loss:7477.451347875847 at iteration 188\n",
            "loss:7448.487007542661 at iteration 189\n",
            "loss:7414.214331502066 at iteration 190\n",
            "loss:7381.598278363545 at iteration 191\n",
            "loss:7351.3190522663335 at iteration 192\n",
            "loss:7319.6959917520735 at iteration 193\n",
            "loss:7284.445433005309 at iteration 194\n",
            "loss:7251.407932515047 at iteration 195\n",
            "loss:7217.081163435418 at iteration 196\n",
            "loss:7186.421133638632 at iteration 197\n",
            "loss:7153.462496503514 at iteration 198\n",
            "loss:7121.091996765137 at iteration 199\n",
            "loss:7091.56019797254 at iteration 200\n",
            "loss:7063.798931763904 at iteration 201\n",
            "loss:7033.374106721925 at iteration 202\n",
            "loss:7003.612278657801 at iteration 203\n",
            "loss:6975.009945753144 at iteration 204\n",
            "loss:6949.852868830116 at iteration 205\n",
            "loss:6921.242127054556 at iteration 206\n",
            "loss:6893.23775276771 at iteration 207\n",
            "loss:6868.76345080508 at iteration 208\n",
            "loss:6838.8319675990515 at iteration 209\n",
            "loss:6815.497326313037 at iteration 210\n",
            "loss:6791.035503171525 at iteration 211\n",
            "loss:6765.276884983403 at iteration 212\n",
            "loss:6736.940587409189 at iteration 213\n",
            "loss:6712.954043366189 at iteration 214\n",
            "loss:6685.696252328378 at iteration 215\n",
            "loss:6659.639164094002 at iteration 216\n",
            "loss:6633.377149669403 at iteration 217\n",
            "loss:6607.175133552725 at iteration 218\n",
            "loss:6581.49213589755 at iteration 219\n",
            "loss:6557.745181812959 at iteration 220\n",
            "loss:6531.439652726457 at iteration 221\n",
            "loss:6509.77084501121 at iteration 222\n",
            "loss:6486.876385280064 at iteration 223\n",
            "loss:6463.147493489583 at iteration 224\n",
            "loss:6439.327097664892 at iteration 225\n",
            "loss:6415.393071783797 at iteration 226\n",
            "loss:6391.966731556675 at iteration 227\n",
            "loss:6368.07413319417 at iteration 228\n",
            "loss:6343.219091531505 at iteration 229\n",
            "loss:6323.234218845119 at iteration 230\n",
            "loss:6304.885180506213 at iteration 231\n",
            "loss:6285.288654114555 at iteration 232\n",
            "loss:6261.699354122847 at iteration 233\n",
            "loss:6240.25594170753 at iteration 234\n",
            "loss:6221.032101647328 at iteration 235\n",
            "loss:6202.174869328109 at iteration 236\n",
            "loss:6188.373068160369 at iteration 237\n",
            "loss:6169.475146944054 at iteration 238\n",
            "loss:6146.697463734945 at iteration 239\n",
            "loss:6127.704480183075 at iteration 240\n",
            "loss:6107.8597187641235 at iteration 241\n",
            "loss:6087.532826113603 at iteration 242\n",
            "loss:6066.032063718702 at iteration 243\n",
            "loss:6046.758268146125 at iteration 244\n",
            "loss:6030.89257837311 at iteration 245\n",
            "loss:6011.9309588598335 at iteration 246\n",
            "loss:5996.367223185877 at iteration 247\n",
            "loss:5980.828258591005 at iteration 248\n",
            "loss:5960.520537109375 at iteration 249\n",
            "loss:5942.9217592520545 at iteration 250\n",
            "loss:5929.321656242249 at iteration 251\n",
            "loss:5912.028200654644 at iteration 252\n",
            "loss:5890.718843715397 at iteration 253\n",
            "loss:5869.689180261948 at iteration 254\n",
            "loss:5851.908807754517 at iteration 255\n",
            "loss:5835.250730046966 at iteration 256\n",
            "loss:5818.39315488357 at iteration 257\n",
            "loss:5800.413232044823 at iteration 258\n",
            "loss:5788.930244328425 at iteration 259\n",
            "loss:5775.075200924928 at iteration 260\n",
            "loss:5756.421608728307 at iteration 261\n",
            "loss:5737.681671026542 at iteration 262\n",
            "loss:5721.653502262 at iteration 263\n",
            "loss:5703.58871125995 at iteration 264\n",
            "loss:5684.4013472248735 at iteration 265\n",
            "loss:5667.820480518127 at iteration 266\n",
            "loss:5650.380873950559 at iteration 267\n",
            "loss:5634.605326712796 at iteration 268\n",
            "loss:5619.288591399016 at iteration 269\n",
            "loss:5601.914222407605 at iteration 270\n",
            "loss:5585.423136991613 at iteration 271\n",
            "loss:5566.9752521445025 at iteration 272\n",
            "loss:5549.595963972329 at iteration 273\n",
            "loss:5535.5321668590195 at iteration 274\n",
            "loss:5519.584292867909 at iteration 275\n",
            "loss:5506.1648475839775 at iteration 276\n",
            "loss:5492.867267196984 at iteration 277\n",
            "loss:5476.268505246836 at iteration 278\n",
            "loss:5461.553112357004 at iteration 279\n",
            "loss:5447.190460096474 at iteration 280\n",
            "loss:5432.951633318096 at iteration 281\n",
            "loss:5419.7178226107 at iteration 282\n",
            "loss:5405.85532733756 at iteration 283\n",
            "loss:5392.521862150494 at iteration 284\n",
            "loss:5376.7682492983095 at iteration 285\n",
            "loss:5361.938657541308 at iteration 286\n",
            "loss:5346.7498730553525 at iteration 287\n",
            "loss:5335.6396815950075 at iteration 288\n",
            "loss:5328.686316549367 at iteration 289\n",
            "loss:5317.641767049573 at iteration 290\n",
            "epoch:  2\n",
            "loss:3159.81982421875 at iteration 0\n",
            "loss:5057.824462890625 at iteration 1\n",
            "loss:5691.109049479167 at iteration 2\n",
            "loss:7799.254150390625 at iteration 3\n",
            "loss:7254.67578125 at iteration 4\n",
            "loss:6900.602620442708 at iteration 5\n",
            "loss:8687.718819754464 at iteration 6\n",
            "loss:9450.666931152344 at iteration 7\n",
            "loss:8873.772677951389 at iteration 8\n",
            "loss:8290.517407226562 at iteration 9\n",
            "loss:8302.336758700285 at iteration 10\n",
            "loss:8080.276346842448 at iteration 11\n",
            "loss:7837.719482421875 at iteration 12\n",
            "loss:7725.722917829241 at iteration 13\n",
            "loss:7627.303987630208 at iteration 14\n",
            "loss:7526.257736206055 at iteration 15\n",
            "loss:7501.448859719669 at iteration 16\n",
            "loss:7512.4035237630205 at iteration 17\n",
            "loss:7720.452392578125 at iteration 18\n",
            "loss:7770.454479980469 at iteration 19\n",
            "loss:7668.080857049851 at iteration 20\n",
            "loss:7566.6828280362215 at iteration 21\n",
            "loss:7670.141548488451 at iteration 22\n",
            "loss:7679.566925048828 at iteration 23\n",
            "loss:7469.7543359375 at iteration 24\n",
            "loss:7482.99941781851 at iteration 25\n",
            "loss:7471.080204716435 at iteration 26\n",
            "loss:7375.663800920759 at iteration 27\n",
            "loss:7373.425074084052 at iteration 28\n",
            "loss:7247.824723307292 at iteration 29\n",
            "loss:7293.349373109879 at iteration 30\n",
            "loss:7389.80046081543 at iteration 31\n",
            "loss:7402.893110795455 at iteration 32\n",
            "loss:7385.436020795037 at iteration 33\n",
            "loss:7353.032156808035 at iteration 34\n",
            "loss:7373.700059678819 at iteration 35\n",
            "loss:7277.166180584882 at iteration 36\n",
            "loss:7339.180876079358 at iteration 37\n",
            "loss:7326.870974809695 at iteration 38\n",
            "loss:7435.914459228516 at iteration 39\n",
            "loss:7444.4103408441315 at iteration 40\n",
            "loss:7472.229021344866 at iteration 41\n",
            "loss:7420.898204714753 at iteration 42\n",
            "loss:7571.824568314986 at iteration 43\n",
            "loss:7521.624831814236 at iteration 44\n",
            "loss:7476.9782024881115 at iteration 45\n",
            "loss:7441.581433884641 at iteration 46\n",
            "loss:7458.228154500325 at iteration 47\n",
            "loss:7553.885667450574 at iteration 48\n",
            "loss:7492.6068505859375 at iteration 49\n",
            "loss:7407.017827052696 at iteration 50\n",
            "loss:7376.128248948317 at iteration 51\n",
            "loss:7372.189692659198 at iteration 52\n",
            "loss:7479.858054832176 at iteration 53\n",
            "loss:7427.9142578125 at iteration 54\n",
            "loss:7342.785640171596 at iteration 55\n",
            "loss:7279.383857593201 at iteration 56\n",
            "loss:7229.849920864763 at iteration 57\n",
            "loss:7160.276023735434 at iteration 58\n",
            "loss:7173.458662923177 at iteration 59\n",
            "loss:7145.839015272797 at iteration 60\n",
            "loss:7069.24468797253 at iteration 61\n",
            "loss:6982.157712906126 at iteration 62\n",
            "loss:6898.690134048462 at iteration 63\n",
            "loss:6816.914240910457 at iteration 64\n",
            "loss:6739.8324566465435 at iteration 65\n",
            "loss:6659.02317696187 at iteration 66\n",
            "loss:6585.403108484605 at iteration 67\n",
            "loss:6522.113613847373 at iteration 68\n",
            "loss:6468.101569475446 at iteration 69\n",
            "loss:6422.539371974031 at iteration 70\n",
            "loss:6346.915713840061 at iteration 71\n",
            "loss:6289.895915828339 at iteration 72\n",
            "loss:6234.635679502745 at iteration 73\n",
            "loss:6175.096311848958 at iteration 74\n",
            "loss:6114.179061086555 at iteration 75\n",
            "loss:6060.272814465808 at iteration 76\n",
            "loss:6004.650897686298 at iteration 77\n",
            "loss:5959.683229084257 at iteration 78\n",
            "loss:5918.388458251953 at iteration 79\n",
            "loss:5871.663426528742 at iteration 80\n",
            "loss:5819.002221084223 at iteration 81\n",
            "loss:5767.435358621988 at iteration 82\n",
            "loss:5721.249097551618 at iteration 83\n",
            "loss:5672.700132123162 at iteration 84\n",
            "loss:5633.925627952398 at iteration 85\n",
            "loss:5596.232960668103 at iteration 86\n",
            "loss:5556.07060657848 at iteration 87\n",
            "loss:5502.049420646067 at iteration 88\n",
            "loss:5454.147641330295 at iteration 89\n",
            "loss:5420.141452663547 at iteration 90\n",
            "loss:5375.050984258237 at iteration 91\n",
            "loss:5343.509186775454 at iteration 92\n",
            "loss:5298.35584275266 at iteration 93\n",
            "loss:5256.297390265214 at iteration 94\n",
            "loss:5219.0737380981445 at iteration 95\n",
            "loss:5190.272800720844 at iteration 96\n",
            "loss:5160.758268395249 at iteration 97\n",
            "loss:5125.637927122791 at iteration 98\n",
            "loss:5083.173165893555 at iteration 99\n",
            "loss:5057.800809652498 at iteration 100\n",
            "loss:5023.1805306228935 at iteration 101\n",
            "loss:4997.202412133078 at iteration 102\n",
            "loss:4965.036040672889 at iteration 103\n",
            "loss:4926.805904715402 at iteration 104\n",
            "loss:4904.834632729584 at iteration 105\n",
            "loss:4869.59555367443 at iteration 106\n",
            "loss:4848.569309941045 at iteration 107\n",
            "loss:4809.809798214414 at iteration 108\n",
            "loss:4778.133023903587 at iteration 109\n",
            "loss:4740.944994677295 at iteration 110\n",
            "loss:4709.650198800223 at iteration 111\n",
            "loss:4689.119203280558 at iteration 112\n",
            "loss:4686.85045530085 at iteration 113\n",
            "loss:4692.84239342731 at iteration 114\n",
            "loss:4668.433917867726 at iteration 115\n",
            "loss:4645.060280824319 at iteration 116\n",
            "loss:4616.50820664228 at iteration 117\n",
            "loss:4595.866335059414 at iteration 118\n",
            "loss:4594.070378621419 at iteration 119\n",
            "loss:4586.053613079481 at iteration 120\n",
            "loss:4558.271124167521 at iteration 121\n",
            "loss:4534.695727340574 at iteration 122\n",
            "loss:4524.922644830519 at iteration 123\n",
            "loss:4536.678462890625 at iteration 124\n",
            "loss:4550.491472516741 at iteration 125\n",
            "loss:4553.235118956078 at iteration 126\n",
            "loss:4549.371189117432 at iteration 127\n",
            "loss:4544.576408445373 at iteration 128\n",
            "loss:4548.271610201322 at iteration 129\n",
            "loss:4525.027978329258 at iteration 130\n",
            "loss:4506.611334598426 at iteration 131\n",
            "loss:4485.369400368597 at iteration 132\n",
            "loss:4476.399855884153 at iteration 133\n",
            "loss:4475.970356807003 at iteration 134\n",
            "loss:4468.628312952378 at iteration 135\n",
            "loss:4475.391144467097 at iteration 136\n",
            "loss:4466.175888282665 at iteration 137\n",
            "loss:4463.280374430924 at iteration 138\n",
            "loss:4456.730910818917 at iteration 139\n",
            "loss:4442.870339684452 at iteration 140\n",
            "loss:4433.507118762379 at iteration 141\n",
            "loss:4432.044458349268 at iteration 142\n",
            "loss:4442.962026807997 at iteration 143\n",
            "loss:4452.270700599407 at iteration 144\n",
            "loss:4445.961411567583 at iteration 145\n",
            "loss:4450.353352034173 at iteration 146\n",
            "loss:4437.47412191855 at iteration 147\n",
            "loss:4441.890674975094 at iteration 148\n",
            "loss:4436.563189290365 at iteration 149\n",
            "loss:4434.0096855921465 at iteration 150\n",
            "loss:4431.1335778487355 at iteration 151\n",
            "loss:4428.709993649152 at iteration 152\n",
            "loss:4429.377670486252 at iteration 153\n",
            "loss:4427.694557239163 at iteration 154\n",
            "loss:4421.957661164112 at iteration 155\n",
            "loss:4423.106287476364 at iteration 156\n",
            "loss:4419.448137886917 at iteration 157\n",
            "loss:4409.5985414517 at iteration 158\n",
            "loss:4391.314260864257 at iteration 159\n",
            "loss:4385.758770865683 at iteration 160\n",
            "loss:4377.615593050733 at iteration 161\n",
            "loss:4367.5471356163725 at iteration 162\n",
            "loss:4360.271106254764 at iteration 163\n",
            "loss:4357.979959753788 at iteration 164\n",
            "loss:4366.621405544051 at iteration 165\n",
            "loss:4362.742547132298 at iteration 166\n",
            "loss:4361.26268078032 at iteration 167\n",
            "loss:4351.302342883228 at iteration 168\n",
            "loss:4334.6833058076745 at iteration 169\n",
            "loss:4316.112668042992 at iteration 170\n",
            "loss:4302.759487418241 at iteration 171\n",
            "loss:4286.514215193732 at iteration 172\n",
            "loss:4276.618540095187 at iteration 173\n",
            "loss:4260.18096749442 at iteration 174\n",
            "loss:4242.719220941717 at iteration 175\n",
            "loss:4227.335037490069 at iteration 176\n",
            "loss:4212.5601806640625 at iteration 177\n",
            "loss:4204.31833618846 at iteration 178\n",
            "loss:4190.5492112901475 at iteration 179\n",
            "loss:4182.971554919501 at iteration 180\n",
            "loss:4174.079126378992 at iteration 181\n",
            "loss:4170.838006024804 at iteration 182\n",
            "loss:4162.896297952403 at iteration 183\n",
            "loss:4154.74439202386 at iteration 184\n",
            "loss:4140.657586210517 at iteration 185\n",
            "loss:4131.027330694352 at iteration 186\n",
            "loss:4121.979232463431 at iteration 187\n",
            "loss:4111.178271742725 at iteration 188\n",
            "loss:4095.1342053865133 at iteration 189\n",
            "loss:4080.7403762577715 at iteration 190\n",
            "loss:4069.2100989023843 at iteration 191\n",
            "loss:4056.0784994332903 at iteration 192\n",
            "loss:4039.418289027263 at iteration 193\n",
            "loss:4029.635524964944 at iteration 194\n",
            "loss:4016.5267931879785 at iteration 195\n",
            "loss:4001.437889757495 at iteration 196\n",
            "loss:3995.6837768554688 at iteration 197\n",
            "loss:3981.422190297189 at iteration 198\n",
            "loss:3966.5605462646486 at iteration 199\n",
            "loss:3958.2823838570816 at iteration 200\n",
            "loss:3944.40537677425 at iteration 201\n",
            "loss:3936.0862712390317 at iteration 202\n",
            "loss:3926.9521681841684 at iteration 203\n",
            "loss:3914.9789324504573 at iteration 204\n",
            "loss:3908.1236382641837 at iteration 205\n",
            "loss:3897.6883049564085 at iteration 206\n",
            "loss:3890.3977831326997 at iteration 207\n",
            "loss:3886.3664615028783 at iteration 208\n",
            "loss:3876.1559035528276 at iteration 209\n",
            "loss:3862.7904521345527 at iteration 210\n",
            "loss:3859.282076853626 at iteration 211\n",
            "loss:3850.972585185593 at iteration 212\n",
            "loss:3840.641442985178 at iteration 213\n",
            "loss:3833.8750181686046 at iteration 214\n",
            "loss:3827.240306712963 at iteration 215\n",
            "loss:3812.841207899806 at iteration 216\n",
            "loss:3800.2354282764118 at iteration 217\n",
            "loss:3787.4036720310714 at iteration 218\n",
            "loss:3773.1184609153056 at iteration 219\n",
            "loss:3767.3325001988474 at iteration 220\n",
            "loss:3757.7213195250915 at iteration 221\n",
            "loss:3748.3090043003785 at iteration 222\n",
            "loss:3742.190755571638 at iteration 223\n",
            "loss:3732.7895703125 at iteration 224\n",
            "loss:3721.4850669118155 at iteration 225\n",
            "loss:3712.7323600332115 at iteration 226\n",
            "loss:3698.9104734721936 at iteration 227\n",
            "loss:3690.464124388049 at iteration 228\n",
            "loss:3680.4046315068786 at iteration 229\n",
            "loss:3675.0129671963778 at iteration 230\n",
            "loss:3671.1991548209353 at iteration 231\n",
            "loss:3664.6185069595795 at iteration 232\n",
            "loss:3655.5690179808525 at iteration 233\n",
            "loss:3654.0136710958277 at iteration 234\n",
            "loss:3651.483329385014 at iteration 235\n",
            "loss:3647.4924370488034 at iteration 236\n",
            "loss:3648.5291801901426 at iteration 237\n",
            "loss:3640.116316408293 at iteration 238\n",
            "loss:3632.4358512878416 at iteration 239\n",
            "loss:3625.6578847798073 at iteration 240\n",
            "loss:3618.0170689102047 at iteration 241\n",
            "loss:3614.280798138905 at iteration 242\n",
            "loss:3608.1669243984534 at iteration 243\n",
            "loss:3598.2036553830517 at iteration 244\n",
            "loss:3589.7674443934993 at iteration 245\n",
            "loss:3579.5181200282295 at iteration 246\n",
            "loss:3574.129751143917 at iteration 247\n",
            "loss:3570.9982226268353 at iteration 248\n",
            "loss:3563.887467529297 at iteration 249\n",
            "loss:3560.2350877252707 at iteration 250\n",
            "loss:3557.68241058834 at iteration 251\n",
            "loss:3549.7471188028812 at iteration 252\n",
            "loss:3540.9342721052994 at iteration 253\n",
            "loss:3529.312520584406 at iteration 254\n",
            "loss:3521.575008392334 at iteration 255\n",
            "loss:3516.3989618798637 at iteration 256\n",
            "loss:3510.0304343053535 at iteration 257\n",
            "loss:3500.80499432538 at iteration 258\n",
            "loss:3500.7439974271333 at iteration 259\n",
            "loss:3496.6134987315913 at iteration 260\n",
            "loss:3487.7975380002085 at iteration 261\n",
            "loss:3477.147368340438 at iteration 262\n",
            "loss:3469.7932921900892 at iteration 263\n",
            "loss:3462.2845019070605 at iteration 264\n",
            "loss:3452.963872923887 at iteration 265\n",
            "loss:3444.3644226302813 at iteration 266\n",
            "loss:3438.120482259722 at iteration 267\n",
            "loss:3430.5690961079085 at iteration 268\n",
            "loss:3421.8160669397425 at iteration 269\n",
            "loss:3413.1992005070197 at iteration 270\n",
            "loss:3404.0354030833523 at iteration 271\n",
            "loss:3395.2495846032225 at iteration 272\n",
            "loss:3386.996357047645 at iteration 273\n",
            "loss:3381.53935768821 at iteration 274\n",
            "loss:3373.428944463315 at iteration 275\n",
            "loss:3366.289966789824 at iteration 276\n",
            "loss:3359.986465563877 at iteration 277\n",
            "loss:3353.2965402910786 at iteration 278\n",
            "loss:3345.3812212262833 at iteration 279\n",
            "loss:3336.513828481219 at iteration 280\n",
            "loss:3330.419171488877 at iteration 281\n",
            "loss:3325.6343897088254 at iteration 282\n",
            "loss:3320.918737492091 at iteration 283\n",
            "loss:3314.4718974866364 at iteration 284\n",
            "loss:3305.9125312858528 at iteration 285\n",
            "loss:3299.5403744368605 at iteration 286\n",
            "loss:3293.649037890964 at iteration 287\n",
            "loss:3290.9140221618864 at iteration 288\n",
            "loss:3291.2806743753367 at iteration 289\n",
            "loss:3288.0849208766244 at iteration 290\n",
            "epoch:  3\n",
            "loss:2650.94921875 at iteration 0\n",
            "loss:4231.356201171875 at iteration 1\n",
            "loss:4687.679036458333 at iteration 2\n",
            "loss:6283.824462890625 at iteration 3\n",
            "loss:5923.5412109375 at iteration 4\n",
            "loss:5552.1352945963545 at iteration 5\n",
            "loss:6995.471156529018 at iteration 6\n",
            "loss:7624.906402587891 at iteration 7\n",
            "loss:7032.148681640625 at iteration 8\n",
            "loss:6564.358715820313 at iteration 9\n",
            "loss:6523.932772549716 at iteration 10\n",
            "loss:6386.464090983073 at iteration 11\n",
            "loss:6175.5631760817305 at iteration 12\n",
            "loss:6117.90509905134 at iteration 13\n",
            "loss:6002.097200520833 at iteration 14\n",
            "loss:5967.492340087891 at iteration 15\n",
            "loss:5922.810834099265 at iteration 16\n",
            "loss:5955.383924696181 at iteration 17\n",
            "loss:6199.5457185444075 at iteration 18\n",
            "loss:6174.938720703125 at iteration 19\n",
            "loss:6133.097121465774 at iteration 20\n",
            "loss:6032.4399525035515 at iteration 21\n",
            "loss:6128.624118970788 at iteration 22\n",
            "loss:6194.311513264974 at iteration 23\n",
            "loss:6040.504052734375 at iteration 24\n",
            "loss:6089.5657958984375 at iteration 25\n",
            "loss:6079.675338179977 at iteration 26\n",
            "loss:5955.81107875279 at iteration 27\n",
            "loss:5938.384639345366 at iteration 28\n",
            "loss:5843.759749348958 at iteration 29\n",
            "loss:5864.041582661291 at iteration 30\n",
            "loss:5964.348968505859 at iteration 31\n",
            "loss:5983.974076704545 at iteration 32\n",
            "loss:5957.595645680147 at iteration 33\n",
            "loss:5941.26962890625 at iteration 34\n",
            "loss:5941.959567599826 at iteration 35\n",
            "loss:5841.214599609375 at iteration 36\n",
            "loss:5875.518522563733 at iteration 37\n",
            "loss:5902.5726975661055 at iteration 38\n",
            "loss:5988.034796142578 at iteration 39\n",
            "loss:5984.185695741235 at iteration 40\n",
            "loss:6039.2782796223955 at iteration 41\n",
            "loss:5990.797573355741 at iteration 42\n",
            "loss:6102.221407803622 at iteration 43\n",
            "loss:6046.193532986111 at iteration 44\n",
            "loss:5998.704812754755 at iteration 45\n",
            "loss:5982.20233543883 at iteration 46\n",
            "loss:5995.3330078125 at iteration 47\n",
            "loss:6125.120256696428 at iteration 48\n",
            "loss:6079.796381835938 at iteration 49\n",
            "loss:6011.588354970894 at iteration 50\n",
            "loss:5975.9831777719355 at iteration 51\n",
            "loss:5975.644895157724 at iteration 52\n",
            "loss:6044.7844645182295 at iteration 53\n",
            "loss:6014.033358487216 at iteration 54\n",
            "loss:5940.684326171875 at iteration 55\n",
            "loss:5901.156524122807 at iteration 56\n",
            "loss:5865.215765591325 at iteration 57\n",
            "loss:5821.966436871027 at iteration 58\n",
            "loss:5828.902689615886 at iteration 59\n",
            "loss:5793.858410444416 at iteration 60\n",
            "loss:5748.616033738659 at iteration 61\n",
            "loss:5695.061821831598 at iteration 62\n",
            "loss:5638.647041320801 at iteration 63\n",
            "loss:5581.480831204928 at iteration 64\n",
            "loss:5541.02753795277 at iteration 65\n",
            "loss:5486.356376078591 at iteration 66\n",
            "loss:5435.711933809168 at iteration 67\n",
            "loss:5392.6301181074505 at iteration 68\n",
            "loss:5361.47952532087 at iteration 69\n",
            "loss:5355.717132138534 at iteration 70\n",
            "loss:5297.674043443468 at iteration 71\n",
            "loss:5265.874292661066 at iteration 72\n",
            "loss:5232.179573677681 at iteration 73\n",
            "loss:5191.408094075521 at iteration 74\n",
            "loss:5155.796802721526 at iteration 75\n",
            "loss:5120.6656272194605 at iteration 76\n",
            "loss:5083.6010820437705 at iteration 77\n",
            "loss:5044.645802944521 at iteration 78\n",
            "loss:5025.964738464356 at iteration 79\n",
            "loss:4991.994892638407 at iteration 80\n",
            "loss:4964.583342761528 at iteration 81\n",
            "loss:4928.413049169333 at iteration 82\n",
            "loss:4890.188023158482 at iteration 83\n",
            "loss:4862.641489545037 at iteration 84\n",
            "loss:4839.335111396257 at iteration 85\n",
            "loss:4818.830824577945 at iteration 86\n",
            "loss:4797.383411754261 at iteration 87\n",
            "loss:4749.112499108475 at iteration 88\n",
            "loss:4714.778602091471 at iteration 89\n",
            "loss:4695.447592599051 at iteration 90\n",
            "loss:4668.509531767472 at iteration 91\n",
            "loss:4647.650243287446 at iteration 92\n",
            "loss:4612.146442494494 at iteration 93\n",
            "loss:4579.99927368164 at iteration 94\n",
            "loss:4552.155442237854 at iteration 95\n",
            "loss:4545.403069564976 at iteration 96\n",
            "loss:4526.834174642758 at iteration 97\n",
            "loss:4506.157350790621 at iteration 98\n",
            "loss:4480.878782653808 at iteration 99\n",
            "loss:4463.879861963857 at iteration 100\n",
            "loss:4438.018384447285 at iteration 101\n",
            "loss:4421.269374514089 at iteration 102\n",
            "loss:4393.601203038143 at iteration 103\n",
            "loss:4357.93335164388 at iteration 104\n",
            "loss:4347.478572917435 at iteration 105\n",
            "loss:4317.1879480664975 at iteration 106\n",
            "loss:4300.382266291866 at iteration 107\n",
            "loss:4269.704156718123 at iteration 108\n",
            "loss:4244.263420243697 at iteration 109\n",
            "loss:4212.228365786441 at iteration 110\n",
            "loss:4190.666100365775 at iteration 111\n",
            "loss:4171.755314649734 at iteration 112\n",
            "loss:4169.905810707493 at iteration 113\n",
            "loss:4169.950846796451 at iteration 114\n",
            "loss:4152.064412873367 at iteration 115\n",
            "loss:4130.58638274364 at iteration 116\n",
            "loss:4106.396216182386 at iteration 117\n",
            "loss:4087.172840022239 at iteration 118\n",
            "loss:4087.73848546346 at iteration 119\n",
            "loss:4079.287287688452 at iteration 120\n",
            "loss:4052.1493212590453 at iteration 121\n",
            "loss:4030.7646824286235 at iteration 122\n",
            "loss:4020.439666009718 at iteration 123\n",
            "loss:4026.623433837891 at iteration 124\n",
            "loss:4032.186837574792 at iteration 125\n",
            "loss:4033.145754115788 at iteration 126\n",
            "loss:4024.392627954483 at iteration 127\n",
            "loss:4020.416549564332 at iteration 128\n",
            "loss:4020.1320897028995 at iteration 129\n",
            "loss:3999.9245309611315 at iteration 130\n",
            "loss:3982.8683732928653 at iteration 131\n",
            "loss:3965.2800662392065 at iteration 132\n",
            "loss:3953.7229297694876 at iteration 133\n",
            "loss:3950.1781541612413 at iteration 134\n",
            "loss:3946.4799160676844 at iteration 135\n",
            "loss:3955.2761856413235 at iteration 136\n",
            "loss:3947.899377131808 at iteration 137\n",
            "loss:3946.0091493455625 at iteration 138\n",
            "loss:3943.642133658273 at iteration 139\n",
            "loss:3930.7847149355193 at iteration 140\n",
            "loss:3919.150707191145 at iteration 141\n",
            "loss:3921.009216095184 at iteration 142\n",
            "loss:3937.1568741268584 at iteration 143\n",
            "loss:3948.008822947535 at iteration 144\n",
            "loss:3943.261591872124 at iteration 145\n",
            "loss:3948.084486150417 at iteration 146\n",
            "loss:3935.728317879342 at iteration 147\n",
            "loss:3941.299591883717 at iteration 148\n",
            "loss:3944.745895385742 at iteration 149\n",
            "loss:3943.441547115907 at iteration 150\n",
            "loss:3941.1511714332983 at iteration 151\n",
            "loss:3937.3489585327948 at iteration 152\n",
            "loss:3941.4435244473543 at iteration 153\n",
            "loss:3941.2314959126134 at iteration 154\n",
            "loss:3933.0624939356094 at iteration 155\n",
            "loss:3939.1984072156774 at iteration 156\n",
            "loss:3935.4301821551744 at iteration 157\n",
            "loss:3925.4582152936446 at iteration 158\n",
            "loss:3911.3527505874636 at iteration 159\n",
            "loss:3910.817010725507 at iteration 160\n",
            "loss:3901.4999225757742 at iteration 161\n",
            "loss:3886.418989684684 at iteration 162\n",
            "loss:3878.604348717666 at iteration 163\n",
            "loss:3879.862918183298 at iteration 164\n",
            "loss:3886.360602505236 at iteration 165\n",
            "loss:3884.927128591937 at iteration 166\n",
            "loss:3878.8039588928223 at iteration 167\n",
            "loss:3872.2210102871327 at iteration 168\n",
            "loss:3857.820716229607 at iteration 169\n",
            "loss:3841.5195335700496 at iteration 170\n",
            "loss:3826.915791533714 at iteration 171\n",
            "loss:3811.142452703046 at iteration 172\n",
            "loss:3797.497018572928 at iteration 173\n",
            "loss:3785.000964878627 at iteration 174\n",
            "loss:3768.2968828027897 at iteration 175\n",
            "loss:3752.342414295606 at iteration 176\n",
            "loss:3739.2095798106675 at iteration 177\n",
            "loss:3731.181404838349 at iteration 178\n",
            "loss:3717.9909540812173 at iteration 179\n",
            "loss:3710.7930950354475 at iteration 180\n",
            "loss:3702.4453710199714 at iteration 181\n",
            "loss:3696.477687981611 at iteration 182\n",
            "loss:3690.967292619788 at iteration 183\n",
            "loss:3686.12491636534 at iteration 184\n",
            "loss:3673.4056903469946 at iteration 185\n",
            "loss:3666.664615569905 at iteration 186\n",
            "loss:3662.2890087695832 at iteration 187\n",
            "loss:3654.418587013527 at iteration 188\n",
            "loss:3640.0704144929587 at iteration 189\n",
            "loss:3625.954769593883 at iteration 190\n",
            "loss:3618.8511551221213 at iteration 191\n",
            "loss:3607.998615007944 at iteration 192\n",
            "loss:3594.3948403584586 at iteration 193\n",
            "loss:3585.4847294734072 at iteration 194\n",
            "loss:3577.588383421606 at iteration 195\n",
            "loss:3566.7213892283175 at iteration 196\n",
            "loss:3560.965083729137 at iteration 197\n",
            "loss:3552.1722389106176 at iteration 198\n",
            "loss:3539.260740509033 at iteration 199\n",
            "loss:3531.0874632270775 at iteration 200\n",
            "loss:3518.1804379000523 at iteration 201\n",
            "loss:3511.0971281305324 at iteration 202\n",
            "loss:3509.944259194767 at iteration 203\n",
            "loss:3502.950385712414 at iteration 204\n",
            "loss:3499.483916199323 at iteration 205\n",
            "loss:3493.321062465797 at iteration 206\n",
            "loss:3490.1398924314058 at iteration 207\n",
            "loss:3486.9924934058668 at iteration 208\n",
            "loss:3479.8945154099238 at iteration 209\n",
            "loss:3467.1022273782305 at iteration 210\n",
            "loss:3464.9208185447837 at iteration 211\n",
            "loss:3458.550877100985 at iteration 212\n",
            "loss:3453.0024660770023 at iteration 213\n",
            "loss:3448.3063267907432 at iteration 214\n",
            "loss:3442.285327628807 at iteration 215\n",
            "loss:3432.0804838540917 at iteration 216\n",
            "loss:3423.128551938118 at iteration 217\n",
            "loss:3411.6620618567617 at iteration 218\n",
            "loss:3399.233792252974 at iteration 219\n",
            "loss:3396.2025040156163 at iteration 220\n",
            "loss:3389.936504054714 at iteration 221\n",
            "loss:3384.8246012461027 at iteration 222\n",
            "loss:3381.726617404393 at iteration 223\n",
            "loss:3374.014899495443 at iteration 224\n",
            "loss:3365.883264997364 at iteration 225\n",
            "loss:3358.282237183155 at iteration 226\n",
            "loss:3347.0336045382314 at iteration 227\n",
            "loss:3339.457780596471 at iteration 228\n",
            "loss:3332.825041265073 at iteration 229\n",
            "loss:3331.8949940338794 at iteration 230\n",
            "loss:3331.6637456170442 at iteration 231\n",
            "loss:3328.794170461499 at iteration 232\n",
            "loss:3321.511293460161 at iteration 233\n",
            "loss:3320.2730825870594 at iteration 234\n",
            "loss:3321.201028468245 at iteration 235\n",
            "loss:3322.5580491979413 at iteration 236\n",
            "loss:3323.452216525038 at iteration 237\n",
            "loss:3317.7026585535027 at iteration 238\n",
            "loss:3313.618806330363 at iteration 239\n",
            "loss:3307.9448641068707 at iteration 240\n",
            "loss:3301.7076782983195 at iteration 241\n",
            "loss:3298.3926608866623 at iteration 242\n",
            "loss:3292.513645734943 at iteration 243\n",
            "loss:3285.082921989597 at iteration 244\n",
            "loss:3277.284952179203 at iteration 245\n",
            "loss:3268.3802943673695 at iteration 246\n",
            "loss:3264.9112089833907 at iteration 247\n",
            "loss:3265.6924498531234 at iteration 248\n",
            "loss:3260.8965189208984 at iteration 249\n",
            "loss:3256.7660231875234 at iteration 250\n",
            "loss:3255.7495760236466 at iteration 251\n",
            "loss:3250.271231428908 at iteration 252\n",
            "loss:3241.4999104897806 at iteration 253\n",
            "loss:3231.3419769885495 at iteration 254\n",
            "loss:3226.1057683229446 at iteration 255\n",
            "loss:3223.668400152184 at iteration 256\n",
            "loss:3216.8458404541016 at iteration 257\n",
            "loss:3208.6488523741027 at iteration 258\n",
            "loss:3210.4201830350435 at iteration 259\n",
            "loss:3209.7532749687575 at iteration 260\n",
            "loss:3203.3042445292 at iteration 261\n",
            "loss:3193.175104177497 at iteration 262\n",
            "loss:3188.299145438454 at iteration 263\n",
            "loss:3181.850065987065 at iteration 264\n",
            "loss:3174.4365708200553 at iteration 265\n",
            "loss:3168.310496698158 at iteration 266\n",
            "loss:3163.057786742253 at iteration 267\n",
            "loss:3156.4398462231716 at iteration 268\n",
            "loss:3148.7147132025825 at iteration 269\n",
            "loss:3141.4913024902344 at iteration 270\n",
            "loss:3133.5822766247916 at iteration 271\n",
            "loss:3125.7430222060652 at iteration 272\n",
            "loss:3118.277761528962 at iteration 273\n",
            "loss:3113.352178511186 at iteration 274\n",
            "loss:3106.674905417622 at iteration 275\n",
            "loss:3101.3094631153754 at iteration 276\n",
            "loss:3096.569529910739 at iteration 277\n",
            "loss:3090.993812807145 at iteration 278\n",
            "loss:3084.1471421378 at iteration 279\n",
            "loss:3077.1137898401007 at iteration 280\n",
            "loss:3072.7853111104764 at iteration 281\n",
            "loss:3068.7382035002693 at iteration 282\n",
            "loss:3066.7452434486067 at iteration 283\n",
            "loss:3061.8578136778715 at iteration 284\n",
            "loss:3054.481208747917 at iteration 285\n",
            "loss:3049.988631617317 at iteration 286\n",
            "loss:3045.797948943244 at iteration 287\n",
            "loss:3044.4440215747663 at iteration 288\n",
            "loss:3046.237313000909 at iteration 289\n",
            "loss:3044.753242518894 at iteration 290\n",
            "epoch:  4\n",
            "loss:2866.761962890625 at iteration 0\n",
            "loss:4730.0621337890625 at iteration 1\n",
            "loss:5268.159586588542 at iteration 2\n",
            "loss:6530.188293457031 at iteration 3\n",
            "loss:5954.191357421875 at iteration 4\n",
            "loss:5548.158935546875 at iteration 5\n",
            "loss:6965.540806361607 at iteration 6\n",
            "loss:7516.936462402344 at iteration 7\n",
            "loss:6982.542263454861 at iteration 8\n",
            "loss:6536.374438476562 at iteration 9\n",
            "loss:6485.703546697443 at iteration 10\n",
            "loss:6264.934794108073 at iteration 11\n",
            "loss:6117.286602313702 at iteration 12\n",
            "loss:6049.719220842634 at iteration 13\n",
            "loss:5937.103499348958 at iteration 14\n",
            "loss:5893.947799682617 at iteration 15\n",
            "loss:5845.911118451287 at iteration 16\n",
            "loss:5827.706773546007 at iteration 17\n",
            "loss:6052.388941714638 at iteration 18\n",
            "loss:6095.491857910156 at iteration 19\n",
            "loss:6060.544282459077 at iteration 20\n",
            "loss:5959.53515625 at iteration 21\n",
            "loss:6051.366593070652 at iteration 22\n",
            "loss:6130.719889322917 at iteration 23\n",
            "loss:5963.84103515625 at iteration 24\n",
            "loss:5995.983999399038 at iteration 25\n",
            "loss:6011.8350513599535 at iteration 26\n",
            "loss:5915.330278669085 at iteration 27\n",
            "loss:5929.430083176186 at iteration 28\n",
            "loss:5825.098014322916 at iteration 29\n",
            "loss:5915.7582850302415 at iteration 30\n",
            "loss:5995.150909423828 at iteration 31\n",
            "loss:6025.136186079545 at iteration 32\n",
            "loss:6015.26114430147 at iteration 33\n",
            "loss:5963.7152064732145 at iteration 34\n",
            "loss:5985.1223551432295 at iteration 35\n",
            "loss:5898.220168654983 at iteration 36\n",
            "loss:5976.531834652549 at iteration 37\n",
            "loss:5990.615278195112 at iteration 38\n",
            "loss:6103.648114013672 at iteration 39\n",
            "loss:6103.524455745046 at iteration 40\n",
            "loss:6119.236891973586 at iteration 41\n",
            "loss:6083.353430459666 at iteration 42\n",
            "loss:6207.069297096946 at iteration 43\n",
            "loss:6189.179899088542 at iteration 44\n",
            "loss:6137.362633746603 at iteration 45\n",
            "loss:6114.286163979388 at iteration 46\n",
            "loss:6107.501617431641 at iteration 47\n",
            "loss:6198.049455915178 at iteration 48\n",
            "loss:6161.505908203125 at iteration 49\n",
            "loss:6081.781106387868 at iteration 50\n",
            "loss:6052.30942946214 at iteration 51\n",
            "loss:6055.965424159787 at iteration 52\n",
            "loss:6121.882351345486 at iteration 53\n",
            "loss:6080.415802556819 at iteration 54\n",
            "loss:6012.769269670759 at iteration 55\n",
            "loss:5971.801192434211 at iteration 56\n",
            "loss:5931.827851394127 at iteration 57\n",
            "loss:5879.437111030191 at iteration 58\n",
            "loss:5883.565592447917 at iteration 59\n",
            "loss:5857.84350185707 at iteration 60\n",
            "loss:5808.8575793850805 at iteration 61\n",
            "loss:5743.439315553695 at iteration 62\n",
            "loss:5690.3792552948 at iteration 63\n",
            "loss:5633.603307166466 at iteration 64\n",
            "loss:5598.829451127486 at iteration 65\n",
            "loss:5549.016413902169 at iteration 66\n",
            "loss:5498.514750761145 at iteration 67\n",
            "loss:5443.5631138898325 at iteration 68\n",
            "loss:5416.002310616629 at iteration 69\n",
            "loss:5390.237973495268 at iteration 70\n",
            "loss:5331.816465589735 at iteration 71\n",
            "loss:5292.1314362826415 at iteration 72\n",
            "loss:5262.337664629962 at iteration 73\n",
            "loss:5227.419848632812 at iteration 74\n",
            "loss:5188.342826441714 at iteration 75\n",
            "loss:5156.543277889103 at iteration 76\n",
            "loss:5119.891418457031 at iteration 77\n",
            "loss:5098.2020232768 at iteration 78\n",
            "loss:5080.405616760254 at iteration 79\n",
            "loss:5049.473782009549 at iteration 80\n",
            "loss:5021.560634706078 at iteration 81\n",
            "loss:4984.459043204066 at iteration 82\n",
            "loss:4947.153478713262 at iteration 83\n",
            "loss:4917.982859892004 at iteration 84\n",
            "loss:4897.6771254428595 at iteration 85\n",
            "loss:4874.589410189925 at iteration 86\n",
            "loss:4848.337839299982 at iteration 87\n",
            "loss:4800.1532428184255 at iteration 88\n",
            "loss:4766.21557820638 at iteration 89\n",
            "loss:4741.695279634916 at iteration 90\n",
            "loss:4715.668636819591 at iteration 91\n",
            "loss:4692.446587675361 at iteration 92\n",
            "loss:4655.444906681142 at iteration 93\n",
            "loss:4625.968015650699 at iteration 94\n",
            "loss:4597.660935084025 at iteration 95\n",
            "loss:4584.118046396787 at iteration 96\n",
            "loss:4565.94827768754 at iteration 97\n",
            "loss:4547.59964698252 at iteration 98\n",
            "loss:4520.528578491211 at iteration 99\n",
            "loss:4497.138325606243 at iteration 100\n",
            "loss:4471.530153162339 at iteration 101\n",
            "loss:4455.329539474932 at iteration 102\n",
            "loss:4430.3078525249775 at iteration 103\n",
            "loss:4397.465695917039 at iteration 104\n",
            "loss:4390.327596412515 at iteration 105\n",
            "loss:4362.333768755476 at iteration 106\n",
            "loss:4351.517782705801 at iteration 107\n",
            "loss:4319.304196418972 at iteration 108\n",
            "loss:4293.882735373757 at iteration 109\n",
            "loss:4260.450604413007 at iteration 110\n",
            "loss:4237.803446088518 at iteration 111\n",
            "loss:4218.315951457066 at iteration 112\n",
            "loss:4217.065786261308 at iteration 113\n",
            "loss:4218.925710130775 at iteration 114\n",
            "loss:4202.334823082233 at iteration 115\n",
            "loss:4176.7586836855635 at iteration 116\n",
            "loss:4147.624096886586 at iteration 117\n",
            "loss:4127.534611549698 at iteration 118\n",
            "loss:4125.215658569336 at iteration 119\n",
            "loss:4116.402613111764 at iteration 120\n",
            "loss:4091.545647292841 at iteration 121\n",
            "loss:4069.1501226657774 at iteration 122\n",
            "loss:4060.369105185232 at iteration 123\n",
            "loss:4063.65040625 at iteration 124\n",
            "loss:4072.386939639137 at iteration 125\n",
            "loss:4078.8174404835136 at iteration 126\n",
            "loss:4073.8704109191895 at iteration 127\n",
            "loss:4069.952519379845 at iteration 128\n",
            "loss:4073.653271484375 at iteration 129\n",
            "loss:4052.731424812142 at iteration 130\n",
            "loss:4034.9531277743254 at iteration 131\n",
            "loss:4014.50383374207 at iteration 132\n",
            "loss:4002.4229982290694 at iteration 133\n",
            "loss:3995.1602294921877 at iteration 134\n",
            "loss:3993.050703160903 at iteration 135\n",
            "loss:4000.7687480397467 at iteration 136\n",
            "loss:3991.0243052606997 at iteration 137\n",
            "loss:3985.413546994436 at iteration 138\n",
            "loss:3980.962082345145 at iteration 139\n",
            "loss:3967.5830762065048 at iteration 140\n",
            "loss:3960.1474480427487 at iteration 141\n",
            "loss:3959.7670002117025 at iteration 142\n",
            "loss:3972.773585849338 at iteration 143\n",
            "loss:3981.680370251886 at iteration 144\n",
            "loss:3977.76909397073 at iteration 145\n",
            "loss:3981.1017161259033 at iteration 146\n",
            "loss:3971.9357456516577 at iteration 147\n",
            "loss:3977.9226000485005 at iteration 148\n",
            "loss:3976.308835449219 at iteration 149\n",
            "loss:3978.4793895190915 at iteration 150\n",
            "loss:3974.600904765882 at iteration 151\n",
            "loss:3970.503492168352 at iteration 152\n",
            "loss:3969.7266013405538 at iteration 153\n",
            "loss:3972.55872999622 at iteration 154\n",
            "loss:3966.528369610126 at iteration 155\n",
            "loss:3968.5251317115344 at iteration 156\n",
            "loss:3964.252684774278 at iteration 157\n",
            "loss:3955.2658499471795 at iteration 158\n",
            "loss:3936.636074447632 at iteration 159\n",
            "loss:3930.795578097705 at iteration 160\n",
            "loss:3921.2660752284673 at iteration 161\n",
            "loss:3906.379622570576 at iteration 162\n",
            "loss:3898.213784194574 at iteration 163\n",
            "loss:3897.315850275213 at iteration 164\n",
            "loss:3904.2483296222 at iteration 165\n",
            "loss:3902.7208569920704 at iteration 166\n",
            "loss:3901.6361974080405 at iteration 167\n",
            "loss:3896.046527207956 at iteration 168\n",
            "loss:3879.6788556267234 at iteration 169\n",
            "loss:3864.9445682994105 at iteration 170\n",
            "loss:3848.912952156954 at iteration 171\n",
            "loss:3834.107667074038 at iteration 172\n",
            "loss:3823.785430908203 at iteration 173\n",
            "loss:3809.323052106585 at iteration 174\n",
            "loss:3792.683744603937 at iteration 175\n",
            "loss:3778.4015502929688 at iteration 176\n",
            "loss:3767.0221883366617 at iteration 177\n",
            "loss:3754.9964418890754 at iteration 178\n",
            "loss:3742.832251993815 at iteration 179\n",
            "loss:3733.4218281276976 at iteration 180\n",
            "loss:3723.3572203248414 at iteration 181\n",
            "loss:3720.7106970281548 at iteration 182\n",
            "loss:3715.0796253370204 at iteration 183\n",
            "loss:3708.6036023938977 at iteration 184\n",
            "loss:3696.9337712769866 at iteration 185\n",
            "loss:3689.531896580987 at iteration 186\n",
            "loss:3688.7183386620054 at iteration 187\n",
            "loss:3682.555178687686 at iteration 188\n",
            "loss:3667.398058118318 at iteration 189\n",
            "loss:3653.6345588724025 at iteration 190\n",
            "loss:3646.5059893925986 at iteration 191\n",
            "loss:3634.267200845511 at iteration 192\n",
            "loss:3621.0621989142032 at iteration 193\n",
            "loss:3615.6344623272234 at iteration 194\n",
            "loss:3604.0837312036633 at iteration 195\n",
            "loss:3593.704850405001 at iteration 196\n",
            "loss:3590.4846046524817 at iteration 197\n",
            "loss:3580.9446926404485 at iteration 198\n",
            "loss:3569.2953329467773 at iteration 199\n",
            "loss:3561.972813848239 at iteration 200\n",
            "loss:3550.438786270595 at iteration 201\n",
            "loss:3542.7227888436155 at iteration 202\n",
            "loss:3536.1279228060853 at iteration 203\n",
            "loss:3527.941537550019 at iteration 204\n",
            "loss:3524.974302717783 at iteration 205\n",
            "loss:3517.404389164874 at iteration 206\n",
            "loss:3512.734813103309 at iteration 207\n",
            "loss:3509.1991746528297 at iteration 208\n",
            "loss:3502.237964157831 at iteration 209\n",
            "loss:3490.4241092916914 at iteration 210\n",
            "loss:3485.236337337854 at iteration 211\n",
            "loss:3479.3253500495157 at iteration 212\n",
            "loss:3473.998044593312 at iteration 213\n",
            "loss:3470.559499909157 at iteration 214\n",
            "loss:3464.5673624674478 at iteration 215\n",
            "loss:3452.9776498820925 at iteration 216\n",
            "loss:3441.2869850648653 at iteration 217\n",
            "loss:3431.29488787368 at iteration 218\n",
            "loss:3419.199030650746 at iteration 219\n",
            "loss:3415.719861889317 at iteration 220\n",
            "loss:3408.179998174444 at iteration 221\n",
            "loss:3404.74289309925 at iteration 222\n",
            "loss:3403.608386993408 at iteration 223\n",
            "loss:3396.906759440104 at iteration 224\n",
            "loss:3386.7975955389243 at iteration 225\n",
            "loss:3378.0877465067456 at iteration 226\n",
            "loss:3366.5129929927357 at iteration 227\n",
            "loss:3356.810790482567 at iteration 228\n",
            "loss:3348.77915569803 at iteration 229\n",
            "loss:3346.508552320076 at iteration 230\n",
            "loss:3345.1492046487742 at iteration 231\n",
            "loss:3342.7701693686295 at iteration 232\n",
            "loss:3334.284449389857 at iteration 233\n",
            "loss:3336.5770575340757 at iteration 234\n",
            "loss:3338.9330232264633 at iteration 235\n",
            "loss:3338.896884580202 at iteration 236\n",
            "loss:3340.3570489963563 at iteration 237\n",
            "loss:3332.689378554851 at iteration 238\n",
            "loss:3327.3653238932293 at iteration 239\n",
            "loss:3321.564324469982 at iteration 240\n",
            "loss:3316.054602756973 at iteration 241\n",
            "loss:3312.4488249099795 at iteration 242\n",
            "loss:3307.034712494397 at iteration 243\n",
            "loss:3299.653636200574 at iteration 244\n",
            "loss:3293.0938373348577 at iteration 245\n",
            "loss:3284.745143380725 at iteration 246\n",
            "loss:3280.3848675143336 at iteration 247\n",
            "loss:3279.6395920596447 at iteration 248\n",
            "loss:3272.8143251953124 at iteration 249\n",
            "loss:3271.7149400445096 at iteration 250\n",
            "loss:3272.3269798642114 at iteration 251\n",
            "loss:3266.5391734730115 at iteration 252\n",
            "loss:3260.0602465051365 at iteration 253\n",
            "loss:3249.965753293505 at iteration 254\n",
            "loss:3244.455267906189 at iteration 255\n",
            "loss:3239.629930785658 at iteration 256\n",
            "loss:3233.486585986707 at iteration 257\n",
            "loss:3225.036087095047 at iteration 258\n",
            "loss:3227.6279048039364 at iteration 259\n",
            "loss:3224.812894273078 at iteration 260\n",
            "loss:3218.3005650644086 at iteration 261\n",
            "loss:3208.258332343156 at iteration 262\n",
            "loss:3203.6691418272076 at iteration 263\n",
            "loss:3197.593504477447 at iteration 264\n",
            "loss:3190.402776503025 at iteration 265\n",
            "loss:3183.8240418166256 at iteration 266\n",
            "loss:3177.9971641426655 at iteration 267\n",
            "loss:3172.191791974036 at iteration 268\n",
            "loss:3163.8314364963107 at iteration 269\n",
            "loss:3156.49227060691 at iteration 270\n",
            "loss:3148.995334625244 at iteration 271\n",
            "loss:3141.4952596028647 at iteration 272\n",
            "loss:3134.4585462138602 at iteration 273\n",
            "loss:3130.054445356889 at iteration 274\n",
            "loss:3123.148850814156 at iteration 275\n",
            "loss:3116.190916426345 at iteration 276\n",
            "loss:3110.286396932259 at iteration 277\n",
            "loss:3104.803495454959 at iteration 278\n",
            "loss:3097.979767499651 at iteration 279\n",
            "loss:3090.0367481598228 at iteration 280\n",
            "loss:3084.593838089747 at iteration 281\n",
            "loss:3081.847612899942 at iteration 282\n",
            "loss:3078.515815627407 at iteration 283\n",
            "loss:3072.174672123424 at iteration 284\n",
            "loss:3064.767859825721 at iteration 285\n",
            "loss:3059.577486576519 at iteration 286\n",
            "loss:3054.2334620157876 at iteration 287\n",
            "loss:3052.177232577314 at iteration 288\n",
            "loss:3054.15745975889 at iteration 289\n",
            "loss:3051.6002033666236 at iteration 290\n",
            "epoch:  5\n",
            "loss:2216.009521484375 at iteration 0\n",
            "loss:4027.7969970703125 at iteration 1\n",
            "loss:5054.226806640625 at iteration 2\n",
            "loss:6393.978942871094 at iteration 3\n",
            "loss:5853.315771484375 at iteration 4\n",
            "loss:5451.354329427083 at iteration 5\n",
            "loss:6852.188337053572 at iteration 6\n",
            "loss:7479.2545166015625 at iteration 7\n",
            "loss:6934.237169053819 at iteration 8\n",
            "loss:6513.18564453125 at iteration 9\n",
            "loss:6472.002752130682 at iteration 10\n",
            "loss:6282.747965494792 at iteration 11\n",
            "loss:6085.281531700721 at iteration 12\n",
            "loss:6055.668858119419 at iteration 13\n",
            "loss:5949.019905598959 at iteration 14\n",
            "loss:5950.087905883789 at iteration 15\n",
            "loss:5885.476806640625 at iteration 16\n",
            "loss:5920.118503146701 at iteration 17\n",
            "loss:6100.327726665296 at iteration 18\n",
            "loss:6157.432385253906 at iteration 19\n",
            "loss:6130.736897786458 at iteration 20\n",
            "loss:6014.9110107421875 at iteration 21\n",
            "loss:6061.244172469429 at iteration 22\n",
            "loss:6070.23432413737 at iteration 23\n",
            "loss:5921.13890625 at iteration 24\n",
            "loss:5926.772329477163 at iteration 25\n",
            "loss:5971.534595630787 at iteration 26\n",
            "loss:5869.640441894531 at iteration 27\n",
            "loss:5891.649136247306 at iteration 28\n",
            "loss:5791.033723958333 at iteration 29\n",
            "loss:5826.369707661291 at iteration 30\n",
            "loss:5896.389434814453 at iteration 31\n",
            "loss:5894.686922940341 at iteration 32\n",
            "loss:5867.283677045037 at iteration 33\n",
            "loss:5844.354938616071 at iteration 34\n",
            "loss:5846.837551540799 at iteration 35\n",
            "loss:5755.177826752534 at iteration 36\n",
            "loss:5788.863075657895 at iteration 37\n",
            "loss:5786.428786057692 at iteration 38\n",
            "loss:5858.038818359375 at iteration 39\n",
            "loss:5877.266280011433 at iteration 40\n",
            "loss:5913.5041271391365 at iteration 41\n",
            "loss:5872.350404251453 at iteration 42\n",
            "loss:5985.23945756392 at iteration 43\n",
            "loss:5933.523025173611 at iteration 44\n",
            "loss:5895.306290336277 at iteration 45\n",
            "loss:5873.385482463431 at iteration 46\n",
            "loss:5898.141204833984 at iteration 47\n",
            "loss:5977.987494021046 at iteration 48\n",
            "loss:5937.0108984375 at iteration 49\n",
            "loss:5884.097440831802 at iteration 50\n",
            "loss:5870.827819824219 at iteration 51\n",
            "loss:5859.125244140625 at iteration 52\n",
            "loss:5927.232534903067 at iteration 53\n",
            "loss:5907.789208984375 at iteration 54\n",
            "loss:5840.5260663713725 at iteration 55\n",
            "loss:5798.258065206963 at iteration 56\n",
            "loss:5765.156266837284 at iteration 57\n",
            "loss:5712.738397113348 at iteration 58\n",
            "loss:5725.712532552084 at iteration 59\n",
            "loss:5694.540171138576 at iteration 60\n",
            "loss:5646.91994156376 at iteration 61\n",
            "loss:5593.535005115327 at iteration 62\n",
            "loss:5546.75271987915 at iteration 63\n",
            "loss:5499.494272085337 at iteration 64\n",
            "loss:5451.680456912879 at iteration 65\n",
            "loss:5401.163213473647 at iteration 66\n",
            "loss:5356.515484978171 at iteration 67\n",
            "loss:5323.822555763134 at iteration 68\n",
            "loss:5301.9320138113835 at iteration 69\n",
            "loss:5283.095152948944 at iteration 70\n",
            "loss:5229.506857977973 at iteration 71\n",
            "loss:5196.420020534568 at iteration 72\n",
            "loss:5158.020291715055 at iteration 73\n",
            "loss:5121.258074544271 at iteration 74\n",
            "loss:5085.519041362561 at iteration 75\n",
            "loss:5055.431268072747 at iteration 76\n",
            "loss:5019.215117625701 at iteration 77\n",
            "loss:5000.308255352551 at iteration 78\n",
            "loss:4973.884074401855 at iteration 79\n",
            "loss:4939.729119948399 at iteration 80\n",
            "loss:4912.831324135385 at iteration 81\n",
            "loss:4878.206173816359 at iteration 82\n",
            "loss:4839.119378952753 at iteration 83\n",
            "loss:4805.3604736328125 at iteration 84\n",
            "loss:4781.771815100382 at iteration 85\n",
            "loss:4756.117853975844 at iteration 86\n",
            "loss:4736.860627607865 at iteration 87\n",
            "loss:4697.338199229723 at iteration 88\n",
            "loss:4660.197954644097 at iteration 89\n",
            "loss:4641.322877317994 at iteration 90\n",
            "loss:4622.0588750424595 at iteration 91\n",
            "loss:4601.6833443590385 at iteration 92\n",
            "loss:4567.158225201546 at iteration 93\n",
            "loss:4534.4332660875825 at iteration 94\n",
            "loss:4509.127801259358 at iteration 95\n",
            "loss:4502.782119593669 at iteration 96\n",
            "loss:4483.750001245616 at iteration 97\n",
            "loss:4466.618991427951 at iteration 98\n",
            "loss:4440.444315185547 at iteration 99\n",
            "loss:4418.7822978709 at iteration 100\n",
            "loss:4399.304645613128 at iteration 101\n",
            "loss:4382.84611200129 at iteration 102\n",
            "loss:4357.2057049091045 at iteration 103\n",
            "loss:4322.6271530877975 at iteration 104\n",
            "loss:4315.31968372273 at iteration 105\n",
            "loss:4289.428285402672 at iteration 106\n",
            "loss:4277.206345169632 at iteration 107\n",
            "loss:4249.11506526842 at iteration 108\n",
            "loss:4227.889105779474 at iteration 109\n",
            "loss:4198.943098188521 at iteration 110\n",
            "loss:4178.007151467459 at iteration 111\n",
            "loss:4161.202119810391 at iteration 112\n",
            "loss:4155.522901568496 at iteration 113\n",
            "loss:4158.478430175781 at iteration 114\n",
            "loss:4140.230083070952 at iteration 115\n",
            "loss:4113.925115079961 at iteration 116\n",
            "loss:4087.9030684131685 at iteration 117\n",
            "loss:4068.7416597254137 at iteration 118\n",
            "loss:4069.275416564941 at iteration 119\n",
            "loss:4064.813110855985 at iteration 120\n",
            "loss:4035.9133826083826 at iteration 121\n",
            "loss:4012.8148486129635 at iteration 122\n",
            "loss:4002.312514274351 at iteration 123\n",
            "loss:4005.8984321289063 at iteration 124\n",
            "loss:4012.8959442623077 at iteration 125\n",
            "loss:4015.5747325026146 at iteration 126\n",
            "loss:4009.347460269928 at iteration 127\n",
            "loss:4006.798584457516 at iteration 128\n",
            "loss:4010.0513545109675 at iteration 129\n",
            "loss:3988.409276132365 at iteration 130\n",
            "loss:3969.6801697702117 at iteration 131\n",
            "loss:3950.3591368252173 at iteration 132\n",
            "loss:3939.265004172254 at iteration 133\n",
            "loss:3935.111715585214 at iteration 134\n",
            "loss:3931.223258074592 at iteration 135\n",
            "loss:3937.0949141230894 at iteration 136\n",
            "loss:3934.958139170771 at iteration 137\n",
            "loss:3930.675188023409 at iteration 138\n",
            "loss:3924.706091744559 at iteration 139\n",
            "loss:3912.091901197501 at iteration 140\n",
            "loss:3900.3594184123294 at iteration 141\n",
            "loss:3899.7646761807528 at iteration 142\n",
            "loss:3912.694031185574 at iteration 143\n",
            "loss:3924.1491854963633 at iteration 144\n",
            "loss:3921.496953676825 at iteration 145\n",
            "loss:3925.54815424705 at iteration 146\n",
            "loss:3916.428754239469 at iteration 147\n",
            "loss:3925.5568179956217 at iteration 148\n",
            "loss:3923.4070088704425 at iteration 149\n",
            "loss:3926.441671813561 at iteration 150\n",
            "loss:3923.1049069856344 at iteration 151\n",
            "loss:3923.011214910769 at iteration 152\n",
            "loss:3921.738230915813 at iteration 153\n",
            "loss:3925.7514620873235 at iteration 154\n",
            "loss:3917.764088557317 at iteration 155\n",
            "loss:3923.258493994452 at iteration 156\n",
            "loss:3923.30103659328 at iteration 157\n",
            "loss:3914.6120593952683 at iteration 158\n",
            "loss:3897.390449142456 at iteration 159\n",
            "loss:3895.2359653259655 at iteration 160\n",
            "loss:3889.2812782570168 at iteration 161\n",
            "loss:3878.3717314363257 at iteration 162\n",
            "loss:3871.7928850127428 at iteration 163\n",
            "loss:3869.7044030391808 at iteration 164\n",
            "loss:3874.8953574306993 at iteration 165\n",
            "loss:3877.1461126818626 at iteration 166\n",
            "loss:3872.772072564988 at iteration 167\n",
            "loss:3865.750253891804 at iteration 168\n",
            "loss:3849.943827191521 at iteration 169\n",
            "loss:3834.517349332397 at iteration 170\n",
            "loss:3819.4492794303005 at iteration 171\n",
            "loss:3804.0261346894195 at iteration 172\n",
            "loss:3789.748467456335 at iteration 173\n",
            "loss:3777.9067114257814 at iteration 174\n",
            "loss:3760.5655160383744 at iteration 175\n",
            "loss:3744.9491346111404 at iteration 176\n",
            "loss:3729.178932790006 at iteration 177\n",
            "loss:3720.9715484107674 at iteration 178\n",
            "loss:3707.1828691270616 at iteration 179\n",
            "loss:3699.126339064119 at iteration 180\n",
            "loss:3690.551054566771 at iteration 181\n",
            "loss:3687.691493967192 at iteration 182\n",
            "loss:3681.812916299571 at iteration 183\n",
            "loss:3676.0929657807224 at iteration 184\n",
            "loss:3664.158933249853 at iteration 185\n",
            "loss:3657.2033250778118 at iteration 186\n",
            "loss:3652.472165696164 at iteration 187\n",
            "loss:3645.932481876757 at iteration 188\n",
            "loss:3631.6378893400492 at iteration 189\n",
            "loss:3617.716128683839 at iteration 190\n",
            "loss:3614.2590869267783 at iteration 191\n",
            "loss:3604.6958542265425 at iteration 192\n",
            "loss:3591.521508600294 at iteration 193\n",
            "loss:3581.7146249624398 at iteration 194\n",
            "loss:3573.1578745939296 at iteration 195\n",
            "loss:3561.754969872799 at iteration 196\n",
            "loss:3555.2019477613044 at iteration 197\n",
            "loss:3544.674801927116 at iteration 198\n",
            "loss:3531.997515563965 at iteration 199\n",
            "loss:3522.661652370472 at iteration 200\n",
            "loss:3509.728889994102 at iteration 201\n",
            "loss:3501.1838748725177 at iteration 202\n",
            "loss:3498.0231272379556 at iteration 203\n",
            "loss:3492.5443749404535 at iteration 204\n",
            "loss:3490.7612029140437 at iteration 205\n",
            "loss:3482.5331291161874 at iteration 206\n",
            "loss:3479.4725227355957 at iteration 207\n",
            "loss:3479.612255917782 at iteration 208\n",
            "loss:3472.6626211983817 at iteration 209\n",
            "loss:3459.5982344930208 at iteration 210\n",
            "loss:3455.6643455073518 at iteration 211\n",
            "loss:3449.4037945527984 at iteration 212\n",
            "loss:3442.1381422381533 at iteration 213\n",
            "loss:3440.4469076467117 at iteration 214\n",
            "loss:3434.608892087583 at iteration 215\n",
            "loss:3424.099368890859 at iteration 216\n",
            "loss:3416.191038079218 at iteration 217\n",
            "loss:3406.434237824183 at iteration 218\n",
            "loss:3395.613032947887 at iteration 219\n",
            "loss:3392.8353699559 at iteration 220\n",
            "loss:3384.7881027084213 at iteration 221\n",
            "loss:3379.4545091021755 at iteration 222\n",
            "loss:3377.459834780012 at iteration 223\n",
            "loss:3369.8267385525173 at iteration 224\n",
            "loss:3359.7400688238904 at iteration 225\n",
            "loss:3352.0728041863126 at iteration 226\n",
            "loss:3340.9402722810446 at iteration 227\n",
            "loss:3332.6704719909935 at iteration 228\n",
            "loss:3327.6054729959237 at iteration 229\n",
            "loss:3324.715890066964 at iteration 230\n",
            "loss:3324.187621017982 at iteration 231\n",
            "loss:3319.9854961608103 at iteration 232\n",
            "loss:3316.232905982906 at iteration 233\n",
            "loss:3316.0479398686834 at iteration 234\n",
            "loss:3314.8875380693858 at iteration 235\n",
            "loss:3315.9160599205566 at iteration 236\n",
            "loss:3317.3289753889835 at iteration 237\n",
            "loss:3310.305932719338 at iteration 238\n",
            "loss:3303.7925806681314 at iteration 239\n",
            "loss:3298.5145076261024 at iteration 240\n",
            "loss:3292.4860829755294 at iteration 241\n",
            "loss:3290.350814003022 at iteration 242\n",
            "loss:3287.421390721055 at iteration 243\n",
            "loss:3279.9238779496172 at iteration 244\n",
            "loss:3273.5872733263463 at iteration 245\n",
            "loss:3265.990580323254 at iteration 246\n",
            "loss:3262.3979255922377 at iteration 247\n",
            "loss:3260.304690441453 at iteration 248\n",
            "loss:3253.5330078125 at iteration 249\n",
            "loss:3250.1237141278634 at iteration 250\n",
            "loss:3249.832750108507 at iteration 251\n",
            "loss:3245.5116116369195 at iteration 252\n",
            "loss:3237.9245355561025 at iteration 253\n",
            "loss:3226.937806372549 at iteration 254\n",
            "loss:3219.963529586792 at iteration 255\n",
            "loss:3216.1141514165856 at iteration 256\n",
            "loss:3211.220582000969 at iteration 257\n",
            "loss:3203.8231469820826 at iteration 258\n",
            "loss:3203.7965134840747 at iteration 259\n",
            "loss:3202.0172469917384 at iteration 260\n",
            "loss:3193.904446900346 at iteration 261\n",
            "loss:3185.461014548182 at iteration 262\n",
            "loss:3179.754196166992 at iteration 263\n",
            "loss:3174.15665260171 at iteration 264\n",
            "loss:3166.8653234037242 at iteration 265\n",
            "loss:3159.852498829588 at iteration 266\n",
            "loss:3155.008763099784 at iteration 267\n",
            "loss:3149.3085569927684 at iteration 268\n",
            "loss:3141.010670979818 at iteration 269\n",
            "loss:3134.481125722512 at iteration 270\n",
            "loss:3126.5417305441465 at iteration 271\n",
            "loss:3119.73882318853 at iteration 272\n",
            "loss:3112.373555649806 at iteration 273\n",
            "loss:3109.3845818536934 at iteration 274\n",
            "loss:3103.0881506878395 at iteration 275\n",
            "loss:3096.777370191223 at iteration 276\n",
            "loss:3091.622003129918 at iteration 277\n",
            "loss:3086.671703051495 at iteration 278\n",
            "loss:3080.434466116769 at iteration 279\n",
            "loss:3073.093783667079 at iteration 280\n",
            "loss:3068.0687625966175 at iteration 281\n",
            "loss:3065.961267693725 at iteration 282\n",
            "loss:3063.4919018812584 at iteration 283\n",
            "loss:3057.3986809981498 at iteration 284\n",
            "loss:3050.653535642824 at iteration 285\n",
            "loss:3044.2889100184425 at iteration 286\n",
            "loss:3039.8892137739394 at iteration 287\n",
            "loss:3039.014042943407 at iteration 288\n",
            "loss:3041.4806996312636 at iteration 289\n",
            "loss:3040.2409821080996 at iteration 290\n",
            "epoch:  6\n",
            "loss:2203.12255859375 at iteration 0\n",
            "loss:3840.639404296875 at iteration 1\n",
            "loss:4732.843587239583 at iteration 2\n",
            "loss:5984.8082275390625 at iteration 3\n",
            "loss:5545.15546875 at iteration 4\n",
            "loss:5250.8153889973955 at iteration 5\n",
            "loss:6602.38152204241 at iteration 6\n",
            "loss:7329.243377685547 at iteration 7\n",
            "loss:6763.801622178819 at iteration 8\n",
            "loss:6308.326806640625 at iteration 9\n",
            "loss:6250.511585582386 at iteration 10\n",
            "loss:6144.582763671875 at iteration 11\n",
            "loss:5992.188739483173 at iteration 12\n",
            "loss:5918.596051897322 at iteration 13\n",
            "loss:5790.902994791667 at iteration 14\n",
            "loss:5762.505767822266 at iteration 15\n",
            "loss:5706.812528722427 at iteration 16\n",
            "loss:5701.825005425348 at iteration 17\n",
            "loss:5864.1882966694075 at iteration 18\n",
            "loss:5881.2373046875 at iteration 19\n",
            "loss:5866.762253534226 at iteration 20\n",
            "loss:5788.938498757102 at iteration 21\n",
            "loss:5850.135338824728 at iteration 22\n",
            "loss:5894.801778157552 at iteration 23\n",
            "loss:5739.36359375 at iteration 24\n",
            "loss:5749.594839242788 at iteration 25\n",
            "loss:5759.208170572917 at iteration 26\n",
            "loss:5678.9561767578125 at iteration 27\n",
            "loss:5701.784415409483 at iteration 28\n",
            "loss:5603.717561848958 at iteration 29\n",
            "loss:5645.334157636089 at iteration 30\n",
            "loss:5709.792755126953 at iteration 31\n",
            "loss:5740.083836410985 at iteration 32\n",
            "loss:5693.082103056066 at iteration 33\n",
            "loss:5652.769377790179 at iteration 34\n",
            "loss:5677.394680447049 at iteration 35\n",
            "loss:5580.358114706503 at iteration 36\n",
            "loss:5625.498297440378 at iteration 37\n",
            "loss:5659.354761368189 at iteration 38\n",
            "loss:5729.652435302734 at iteration 39\n",
            "loss:5757.835979182546 at iteration 40\n",
            "loss:5800.83834984189 at iteration 41\n",
            "loss:5748.787620367006 at iteration 42\n",
            "loss:5885.8770751953125 at iteration 43\n",
            "loss:5861.567426215278 at iteration 44\n",
            "loss:5828.026112432065 at iteration 45\n",
            "loss:5820.43896484375 at iteration 46\n",
            "loss:5818.754913330078 at iteration 47\n",
            "loss:5884.118811782526 at iteration 48\n",
            "loss:5836.0509423828125 at iteration 49\n",
            "loss:5760.126000497856 at iteration 50\n",
            "loss:5739.674508901743 at iteration 51\n",
            "loss:5741.8311145710495 at iteration 52\n",
            "loss:5808.616812246817 at iteration 53\n",
            "loss:5772.489581853693 at iteration 54\n",
            "loss:5708.676387241909 at iteration 55\n",
            "loss:5672.620387027138 at iteration 56\n",
            "loss:5638.582835230334 at iteration 57\n",
            "loss:5590.733290850106 at iteration 58\n",
            "loss:5594.031673177084 at iteration 59\n",
            "loss:5559.66925349001 at iteration 60\n",
            "loss:5517.2590843939015 at iteration 61\n",
            "loss:5456.282978360615 at iteration 62\n",
            "loss:5410.92862701416 at iteration 63\n",
            "loss:5354.2258807842545 at iteration 64\n",
            "loss:5306.936181270715 at iteration 65\n",
            "loss:5249.967915549207 at iteration 66\n",
            "loss:5215.450094784007 at iteration 67\n",
            "loss:5174.353144106658 at iteration 68\n",
            "loss:5151.552961077009 at iteration 69\n",
            "loss:5131.75820793904 at iteration 70\n",
            "loss:5077.840845743815 at iteration 71\n",
            "loss:5045.824016414276 at iteration 72\n",
            "loss:5016.074906632707 at iteration 73\n",
            "loss:4980.109340820312 at iteration 74\n",
            "loss:4942.128564131887 at iteration 75\n",
            "loss:4909.447999632203 at iteration 76\n",
            "loss:4873.093088003306 at iteration 77\n",
            "loss:4857.754328087915 at iteration 78\n",
            "loss:4845.710505676269 at iteration 79\n",
            "loss:4817.737797489873 at iteration 80\n",
            "loss:4792.2563163943405 at iteration 81\n",
            "loss:4766.155392566359 at iteration 82\n",
            "loss:4739.0757722400485 at iteration 83\n",
            "loss:4702.552233168658 at iteration 84\n",
            "loss:4680.900088288064 at iteration 85\n",
            "loss:4666.608649593661 at iteration 86\n",
            "loss:4641.026135531339 at iteration 87\n",
            "loss:4597.873351364993 at iteration 88\n",
            "loss:4563.053074815538 at iteration 89\n",
            "loss:4543.56987116887 at iteration 90\n",
            "loss:4519.495965045431 at iteration 91\n",
            "loss:4498.062175791751 at iteration 92\n",
            "loss:4462.5937097427695 at iteration 93\n",
            "loss:4431.281081671464 at iteration 94\n",
            "loss:4404.225074768066 at iteration 95\n",
            "loss:4392.733695433312 at iteration 96\n",
            "loss:4375.65010413345 at iteration 97\n",
            "loss:4353.699504813762 at iteration 98\n",
            "loss:4327.577022705078 at iteration 99\n",
            "loss:4307.998072255956 at iteration 100\n",
            "loss:4285.400960286458 at iteration 101\n",
            "loss:4268.502273115139 at iteration 102\n",
            "loss:4243.311507004958 at iteration 103\n",
            "loss:4209.917244466146 at iteration 104\n",
            "loss:4199.20250658719 at iteration 105\n",
            "loss:4176.806016583309 at iteration 106\n",
            "loss:4165.086616798683 at iteration 107\n",
            "loss:4137.326078922377 at iteration 108\n",
            "loss:4116.034817782315 at iteration 109\n",
            "loss:4085.5656793267876 at iteration 110\n",
            "loss:4067.9689494541713 at iteration 111\n",
            "loss:4054.6029225577295 at iteration 112\n",
            "loss:4048.621945029811 at iteration 113\n",
            "loss:4055.348759128736 at iteration 114\n",
            "loss:4038.136597732018 at iteration 115\n",
            "loss:4016.6765960954194 at iteration 116\n",
            "loss:3991.458244711666 at iteration 117\n",
            "loss:3972.6969527557117 at iteration 118\n",
            "loss:3967.501909383138 at iteration 119\n",
            "loss:3959.3604695974304 at iteration 120\n",
            "loss:3935.5596823770493 at iteration 121\n",
            "loss:3911.595933867664 at iteration 122\n",
            "loss:3899.57104738297 at iteration 123\n",
            "loss:3909.678154785156 at iteration 124\n",
            "loss:3912.785488068111 at iteration 125\n",
            "loss:3911.5504241703065 at iteration 126\n",
            "loss:3903.7916626930237 at iteration 127\n",
            "loss:3901.716066818829 at iteration 128\n",
            "loss:3898.874298095703 at iteration 129\n",
            "loss:3877.1507377333314 at iteration 130\n",
            "loss:3862.129261826024 at iteration 131\n",
            "loss:3846.1077059408776 at iteration 132\n",
            "loss:3835.5120225593223 at iteration 133\n",
            "loss:3829.850523998119 at iteration 134\n",
            "loss:3825.5359690049117 at iteration 135\n",
            "loss:3833.123629159301 at iteration 136\n",
            "loss:3824.739168913468 at iteration 137\n",
            "loss:3822.621161810786 at iteration 138\n",
            "loss:3817.327655465262 at iteration 139\n",
            "loss:3804.488756112173 at iteration 140\n",
            "loss:3796.750449167171 at iteration 141\n",
            "loss:3798.4664490172913 at iteration 142\n",
            "loss:3811.4054094950357 at iteration 143\n",
            "loss:3822.4809338799837 at iteration 144\n",
            "loss:3817.7522327997913 at iteration 145\n",
            "loss:3821.4308886884833 at iteration 146\n",
            "loss:3811.569524404165 at iteration 147\n",
            "loss:3816.871956025194 at iteration 148\n",
            "loss:3816.7951582845053 at iteration 149\n",
            "loss:3814.940307212981 at iteration 150\n",
            "loss:3813.0931448685496 at iteration 151\n",
            "loss:3810.676577898412 at iteration 152\n",
            "loss:3811.9377191716976 at iteration 153\n",
            "loss:3813.469081164945 at iteration 154\n",
            "loss:3805.0623251108022 at iteration 155\n",
            "loss:3811.4887201588626 at iteration 156\n",
            "loss:3808.998567991619 at iteration 157\n",
            "loss:3799.849402469659 at iteration 158\n",
            "loss:3781.9899391174317 at iteration 159\n",
            "loss:3775.163450632036 at iteration 160\n",
            "loss:3765.7451752085744 at iteration 161\n",
            "loss:3752.9928068383338 at iteration 162\n",
            "loss:3748.524661924781 at iteration 163\n",
            "loss:3749.196949721828 at iteration 164\n",
            "loss:3757.661074718797 at iteration 165\n",
            "loss:3760.1673554745976 at iteration 166\n",
            "loss:3758.0415918259396 at iteration 167\n",
            "loss:3753.1436652008597 at iteration 168\n",
            "loss:3738.2806317497702 at iteration 169\n",
            "loss:3723.677872150265 at iteration 170\n",
            "loss:3707.8085710392443 at iteration 171\n",
            "loss:3692.2175363529623 at iteration 172\n",
            "loss:3681.4244679418102 at iteration 173\n",
            "loss:3669.380120675223 at iteration 174\n",
            "loss:3653.3551729375667 at iteration 175\n",
            "loss:3638.0791074246335 at iteration 176\n",
            "loss:3623.7420122810963 at iteration 177\n",
            "loss:3615.612876508489 at iteration 178\n",
            "loss:3605.245769924588 at iteration 179\n",
            "loss:3599.6169423477427 at iteration 180\n",
            "loss:3588.5086525717934 at iteration 181\n",
            "loss:3587.1430774125897 at iteration 182\n",
            "loss:3578.863800380541 at iteration 183\n",
            "loss:3575.6113799224026 at iteration 184\n",
            "loss:3564.0599670410156 at iteration 185\n",
            "loss:3556.46701000846 at iteration 186\n",
            "loss:3550.746079789831 at iteration 187\n",
            "loss:3542.922320976459 at iteration 188\n",
            "loss:3528.7700600071958 at iteration 189\n",
            "loss:3513.9127625470387 at iteration 190\n",
            "loss:3505.7701663970947 at iteration 191\n",
            "loss:3495.526064857918 at iteration 192\n",
            "loss:3482.7469966927756 at iteration 193\n",
            "loss:3474.9043325570915 at iteration 194\n",
            "loss:3463.9436464893574 at iteration 195\n",
            "loss:3454.0264582755 at iteration 196\n",
            "loss:3449.0768346304844 at iteration 197\n",
            "loss:3437.171192265036 at iteration 198\n",
            "loss:3425.054357299805 at iteration 199\n",
            "loss:3419.4753047506606 at iteration 200\n",
            "loss:3407.153841528562 at iteration 201\n",
            "loss:3404.586432095232 at iteration 202\n",
            "loss:3402.485445209578 at iteration 203\n",
            "loss:3396.6535516506287 at iteration 204\n",
            "loss:3393.589288211563 at iteration 205\n",
            "loss:3386.1837821628737 at iteration 206\n",
            "loss:3382.964201413668 at iteration 207\n",
            "loss:3383.7092107015364 at iteration 208\n",
            "loss:3376.411231921968 at iteration 209\n",
            "loss:3364.254178160175 at iteration 210\n",
            "loss:3358.5277387511055 at iteration 211\n",
            "loss:3353.644452162192 at iteration 212\n",
            "loss:3347.385313800562 at iteration 213\n",
            "loss:3342.9698497683503 at iteration 214\n",
            "loss:3337.1098762794777 at iteration 215\n",
            "loss:3325.476345361103 at iteration 216\n",
            "loss:3315.3161285120414 at iteration 217\n",
            "loss:3306.143111555544 at iteration 218\n",
            "loss:3294.6364812677557 at iteration 219\n",
            "loss:3291.2930626502402 at iteration 220\n",
            "loss:3283.8723820866767 at iteration 221\n",
            "loss:3278.547750293407 at iteration 222\n",
            "loss:3275.835207802909 at iteration 223\n",
            "loss:3269.6612505425346 at iteration 224\n",
            "loss:3260.2681117775164 at iteration 225\n",
            "loss:3252.7962382984583 at iteration 226\n",
            "loss:3241.7752728378564 at iteration 227\n",
            "loss:3234.969450971445 at iteration 228\n",
            "loss:3230.3211059570312 at iteration 229\n",
            "loss:3228.179884609206 at iteration 230\n",
            "loss:3229.672882606243 at iteration 231\n",
            "loss:3227.260252334529 at iteration 232\n",
            "loss:3222.1678706764155 at iteration 233\n",
            "loss:3220.5553253823136 at iteration 234\n",
            "loss:3221.297656043101 at iteration 235\n",
            "loss:3222.17291749077 at iteration 236\n",
            "loss:3225.544810062697 at iteration 237\n",
            "loss:3219.5280562524517 at iteration 238\n",
            "loss:3213.044758097331 at iteration 239\n",
            "loss:3210.3603161063925 at iteration 240\n",
            "loss:3204.1960368511104 at iteration 241\n",
            "loss:3200.87416409465 at iteration 242\n",
            "loss:3195.649106885566 at iteration 243\n",
            "loss:3189.5470882493623 at iteration 244\n",
            "loss:3182.677720480818 at iteration 245\n",
            "loss:3174.507210550038 at iteration 246\n",
            "loss:3172.1822194745464 at iteration 247\n",
            "loss:3172.794963055346 at iteration 248\n",
            "loss:3168.02555078125 at iteration 249\n",
            "loss:3165.847416972734 at iteration 250\n",
            "loss:3165.578358483693 at iteration 251\n",
            "loss:3160.7861839565835 at iteration 252\n",
            "loss:3153.937979150006 at iteration 253\n",
            "loss:3144.6911563648896 at iteration 254\n",
            "loss:3139.53955411911 at iteration 255\n",
            "loss:3135.5092141711757 at iteration 256\n",
            "loss:3130.8830798245217 at iteration 257\n",
            "loss:3123.8414768528296 at iteration 258\n",
            "loss:3127.8970444899337 at iteration 259\n",
            "loss:3126.657320570672 at iteration 260\n",
            "loss:3119.995228541716 at iteration 261\n",
            "loss:3110.5246893008853 at iteration 262\n",
            "loss:3107.4611108953304 at iteration 263\n",
            "loss:3101.2640740160673 at iteration 264\n",
            "loss:3093.9109501659423 at iteration 265\n",
            "loss:3087.769390892 at iteration 266\n",
            "loss:3083.6790830697587 at iteration 267\n",
            "loss:3078.17346917475 at iteration 268\n",
            "loss:3070.0385913990162 at iteration 269\n",
            "loss:3065.715374372982 at iteration 270\n",
            "loss:3057.2585431267235 at iteration 271\n",
            "loss:3049.201832753835 at iteration 272\n",
            "loss:3042.761062510692 at iteration 273\n",
            "loss:3038.9590953480115 at iteration 274\n",
            "loss:3032.1840400142946 at iteration 275\n",
            "loss:3026.750066543744 at iteration 276\n",
            "loss:3022.158820941294 at iteration 277\n",
            "loss:3015.7686439432123 at iteration 278\n",
            "loss:3009.4907784598213 at iteration 279\n",
            "loss:3002.499142901329 at iteration 280\n",
            "loss:2997.445013384447 at iteration 281\n",
            "loss:2994.478803331355 at iteration 282\n",
            "loss:2991.906893448091 at iteration 283\n",
            "loss:2986.014246676261 at iteration 284\n",
            "loss:2979.040934529338 at iteration 285\n",
            "loss:2973.4960435608123 at iteration 286\n",
            "loss:2969.345091925727 at iteration 287\n",
            "loss:2968.646328091209 at iteration 288\n",
            "loss:2971.3204000538794 at iteration 289\n",
            "loss:2970.530620771585 at iteration 290\n",
            "epoch:  7\n",
            "loss:1964.8868408203125 at iteration 0\n",
            "loss:3561.7442016601562 at iteration 1\n",
            "loss:4558.7541097005205 at iteration 2\n",
            "loss:6091.489898681641 at iteration 3\n",
            "loss:5759.1636962890625 at iteration 4\n",
            "loss:5301.905700683594 at iteration 5\n",
            "loss:6723.236275809152 at iteration 6\n",
            "loss:7442.450271606445 at iteration 7\n",
            "loss:6850.8717854817705 at iteration 8\n",
            "loss:6343.160046386719 at iteration 9\n",
            "loss:6348.6143354936075 at iteration 10\n",
            "loss:6241.471913655599 at iteration 11\n",
            "loss:6057.126737154447 at iteration 12\n",
            "loss:6005.702087402344 at iteration 13\n",
            "loss:5921.9813232421875 at iteration 14\n",
            "loss:5886.513832092285 at iteration 15\n",
            "loss:5821.728580250459 at iteration 16\n",
            "loss:5819.768832736545 at iteration 17\n",
            "loss:6003.621819747122 at iteration 18\n",
            "loss:5984.343487548828 at iteration 19\n",
            "loss:5953.263491675967 at iteration 20\n",
            "loss:5854.905634099787 at iteration 21\n",
            "loss:5881.4125817340355 at iteration 22\n",
            "loss:5934.489547729492 at iteration 23\n",
            "loss:5773.957963867188 at iteration 24\n",
            "loss:5776.369812011719 at iteration 25\n",
            "loss:5825.486070421007 at iteration 26\n",
            "loss:5733.75494820731 at iteration 27\n",
            "loss:5730.417038490033 at iteration 28\n",
            "loss:5634.5762410481775 at iteration 29\n",
            "loss:5690.589658675655 at iteration 30\n",
            "loss:5771.937198638916 at iteration 31\n",
            "loss:5792.9122610381155 at iteration 32\n",
            "loss:5778.315031163833 at iteration 33\n",
            "loss:5748.602319335938 at iteration 34\n",
            "loss:5769.935862223308 at iteration 35\n",
            "loss:5654.509059596706 at iteration 36\n",
            "loss:5729.275165758635 at iteration 37\n",
            "loss:5743.40719526242 at iteration 38\n",
            "loss:5820.418133544922 at iteration 39\n",
            "loss:5848.908566358613 at iteration 40\n",
            "loss:5909.633492606027 at iteration 41\n",
            "loss:5859.953028479288 at iteration 42\n",
            "loss:5931.976556951349 at iteration 43\n",
            "loss:5900.461669921875 at iteration 44\n",
            "loss:5873.3982942000675 at iteration 45\n",
            "loss:5844.316286776928 at iteration 46\n",
            "loss:5849.9071706136065 at iteration 47\n",
            "loss:5952.850710499043 at iteration 48\n",
            "loss:5914.629116210937 at iteration 49\n",
            "loss:5842.551427504595 at iteration 50\n",
            "loss:5820.534700833834 at iteration 51\n",
            "loss:5814.2102695681015 at iteration 52\n",
            "loss:5868.32038031684 at iteration 53\n",
            "loss:5825.386110617897 at iteration 54\n",
            "loss:5767.9141191755025 at iteration 55\n",
            "loss:5715.479466488487 at iteration 56\n",
            "loss:5686.896555933459 at iteration 57\n",
            "loss:5633.749788963189 at iteration 58\n",
            "loss:5651.981498209635 at iteration 59\n",
            "loss:5624.237556832735 at iteration 60\n",
            "loss:5582.510045205393 at iteration 61\n",
            "loss:5523.593405102926 at iteration 62\n",
            "loss:5474.380035400391 at iteration 63\n",
            "loss:5426.46133188101 at iteration 64\n",
            "loss:5385.73886570786 at iteration 65\n",
            "loss:5322.2019389138295 at iteration 66\n",
            "loss:5277.942319982192 at iteration 67\n",
            "loss:5235.9597645635195 at iteration 68\n",
            "loss:5217.934293038505 at iteration 69\n",
            "loss:5196.357977208957 at iteration 70\n",
            "loss:5138.352587381999 at iteration 71\n",
            "loss:5102.175504501552 at iteration 72\n",
            "loss:5071.168447958456 at iteration 73\n",
            "loss:5029.46476155599 at iteration 74\n",
            "loss:5004.0589366712065 at iteration 75\n",
            "loss:4977.5897193016945 at iteration 76\n",
            "loss:4942.443111321865 at iteration 77\n",
            "loss:4922.541017942791 at iteration 78\n",
            "loss:4908.072063446045 at iteration 79\n",
            "loss:4873.383164394049 at iteration 80\n",
            "loss:4838.419861584175 at iteration 81\n",
            "loss:4806.613409938583 at iteration 82\n",
            "loss:4770.806173415411 at iteration 83\n",
            "loss:4743.217377786075 at iteration 84\n",
            "loss:4722.807092710983 at iteration 85\n",
            "loss:4704.914203512258 at iteration 86\n",
            "loss:4685.131736755371 at iteration 87\n",
            "loss:4641.53404870194 at iteration 88\n",
            "loss:4606.286282687717 at iteration 89\n",
            "loss:4585.924547803271 at iteration 90\n",
            "loss:4561.995959074601 at iteration 91\n",
            "loss:4545.838445191743 at iteration 92\n",
            "loss:4511.563196709815 at iteration 93\n",
            "loss:4478.002693899054 at iteration 94\n",
            "loss:4451.155131657918 at iteration 95\n",
            "loss:4437.641778375684 at iteration 96\n",
            "loss:4420.071885089485 at iteration 97\n",
            "loss:4398.745887216895 at iteration 98\n",
            "loss:4369.684021606446 at iteration 99\n",
            "loss:4347.097470727297 at iteration 100\n",
            "loss:4321.258999095244 at iteration 101\n",
            "loss:4303.343844219319 at iteration 102\n",
            "loss:4281.032193110539 at iteration 103\n",
            "loss:4251.357128324963 at iteration 104\n",
            "loss:4244.818833261166 at iteration 105\n",
            "loss:4222.899125999379 at iteration 106\n",
            "loss:4209.705507066515 at iteration 107\n",
            "loss:4181.24383656913 at iteration 108\n",
            "loss:4156.583887273615 at iteration 109\n",
            "loss:4125.421927237296 at iteration 110\n",
            "loss:4105.846259525844 at iteration 111\n",
            "loss:4089.959101584105 at iteration 112\n",
            "loss:4084.2888788591354 at iteration 113\n",
            "loss:4087.9461367399795 at iteration 114\n",
            "loss:4066.7333737077383 at iteration 115\n",
            "loss:4043.1632565229365 at iteration 116\n",
            "loss:4017.10739342641 at iteration 117\n",
            "loss:3998.327612612428 at iteration 118\n",
            "loss:3995.655076599121 at iteration 119\n",
            "loss:3989.7162203197636 at iteration 120\n",
            "loss:3962.650876404809 at iteration 121\n",
            "loss:3941.047924506955 at iteration 122\n",
            "loss:3927.975423997448 at iteration 123\n",
            "loss:3936.3398159179687 at iteration 124\n",
            "loss:3943.2186681353855 at iteration 125\n",
            "loss:3940.4310461329665 at iteration 126\n",
            "loss:3931.6409487724304 at iteration 127\n",
            "loss:3927.219516014868 at iteration 128\n",
            "loss:3931.002431546725 at iteration 129\n",
            "loss:3909.919612971881 at iteration 130\n",
            "loss:3896.074661254883 at iteration 131\n",
            "loss:3876.59345492026 at iteration 132\n",
            "loss:3869.142981230323 at iteration 133\n",
            "loss:3865.0359415690104 at iteration 134\n",
            "loss:3860.4026798921473 at iteration 135\n",
            "loss:3868.0842040124603 at iteration 136\n",
            "loss:3858.9961048070936 at iteration 137\n",
            "loss:3857.7261958499607 at iteration 138\n",
            "loss:3853.0179465157644 at iteration 139\n",
            "loss:3839.495947871648 at iteration 140\n",
            "loss:3828.1085682183925 at iteration 141\n",
            "loss:3830.9000606937007 at iteration 142\n",
            "loss:3845.7563930087617 at iteration 143\n",
            "loss:3855.8460209287446 at iteration 144\n",
            "loss:3851.9434609609107 at iteration 145\n",
            "loss:3854.5501912434897 at iteration 146\n",
            "loss:3845.828228512326 at iteration 147\n",
            "loss:3849.377229626547 at iteration 148\n",
            "loss:3848.6218534342447 at iteration 149\n",
            "loss:3848.7140090639227 at iteration 150\n",
            "loss:3847.3233638562656 at iteration 151\n",
            "loss:3846.8643834731156 at iteration 152\n",
            "loss:3848.1232446447593 at iteration 153\n",
            "loss:3848.3629359091483 at iteration 154\n",
            "loss:3836.5348139053735 at iteration 155\n",
            "loss:3836.7935398369077 at iteration 156\n",
            "loss:3834.358610515353 at iteration 157\n",
            "loss:3825.817928290217 at iteration 158\n",
            "loss:3808.660007095337 at iteration 159\n",
            "loss:3805.182011006041 at iteration 160\n",
            "loss:3794.5362748511043 at iteration 161\n",
            "loss:3781.362776867451 at iteration 162\n",
            "loss:3777.0774971566548 at iteration 163\n",
            "loss:3777.9799586440577 at iteration 164\n",
            "loss:3785.0042287068195 at iteration 165\n",
            "loss:3786.9284905530735 at iteration 166\n",
            "loss:3784.564316885812 at iteration 167\n",
            "loss:3776.8286251993572 at iteration 168\n",
            "loss:3762.0325069651885 at iteration 169\n",
            "loss:3747.5130354674934 at iteration 170\n",
            "loss:3733.9503432872684 at iteration 171\n",
            "loss:3718.7193564707145 at iteration 172\n",
            "loss:3705.7700444364 at iteration 173\n",
            "loss:3695.159957798549 at iteration 174\n",
            "loss:3679.2298788590865 at iteration 175\n",
            "loss:3663.916918048751 at iteration 176\n",
            "loss:3653.8924131929207 at iteration 177\n",
            "loss:3642.0291294545436 at iteration 178\n",
            "loss:3631.328913370768 at iteration 179\n",
            "loss:3621.9813458353115 at iteration 180\n",
            "loss:3612.102569580078 at iteration 181\n",
            "loss:3610.544310522861 at iteration 182\n",
            "loss:3602.332505931025 at iteration 183\n",
            "loss:3597.5909704259925 at iteration 184\n",
            "loss:3586.047109624391 at iteration 185\n",
            "loss:3576.4268410422587 at iteration 186\n",
            "loss:3573.6996638521236 at iteration 187\n",
            "loss:3568.4180200970363 at iteration 188\n",
            "loss:3555.907758210835 at iteration 189\n",
            "loss:3541.494862181978 at iteration 190\n",
            "loss:3534.5957457224526 at iteration 191\n",
            "loss:3525.8466689351926 at iteration 192\n",
            "loss:3514.244777404156 at iteration 193\n",
            "loss:3508.2109537760416 at iteration 194\n",
            "loss:3497.950222093232 at iteration 195\n",
            "loss:3485.7776963287197 at iteration 196\n",
            "loss:3479.2184004350142 at iteration 197\n",
            "loss:3469.0662130231235 at iteration 198\n",
            "loss:3457.366510620117 at iteration 199\n",
            "loss:3451.719084630558 at iteration 200\n",
            "loss:3438.325624371519 at iteration 201\n",
            "loss:3432.1570882562346 at iteration 202\n",
            "loss:3427.1520493451285 at iteration 203\n",
            "loss:3426.1643364138718 at iteration 204\n",
            "loss:3423.0492370012894 at iteration 205\n",
            "loss:3416.854782325634 at iteration 206\n",
            "loss:3414.845537625826 at iteration 207\n",
            "loss:3413.7619371916117 at iteration 208\n",
            "loss:3408.8188406808035 at iteration 209\n",
            "loss:3397.794221850933 at iteration 210\n",
            "loss:3393.4355031139444 at iteration 211\n",
            "loss:3387.436769870525 at iteration 212\n",
            "loss:3380.2501557252117 at iteration 213\n",
            "loss:3376.4035820539607 at iteration 214\n",
            "loss:3369.96331165455 at iteration 215\n",
            "loss:3358.635508735059 at iteration 216\n",
            "loss:3349.694726786482 at iteration 217\n",
            "loss:3341.2688211240725 at iteration 218\n",
            "loss:3329.69775279652 at iteration 219\n",
            "loss:3327.4688394814057 at iteration 220\n",
            "loss:3319.8878773182364 at iteration 221\n",
            "loss:3317.0332419904357 at iteration 222\n",
            "loss:3313.672200339181 at iteration 223\n",
            "loss:3307.60569390191 at iteration 224\n",
            "loss:3298.4676389441024 at iteration 225\n",
            "loss:3290.736199601631 at iteration 226\n",
            "loss:3279.7906550357216 at iteration 227\n",
            "loss:3272.868525209385 at iteration 228\n",
            "loss:3265.4327565068784 at iteration 229\n",
            "loss:3262.132165950098 at iteration 230\n",
            "loss:3260.818227044467 at iteration 231\n",
            "loss:3257.8845605154406 at iteration 232\n",
            "loss:3251.783642108624 at iteration 233\n",
            "loss:3251.351871831366 at iteration 234\n",
            "loss:3250.736134415966 at iteration 235\n",
            "loss:3249.733042785387 at iteration 236\n",
            "loss:3252.428668623211 at iteration 237\n",
            "loss:3247.4634777372353 at iteration 238\n",
            "loss:3241.074843597412 at iteration 239\n",
            "loss:3237.0648221217743 at iteration 240\n",
            "loss:3231.101881042985 at iteration 241\n",
            "loss:3230.779155966676 at iteration 242\n",
            "loss:3228.0677917980756 at iteration 243\n",
            "loss:3220.509615902025 at iteration 244\n",
            "loss:3213.590189367775 at iteration 245\n",
            "loss:3205.236195923346 at iteration 246\n",
            "loss:3202.6146400205553 at iteration 247\n",
            "loss:3203.7775920576837 at iteration 248\n",
            "loss:3198.1589919433595 at iteration 249\n",
            "loss:3195.251771964875 at iteration 250\n",
            "loss:3194.9931202237567 at iteration 251\n",
            "loss:3189.9184813970633 at iteration 252\n",
            "loss:3183.4942100705125 at iteration 253\n",
            "loss:3173.751188151042 at iteration 254\n",
            "loss:3169.640125274658 at iteration 255\n",
            "loss:3165.3202631018967 at iteration 256\n",
            "loss:3159.942336444707 at iteration 257\n",
            "loss:3153.0244093493607 at iteration 258\n",
            "loss:3155.7150794396034 at iteration 259\n",
            "loss:3154.4647511449352 at iteration 260\n",
            "loss:3147.6040733279165 at iteration 261\n",
            "loss:3137.7388333512804 at iteration 262\n",
            "loss:3132.9209509184866 at iteration 263\n",
            "loss:3127.5685309644014 at iteration 264\n",
            "loss:3120.686543859037 at iteration 265\n",
            "loss:3113.4816302467375 at iteration 266\n",
            "loss:3108.77775391536 at iteration 267\n",
            "loss:3102.3844327678466 at iteration 268\n",
            "loss:3094.580334020544 at iteration 269\n",
            "loss:3088.617919471431 at iteration 270\n",
            "loss:3079.784975612865 at iteration 271\n",
            "loss:3073.1592760470326 at iteration 272\n",
            "loss:3066.3808854374574 at iteration 273\n",
            "loss:3062.8904077148436 at iteration 274\n",
            "loss:3057.6707367827926 at iteration 275\n",
            "loss:3051.093127970231 at iteration 276\n",
            "loss:3045.927195377487 at iteration 277\n",
            "loss:3040.4336875997565 at iteration 278\n",
            "loss:3033.7226377214706 at iteration 279\n",
            "loss:3026.6655140941252 at iteration 280\n",
            "loss:3021.341199293204 at iteration 281\n",
            "loss:3018.9397212052095 at iteration 282\n",
            "loss:3015.2871676162936 at iteration 283\n",
            "loss:3008.834361079701 at iteration 284\n",
            "loss:3002.0249708482434 at iteration 285\n",
            "loss:2996.013942173549 at iteration 286\n",
            "loss:2991.574123594496 at iteration 287\n",
            "loss:2992.0504439726833 at iteration 288\n",
            "loss:2993.9480273016566 at iteration 289\n",
            "loss:2991.360499011692 at iteration 290\n",
            "epoch:  8\n",
            "loss:2457.02734375 at iteration 0\n",
            "loss:4203.151123046875 at iteration 1\n",
            "loss:4823.73681640625 at iteration 2\n",
            "loss:6267.2864990234375 at iteration 3\n",
            "loss:5790.011328125 at iteration 4\n",
            "loss:5471.810791015625 at iteration 5\n",
            "loss:6879.764578683035 at iteration 6\n",
            "loss:7343.785095214844 at iteration 7\n",
            "loss:6797.477457682292 at iteration 8\n",
            "loss:6316.243359375 at iteration 9\n",
            "loss:6332.766512784091 at iteration 10\n",
            "loss:6171.7421468098955 at iteration 11\n",
            "loss:6002.836632361779 at iteration 12\n",
            "loss:5906.469744001116 at iteration 13\n",
            "loss:5795.232763671875 at iteration 14\n",
            "loss:5765.799118041992 at iteration 15\n",
            "loss:5735.667207605698 at iteration 16\n",
            "loss:5770.242987738715 at iteration 17\n",
            "loss:5979.815314041941 at iteration 18\n",
            "loss:5979.455798339844 at iteration 19\n",
            "loss:5956.1984630766365 at iteration 20\n",
            "loss:5872.0448885830965 at iteration 21\n",
            "loss:5918.438062584918 at iteration 22\n",
            "loss:5916.483428955078 at iteration 23\n",
            "loss:5754.084130859375 at iteration 24\n",
            "loss:5771.964665339543 at iteration 25\n",
            "loss:5760.933566623264 at iteration 26\n",
            "loss:5682.231140136719 at iteration 27\n",
            "loss:5686.524776064116 at iteration 28\n",
            "loss:5600.431901041667 at iteration 29\n",
            "loss:5661.505906628025 at iteration 30\n",
            "loss:5744.089553833008 at iteration 31\n",
            "loss:5751.186212713068 at iteration 32\n",
            "loss:5757.130557789522 at iteration 33\n",
            "loss:5714.998674665178 at iteration 34\n",
            "loss:5717.8831787109375 at iteration 35\n",
            "loss:5618.6402653874575 at iteration 36\n",
            "loss:5690.370075426604 at iteration 37\n",
            "loss:5712.894352839543 at iteration 38\n",
            "loss:5796.748800659179 at iteration 39\n",
            "loss:5818.374318192645 at iteration 40\n",
            "loss:5855.280165899368 at iteration 41\n",
            "loss:5780.21378486101 at iteration 42\n",
            "loss:5900.352525190873 at iteration 43\n",
            "loss:5866.942043728299 at iteration 44\n",
            "loss:5836.013446310292 at iteration 45\n",
            "loss:5789.023689432347 at iteration 46\n",
            "loss:5798.672345479329 at iteration 47\n",
            "loss:5904.891384825414 at iteration 48\n",
            "loss:5875.6942211914065 at iteration 49\n",
            "loss:5806.087031345742 at iteration 50\n",
            "loss:5786.070502647986 at iteration 51\n",
            "loss:5757.368875755454 at iteration 52\n",
            "loss:5834.948144983362 at iteration 53\n",
            "loss:5808.674434037642 at iteration 54\n",
            "loss:5747.277720860073 at iteration 55\n",
            "loss:5701.318974009731 at iteration 56\n",
            "loss:5654.76859467605 at iteration 57\n",
            "loss:5600.909765211202 at iteration 58\n",
            "loss:5607.48032023112 at iteration 59\n",
            "loss:5579.639090115907 at iteration 60\n",
            "loss:5530.339700022051 at iteration 61\n",
            "loss:5469.7719319661455 at iteration 62\n",
            "loss:5427.634878158569 at iteration 63\n",
            "loss:5381.680387995793 at iteration 64\n",
            "loss:5342.361899636008 at iteration 65\n",
            "loss:5296.824869184352 at iteration 66\n",
            "loss:5251.940230425666 at iteration 67\n",
            "loss:5205.8132271144705 at iteration 68\n",
            "loss:5175.527317592076 at iteration 69\n",
            "loss:5153.082552197953 at iteration 70\n",
            "loss:5103.03427971734 at iteration 71\n",
            "loss:5064.164087582941 at iteration 72\n",
            "loss:5028.368159113704 at iteration 73\n",
            "loss:4994.6419287109375 at iteration 74\n",
            "loss:4961.226766485917 at iteration 75\n",
            "loss:4931.328839983259 at iteration 76\n",
            "loss:4895.535339355469 at iteration 77\n",
            "loss:4869.516773079015 at iteration 78\n",
            "loss:4849.729551696777 at iteration 79\n",
            "loss:4828.526522412712 at iteration 80\n",
            "loss:4797.898903451315 at iteration 81\n",
            "loss:4784.009040556758 at iteration 82\n",
            "loss:4755.9173918224515 at iteration 83\n",
            "loss:4727.734588982077 at iteration 84\n",
            "loss:4713.066015908885 at iteration 85\n",
            "loss:4689.951291139098 at iteration 86\n",
            "loss:4667.07327409224 at iteration 87\n",
            "loss:4625.190083364422 at iteration 88\n",
            "loss:4590.463144938151 at iteration 89\n",
            "loss:4569.258986923721 at iteration 90\n",
            "loss:4542.9364272407865 at iteration 91\n",
            "loss:4523.0447164556035 at iteration 92\n",
            "loss:4488.369941224443 at iteration 93\n",
            "loss:4456.447676166736 at iteration 94\n",
            "loss:4429.821481704712 at iteration 95\n",
            "loss:4419.474671668613 at iteration 96\n",
            "loss:4400.298381571867 at iteration 97\n",
            "loss:4382.104442249645 at iteration 98\n",
            "loss:4356.754765014648 at iteration 99\n",
            "loss:4343.381675795754 at iteration 100\n",
            "loss:4318.413355808632 at iteration 101\n",
            "loss:4300.325109389222 at iteration 102\n",
            "loss:4274.021879342886 at iteration 103\n",
            "loss:4240.42201625279 at iteration 104\n",
            "loss:4227.981129196455 at iteration 105\n",
            "loss:4202.233661402051 at iteration 106\n",
            "loss:4194.566083554869 at iteration 107\n",
            "loss:4164.680681981078 at iteration 108\n",
            "loss:4143.7032703746445 at iteration 109\n",
            "loss:4113.277368493982 at iteration 110\n",
            "loss:4088.723500388009 at iteration 111\n",
            "loss:4070.9495196047083 at iteration 112\n",
            "loss:4064.5613033897 at iteration 113\n",
            "loss:4068.11936831267 at iteration 114\n",
            "loss:4050.206666617558 at iteration 115\n",
            "loss:4027.7843638363047 at iteration 116\n",
            "loss:4003.975099207991 at iteration 117\n",
            "loss:3983.963347619321 at iteration 118\n",
            "loss:3980.8457778930665 at iteration 119\n",
            "loss:3967.213079783542 at iteration 120\n",
            "loss:3942.785891173316 at iteration 121\n",
            "loss:3921.6671623912284 at iteration 122\n",
            "loss:3905.908853346302 at iteration 123\n",
            "loss:3909.154762207031 at iteration 124\n",
            "loss:3920.404572502015 at iteration 125\n",
            "loss:3922.1476267416647 at iteration 126\n",
            "loss:3916.1802067756653 at iteration 127\n",
            "loss:3911.888146215631 at iteration 128\n",
            "loss:3920.7633756197415 at iteration 129\n",
            "loss:3900.481497961146 at iteration 130\n",
            "loss:3886.1479672518644 at iteration 131\n",
            "loss:3866.0039828881286 at iteration 132\n",
            "loss:3855.0845359688374 at iteration 133\n",
            "loss:3848.8661905924478 at iteration 134\n",
            "loss:3847.0174627865063 at iteration 135\n",
            "loss:3854.778095328895 at iteration 136\n",
            "loss:3846.1660594110904 at iteration 137\n",
            "loss:3845.169868743677 at iteration 138\n",
            "loss:3840.3178427559988 at iteration 139\n",
            "loss:3827.9073456026986 at iteration 140\n",
            "loss:3819.1651383520853 at iteration 141\n",
            "loss:3821.1717618928924 at iteration 142\n",
            "loss:3834.902204301622 at iteration 143\n",
            "loss:3845.1940156081628 at iteration 144\n",
            "loss:3841.6987802165827 at iteration 145\n",
            "loss:3843.312640754544 at iteration 146\n",
            "loss:3833.7093699687234 at iteration 147\n",
            "loss:3840.177245684118 at iteration 148\n",
            "loss:3840.8523563639324 at iteration 149\n",
            "loss:3843.616275206307 at iteration 150\n",
            "loss:3840.9661042062858 at iteration 151\n",
            "loss:3835.251572951772 at iteration 152\n",
            "loss:3836.596733192345 at iteration 153\n",
            "loss:3840.0233236989666 at iteration 154\n",
            "loss:3832.8796038505357 at iteration 155\n",
            "loss:3833.5610580930284 at iteration 156\n",
            "loss:3830.2489797857743 at iteration 157\n",
            "loss:3819.2770147743463 at iteration 158\n",
            "loss:3803.918599319458 at iteration 159\n",
            "loss:3804.0471574297603 at iteration 160\n",
            "loss:3795.9420064290366 at iteration 161\n",
            "loss:3784.0362110723017 at iteration 162\n",
            "loss:3782.6942365692885 at iteration 163\n",
            "loss:3783.404988236861 at iteration 164\n",
            "loss:3791.726167242211 at iteration 165\n",
            "loss:3796.2425898934553 at iteration 166\n",
            "loss:3794.816473461333 at iteration 167\n",
            "loss:3787.1333545933107 at iteration 168\n",
            "loss:3771.652805103975 at iteration 169\n",
            "loss:3755.5829053733783 at iteration 170\n",
            "loss:3740.5406767379404 at iteration 171\n",
            "loss:3725.6674885832504 at iteration 172\n",
            "loss:3711.1239676639952 at iteration 173\n",
            "loss:3698.637024623326 at iteration 174\n",
            "loss:3681.4724675958805 at iteration 175\n",
            "loss:3666.633171124647 at iteration 176\n",
            "loss:3653.3482741452335 at iteration 177\n",
            "loss:3645.3290545074633 at iteration 178\n",
            "loss:3631.2832302517363 at iteration 179\n",
            "loss:3622.4857885877072 at iteration 180\n",
            "loss:3613.073276394016 at iteration 181\n",
            "loss:3610.925865965463 at iteration 182\n",
            "loss:3603.7379674496856 at iteration 183\n",
            "loss:3599.824346099029 at iteration 184\n",
            "loss:3588.5896763955393 at iteration 185\n",
            "loss:3582.2266950148314 at iteration 186\n",
            "loss:3578.8324214854138 at iteration 187\n",
            "loss:3571.9277117693864 at iteration 188\n",
            "loss:3559.0316727487666 at iteration 189\n",
            "loss:3544.5381377055382 at iteration 190\n",
            "loss:3537.4943358103433 at iteration 191\n",
            "loss:3526.7152845946002 at iteration 192\n",
            "loss:3512.259944955098 at iteration 193\n",
            "loss:3508.3135009765624 at iteration 194\n",
            "loss:3498.8121431311783 at iteration 195\n",
            "loss:3487.151376482194 at iteration 196\n",
            "loss:3483.7704726710463 at iteration 197\n",
            "loss:3474.665470295815 at iteration 198\n",
            "loss:3462.892944946289 at iteration 199\n",
            "loss:3455.597785608092 at iteration 200\n",
            "loss:3442.623914661974 at iteration 201\n",
            "loss:3436.7954161695657 at iteration 202\n",
            "loss:3435.6137743183212 at iteration 203\n",
            "loss:3431.1776736375764 at iteration 204\n",
            "loss:3430.165590156629 at iteration 205\n",
            "loss:3422.1623287477355 at iteration 206\n",
            "loss:3416.8787818321816 at iteration 207\n",
            "loss:3416.9577122738488 at iteration 208\n",
            "loss:3411.2000778924853 at iteration 209\n",
            "loss:3398.4528736277216 at iteration 210\n",
            "loss:3395.66862833275 at iteration 211\n",
            "loss:3388.9636353685264 at iteration 212\n",
            "loss:3382.9095239371895 at iteration 213\n",
            "loss:3378.4948716274525 at iteration 214\n",
            "loss:3373.8808534410264 at iteration 215\n",
            "loss:3363.660591371598 at iteration 216\n",
            "loss:3354.8382056000037 at iteration 217\n",
            "loss:3344.812399946936 at iteration 218\n",
            "loss:3332.6470700350674 at iteration 219\n",
            "loss:3333.698103822734 at iteration 220\n",
            "loss:3327.152372068113 at iteration 221\n",
            "loss:3324.5168071113894 at iteration 222\n",
            "loss:3321.4454506465368 at iteration 223\n",
            "loss:3315.5210842556426 at iteration 224\n",
            "loss:3306.9497775187533 at iteration 225\n",
            "loss:3298.768943215257 at iteration 226\n",
            "loss:3287.0293798613966 at iteration 227\n",
            "loss:3278.6857371767537 at iteration 228\n",
            "loss:3272.7543005901834 at iteration 229\n",
            "loss:3270.8058516597334 at iteration 230\n",
            "loss:3271.38471037766 at iteration 231\n",
            "loss:3269.045621290739 at iteration 232\n",
            "loss:3264.3523862137754 at iteration 233\n",
            "loss:3262.383706470246 at iteration 234\n",
            "loss:3263.311559127549 at iteration 235\n",
            "loss:3263.2580859993077 at iteration 236\n",
            "loss:3266.072329737559 at iteration 237\n",
            "loss:3260.1088596487643 at iteration 238\n",
            "loss:3253.324637858073 at iteration 239\n",
            "loss:3247.7498495648015 at iteration 240\n",
            "loss:3241.275283182948 at iteration 241\n",
            "loss:3236.1573601867926 at iteration 242\n",
            "loss:3236.3913204005507 at iteration 243\n",
            "loss:3228.8302664620537 at iteration 244\n",
            "loss:3222.265093051321 at iteration 245\n",
            "loss:3213.5799328267335 at iteration 246\n",
            "loss:3210.9979887931577 at iteration 247\n",
            "loss:3211.228300898908 at iteration 248\n",
            "loss:3203.590705078125 at iteration 249\n",
            "loss:3199.375992125249 at iteration 250\n",
            "loss:3198.5698445638022 at iteration 251\n",
            "loss:3192.1257565464425 at iteration 252\n",
            "loss:3184.61098017655 at iteration 253\n",
            "loss:3174.4309029373467 at iteration 254\n",
            "loss:3169.3676567077637 at iteration 255\n",
            "loss:3165.2390497704887 at iteration 256\n",
            "loss:3160.1760854794998 at iteration 257\n",
            "loss:3152.652996048504 at iteration 258\n",
            "loss:3155.555489408053 at iteration 259\n",
            "loss:3153.6007309252277 at iteration 260\n",
            "loss:3145.408376446207 at iteration 261\n",
            "loss:3135.371986302133 at iteration 262\n",
            "loss:3130.319170402758 at iteration 263\n",
            "loss:3124.599923533314 at iteration 264\n",
            "loss:3117.0167851268798 at iteration 265\n",
            "loss:3110.0890116602295 at iteration 266\n",
            "loss:3105.8046938768075 at iteration 267\n",
            "loss:3099.960559944238 at iteration 268\n",
            "loss:3091.9983041268806 at iteration 269\n",
            "loss:3085.598492724429 at iteration 270\n",
            "loss:3076.8679549273324 at iteration 271\n",
            "loss:3069.14941629822 at iteration 272\n",
            "loss:3061.8640292647983 at iteration 273\n",
            "loss:3057.754034978693 at iteration 274\n",
            "loss:3050.8338822074556 at iteration 275\n",
            "loss:3044.3458957052403 at iteration 276\n",
            "loss:3039.0036629875785 at iteration 277\n",
            "loss:3034.771768768201 at iteration 278\n",
            "loss:3028.2565721784317 at iteration 279\n",
            "loss:3020.3999225439975 at iteration 280\n",
            "loss:3015.3316392830925 at iteration 281\n",
            "loss:3012.002676272982 at iteration 282\n",
            "loss:3008.6001060378385 at iteration 283\n",
            "loss:3002.6804642526727 at iteration 284\n",
            "loss:2995.771429101904 at iteration 285\n",
            "loss:2989.7611860215457 at iteration 286\n",
            "loss:2985.443797853258 at iteration 287\n",
            "loss:2986.2217246718883 at iteration 288\n",
            "loss:2988.764252971781 at iteration 289\n",
            "loss:2986.7970883084326 at iteration 290\n",
            "epoch:  9\n",
            "loss:2738.996337890625 at iteration 0\n",
            "loss:4254.8863525390625 at iteration 1\n",
            "loss:4711.338134765625 at iteration 2\n",
            "loss:6513.962585449219 at iteration 3\n",
            "loss:5877.772509765625 at iteration 4\n",
            "loss:5421.2937418619795 at iteration 5\n",
            "loss:6898.446812220982 at iteration 6\n",
            "loss:7511.781951904297 at iteration 7\n",
            "loss:6956.950764973958 at iteration 8\n",
            "loss:6479.689282226563 at iteration 9\n",
            "loss:6588.884876598011 at iteration 10\n",
            "loss:6462.509541829427 at iteration 11\n",
            "loss:6267.797006460337 at iteration 12\n",
            "loss:6211.491646902902 at iteration 13\n",
            "loss:6083.248486328125 at iteration 14\n",
            "loss:6054.386581420898 at iteration 15\n",
            "loss:6007.710836971507 at iteration 16\n",
            "loss:6030.4398193359375 at iteration 17\n",
            "loss:6205.43070261102 at iteration 18\n",
            "loss:6225.790490722657 at iteration 19\n",
            "loss:6171.275960286458 at iteration 20\n",
            "loss:6074.551424893466 at iteration 21\n",
            "loss:6221.024859884511 at iteration 22\n",
            "loss:6183.101155598958 at iteration 23\n",
            "loss:6002.674111328125 at iteration 24\n",
            "loss:5995.930598332332 at iteration 25\n",
            "loss:5988.676947699652 at iteration 26\n",
            "loss:5904.476292201451 at iteration 27\n",
            "loss:5939.175385573814 at iteration 28\n",
            "loss:5832.899438476563 at iteration 29\n",
            "loss:5889.075707220262 at iteration 30\n",
            "loss:5931.9272384643555 at iteration 31\n",
            "loss:5975.776492956913 at iteration 32\n",
            "loss:5957.522884593291 at iteration 33\n",
            "loss:5923.289976283482 at iteration 34\n",
            "loss:5929.867560492621 at iteration 35\n",
            "loss:5833.089375263936 at iteration 36\n",
            "loss:5845.7556987561675 at iteration 37\n",
            "loss:5824.846185146234 at iteration 38\n",
            "loss:5895.296661376953 at iteration 39\n",
            "loss:5908.801382669589 at iteration 40\n",
            "loss:5960.799543108259 at iteration 41\n",
            "loss:5901.130637945131 at iteration 42\n",
            "loss:6037.995988325639 at iteration 43\n",
            "loss:5995.376904296875 at iteration 44\n",
            "loss:5943.2316523012905 at iteration 45\n",
            "loss:5907.906494140625 at iteration 46\n",
            "loss:5913.530471801758 at iteration 47\n",
            "loss:5987.335952447385 at iteration 48\n",
            "loss:5946.101821289062 at iteration 49\n",
            "loss:5878.699505974265 at iteration 50\n",
            "loss:5854.1618088942305 at iteration 51\n",
            "loss:5850.6860996462265 at iteration 52\n",
            "loss:5895.269495081018 at iteration 53\n",
            "loss:5867.836798650568 at iteration 54\n",
            "loss:5811.927228655134 at iteration 55\n",
            "loss:5764.438378049616 at iteration 56\n",
            "loss:5723.386318864494 at iteration 57\n",
            "loss:5674.2542621159955 at iteration 58\n",
            "loss:5688.686222330729 at iteration 59\n",
            "loss:5655.813528592469 at iteration 60\n",
            "loss:5604.803888136341 at iteration 61\n",
            "loss:5541.236126612103 at iteration 62\n",
            "loss:5494.255023956299 at iteration 63\n",
            "loss:5445.899492938702 at iteration 64\n",
            "loss:5405.988022312973 at iteration 65\n",
            "loss:5350.390282474347 at iteration 66\n",
            "loss:5303.156041762408 at iteration 67\n",
            "loss:5262.350868999094 at iteration 68\n",
            "loss:5228.898577008928 at iteration 69\n",
            "loss:5207.404620103433 at iteration 70\n",
            "loss:5149.42079840766 at iteration 71\n",
            "loss:5112.95524367241 at iteration 72\n",
            "loss:5091.342659615181 at iteration 73\n",
            "loss:5057.8522151692705 at iteration 74\n",
            "loss:5024.39874428197 at iteration 75\n",
            "loss:4989.7051780007105 at iteration 76\n",
            "loss:4952.509169358474 at iteration 77\n",
            "loss:4919.342033289656 at iteration 78\n",
            "loss:4904.862898254394 at iteration 79\n",
            "loss:4878.3575921706215 at iteration 80\n",
            "loss:4849.164781523914 at iteration 81\n",
            "loss:4818.707032720727 at iteration 82\n",
            "loss:4787.602191743396 at iteration 83\n",
            "loss:4756.464336799173 at iteration 84\n",
            "loss:4734.926818847656 at iteration 85\n",
            "loss:4718.0365804036455 at iteration 86\n",
            "loss:4698.113740400834 at iteration 87\n",
            "loss:4653.497543506408 at iteration 88\n",
            "loss:4615.619759114584 at iteration 89\n",
            "loss:4601.459418998969 at iteration 90\n",
            "loss:4574.949354088824 at iteration 91\n",
            "loss:4559.815539944557 at iteration 92\n",
            "loss:4525.1261505776265 at iteration 93\n",
            "loss:4496.292693770559 at iteration 94\n",
            "loss:4468.836334228516 at iteration 95\n",
            "loss:4460.88294337951 at iteration 96\n",
            "loss:4441.774815150669 at iteration 97\n",
            "loss:4419.803091954704 at iteration 98\n",
            "loss:4388.991134033203 at iteration 99\n",
            "loss:4373.521391311495 at iteration 100\n",
            "loss:4348.102979473039 at iteration 101\n",
            "loss:4330.454099192203 at iteration 102\n",
            "loss:4303.363102839543 at iteration 103\n",
            "loss:4269.1192661830355 at iteration 104\n",
            "loss:4259.595986420253 at iteration 105\n",
            "loss:4234.190088575131 at iteration 106\n",
            "loss:4227.715945773654 at iteration 107\n",
            "loss:4196.955717034296 at iteration 108\n",
            "loss:4174.9229397860445 at iteration 109\n",
            "loss:4144.627807067322 at iteration 110\n",
            "loss:4122.860322679792 at iteration 111\n",
            "loss:4106.764083997338 at iteration 112\n",
            "loss:4105.277495267099 at iteration 113\n",
            "loss:4109.173269255265 at iteration 114\n",
            "loss:4088.9154994569976 at iteration 115\n",
            "loss:4064.134767190004 at iteration 116\n",
            "loss:4036.7034141411214 at iteration 117\n",
            "loss:4016.6673671177455 at iteration 118\n",
            "loss:4012.8837214152018 at iteration 119\n",
            "loss:4005.3758731558305 at iteration 120\n",
            "loss:3978.047782022445 at iteration 121\n",
            "loss:3958.5757436364647 at iteration 122\n",
            "loss:3952.2122984855405 at iteration 123\n",
            "loss:3958.3930219726562 at iteration 124\n",
            "loss:3960.154578314887 at iteration 125\n",
            "loss:3967.4989181879 at iteration 126\n",
            "loss:3964.684643268585 at iteration 127\n",
            "loss:3961.674137085907 at iteration 128\n",
            "loss:3966.0305649977463 at iteration 129\n",
            "loss:3944.7223128690066 at iteration 130\n",
            "loss:3929.112613099994 at iteration 131\n",
            "loss:3909.4953397593104 at iteration 132\n",
            "loss:3897.5319099995627 at iteration 133\n",
            "loss:3892.9762754087096 at iteration 134\n",
            "loss:3889.3770235847023 at iteration 135\n",
            "loss:3897.4023495416573 at iteration 136\n",
            "loss:3887.829906961192 at iteration 137\n",
            "loss:3887.668980879749 at iteration 138\n",
            "loss:3883.5138432094027 at iteration 139\n",
            "loss:3871.827555771415 at iteration 140\n",
            "loss:3856.401140669702 at iteration 141\n",
            "loss:3855.940687913161 at iteration 142\n",
            "loss:3867.9833056131997 at iteration 143\n",
            "loss:3878.3242646316003 at iteration 144\n",
            "loss:3875.297144641615 at iteration 145\n",
            "loss:3878.3328936310854 at iteration 146\n",
            "loss:3867.809587220888 at iteration 147\n",
            "loss:3872.0673635597996 at iteration 148\n",
            "loss:3869.8065970865887 at iteration 149\n",
            "loss:3872.6983444517023 at iteration 150\n",
            "loss:3870.375464589972 at iteration 151\n",
            "loss:3868.679395887587 at iteration 152\n",
            "loss:3868.6126348322086 at iteration 153\n",
            "loss:3870.149304199219 at iteration 154\n",
            "loss:3861.7205798809346 at iteration 155\n",
            "loss:3860.4812248861713 at iteration 156\n",
            "loss:3860.8265863732445 at iteration 157\n",
            "loss:3852.6205183305083 at iteration 158\n",
            "loss:3835.9091564178466 at iteration 159\n",
            "loss:3836.2331266225497 at iteration 160\n",
            "loss:3826.629703097873 at iteration 161\n",
            "loss:3814.6001077663677 at iteration 162\n",
            "loss:3811.8482037055783 at iteration 163\n",
            "loss:3811.7154189601088 at iteration 164\n",
            "loss:3818.4200053387376 at iteration 165\n",
            "loss:3817.184457379187 at iteration 166\n",
            "loss:3815.961871555873 at iteration 167\n",
            "loss:3807.448623205783 at iteration 168\n",
            "loss:3792.4386269962088 at iteration 169\n",
            "loss:3777.3873894228573 at iteration 170\n",
            "loss:3760.5489462919013 at iteration 171\n",
            "loss:3747.11796472803 at iteration 172\n",
            "loss:3735.9718708608343 at iteration 173\n",
            "loss:3724.6378867885046 at iteration 174\n",
            "loss:3708.9346157420764 at iteration 175\n",
            "loss:3692.956208827132 at iteration 176\n",
            "loss:3678.6792990009435 at iteration 177\n",
            "loss:3669.516059065664 at iteration 178\n",
            "loss:3655.636262681749 at iteration 179\n",
            "loss:3647.4934982384107 at iteration 180\n",
            "loss:3635.8870457240514 at iteration 181\n",
            "loss:3630.1048787434897 at iteration 182\n",
            "loss:3623.941457665485 at iteration 183\n",
            "loss:3619.677834340688 at iteration 184\n",
            "loss:3606.5701015021214 at iteration 185\n",
            "loss:3602.545842624603 at iteration 186\n",
            "loss:3598.326509840945 at iteration 187\n",
            "loss:3591.0638902452256 at iteration 188\n",
            "loss:3577.2243935032893 at iteration 189\n",
            "loss:3563.386397596429 at iteration 190\n",
            "loss:3558.0734071731567 at iteration 191\n",
            "loss:3547.5284901357068 at iteration 192\n",
            "loss:3533.765727878846 at iteration 193\n",
            "loss:3529.939325107672 at iteration 194\n",
            "loss:3521.0071320825696 at iteration 195\n",
            "loss:3509.881301492604 at iteration 196\n",
            "loss:3505.0427378644845 at iteration 197\n",
            "loss:3494.906054626158 at iteration 198\n",
            "loss:3481.2351776123046 at iteration 199\n",
            "loss:3472.453519147427 at iteration 200\n",
            "loss:3460.6106059763692 at iteration 201\n",
            "loss:3454.424415625962 at iteration 202\n",
            "loss:3451.209664737477 at iteration 203\n",
            "loss:3446.3244884956175 at iteration 204\n",
            "loss:3443.2344810708055 at iteration 205\n",
            "loss:3435.051366833673 at iteration 206\n",
            "loss:3428.9654100858247 at iteration 207\n",
            "loss:3430.572275554164 at iteration 208\n",
            "loss:3423.5586640857514 at iteration 209\n",
            "loss:3412.896712895253 at iteration 210\n",
            "loss:3407.8203165306236 at iteration 211\n",
            "loss:3402.403562733825 at iteration 212\n",
            "loss:3394.7963513525847 at iteration 213\n",
            "loss:3392.3510651344477 at iteration 214\n",
            "loss:3384.0027138038918 at iteration 215\n",
            "loss:3372.665670790431 at iteration 216\n",
            "loss:3362.133431250896 at iteration 217\n",
            "loss:3352.87288968857 at iteration 218\n",
            "loss:3340.342322332209 at iteration 219\n",
            "loss:3335.843626824979 at iteration 220\n",
            "loss:3330.395439079216 at iteration 221\n",
            "loss:3326.23722859883 at iteration 222\n",
            "loss:3323.832224709647 at iteration 223\n",
            "loss:3315.4965093315973 at iteration 224\n",
            "loss:3305.6387977262516 at iteration 225\n",
            "loss:3296.4615107464897 at iteration 226\n",
            "loss:3285.757290488795 at iteration 227\n",
            "loss:3279.0458371358145 at iteration 228\n",
            "loss:3273.5576676078463 at iteration 229\n",
            "loss:3270.9953164104777 at iteration 230\n",
            "loss:3273.7956821836274 at iteration 231\n",
            "loss:3271.1259540345022 at iteration 232\n",
            "loss:3264.6732182951055 at iteration 233\n",
            "loss:3261.6153751454453 at iteration 234\n",
            "loss:3263.9490351272843 at iteration 235\n",
            "loss:3263.590882635318 at iteration 236\n",
            "loss:3267.726716883042 at iteration 237\n",
            "loss:3261.193190826033 at iteration 238\n",
            "loss:3255.209184773763 at iteration 239\n",
            "loss:3251.028810619813 at iteration 240\n",
            "loss:3245.072503208129 at iteration 241\n",
            "loss:3243.148283279482 at iteration 242\n",
            "loss:3240.8408548323832 at iteration 243\n",
            "loss:3233.631405452806 at iteration 244\n",
            "loss:3226.206389636528 at iteration 245\n",
            "loss:3217.5031298432755 at iteration 246\n",
            "loss:3214.528386762065 at iteration 247\n",
            "loss:3214.802890762268 at iteration 248\n",
            "loss:3208.808349609375 at iteration 249\n",
            "loss:3205.1003233161105 at iteration 250\n",
            "loss:3204.643767826141 at iteration 251\n",
            "loss:3199.1912407554655 at iteration 252\n",
            "loss:3193.709257831724 at iteration 253\n",
            "loss:3184.5659608130363 at iteration 254\n",
            "loss:3179.921849966049 at iteration 255\n",
            "loss:3175.7255648008118 at iteration 256\n",
            "loss:3169.972399571145 at iteration 257\n",
            "loss:3162.7545149519638 at iteration 258\n",
            "loss:3163.4136979323166 at iteration 259\n",
            "loss:3161.6168954198843 at iteration 260\n",
            "loss:3153.372153478724 at iteration 261\n",
            "loss:3143.1593848398884 at iteration 262\n",
            "loss:3139.2588454737806 at iteration 263\n",
            "loss:3134.3515353220814 at iteration 264\n",
            "loss:3125.915896767064 at iteration 265\n",
            "loss:3119.325839496284 at iteration 266\n",
            "loss:3114.459406610745 at iteration 267\n",
            "loss:3109.1564846109723 at iteration 268\n",
            "loss:3099.9474062319155 at iteration 269\n",
            "loss:3094.2027389695286 at iteration 270\n",
            "loss:3086.8407700482535 at iteration 271\n",
            "loss:3079.282543140453 at iteration 272\n",
            "loss:3072.122502459227 at iteration 273\n",
            "loss:3068.294616033381 at iteration 274\n",
            "loss:3062.2604918549027 at iteration 275\n",
            "loss:3056.3742609678193 at iteration 276\n",
            "loss:3051.92101040847 at iteration 277\n",
            "loss:3045.766919645357 at iteration 278\n",
            "loss:3039.147218976702 at iteration 279\n",
            "loss:3031.8148189015237 at iteration 280\n",
            "loss:3027.024588943373 at iteration 281\n",
            "loss:3025.8318173034454 at iteration 282\n",
            "loss:3022.807169309804 at iteration 283\n",
            "loss:3016.0712115371434 at iteration 284\n",
            "loss:3008.419052444138 at iteration 285\n",
            "loss:3002.3714825035386 at iteration 286\n",
            "loss:2997.239437950982 at iteration 287\n",
            "loss:2995.6132740693934 at iteration 288\n",
            "loss:2998.5492587385506 at iteration 289\n",
            "loss:2997.5714832843373 at iteration 290\n",
            "epoch:  10\n",
            "loss:1848.675048828125 at iteration 0\n",
            "loss:4082.7259521484375 at iteration 1\n",
            "loss:4605.635009765625 at iteration 2\n",
            "loss:5840.235046386719 at iteration 3\n",
            "loss:5400.935107421875 at iteration 4\n",
            "loss:5065.3228759765625 at iteration 5\n",
            "loss:6524.123291015625 at iteration 6\n",
            "loss:7238.814544677734 at iteration 7\n",
            "loss:6776.742485894098 at iteration 8\n",
            "loss:6327.803686523437 at iteration 9\n",
            "loss:6343.517644708807 at iteration 10\n",
            "loss:6183.174540201823 at iteration 11\n",
            "loss:6011.078500600962 at iteration 12\n",
            "loss:5986.961879185268 at iteration 13\n",
            "loss:5850.368880208333 at iteration 14\n",
            "loss:5789.907196044922 at iteration 15\n",
            "loss:5721.731014476103 at iteration 16\n",
            "loss:5771.391248914931 at iteration 17\n",
            "loss:5979.722013774671 at iteration 18\n",
            "loss:5992.873999023437 at iteration 19\n",
            "loss:5961.60595703125 at iteration 20\n",
            "loss:5875.458473899148 at iteration 21\n",
            "loss:5949.256177819293 at iteration 22\n",
            "loss:5966.549987792969 at iteration 23\n",
            "loss:5798.5018310546875 at iteration 24\n",
            "loss:5806.837153508113 at iteration 25\n",
            "loss:5827.423805519386 at iteration 26\n",
            "loss:5730.176439557757 at iteration 27\n",
            "loss:5742.429683290678 at iteration 28\n",
            "loss:5646.371561686198 at iteration 29\n",
            "loss:5672.098518617691 at iteration 30\n",
            "loss:5760.804943084717 at iteration 31\n",
            "loss:5798.0156360973015 at iteration 32\n",
            "loss:5744.058281393613 at iteration 33\n",
            "loss:5734.516772460937 at iteration 34\n",
            "loss:5741.049496120877 at iteration 35\n",
            "loss:5653.007954365498 at iteration 36\n",
            "loss:5712.675996479235 at iteration 37\n",
            "loss:5724.186607947717 at iteration 38\n",
            "loss:5814.797372436524 at iteration 39\n",
            "loss:5815.139419183499 at iteration 40\n",
            "loss:5835.712039039248 at iteration 41\n",
            "loss:5782.07430107649 at iteration 42\n",
            "loss:5897.343963623047 at iteration 43\n",
            "loss:5874.161612955729 at iteration 44\n",
            "loss:5826.141588293988 at iteration 45\n",
            "loss:5791.20109655502 at iteration 46\n",
            "loss:5801.9696528116865 at iteration 47\n",
            "loss:5886.128754284917 at iteration 48\n",
            "loss:5854.141032714844 at iteration 49\n",
            "loss:5779.716243968291 at iteration 50\n",
            "loss:5761.6461674616885 at iteration 51\n",
            "loss:5776.816113741893 at iteration 52\n",
            "loss:5821.589846010561 at iteration 53\n",
            "loss:5792.0904319069605 at iteration 54\n",
            "loss:5730.7068764822825 at iteration 55\n",
            "loss:5703.144944575795 at iteration 56\n",
            "loss:5655.063882761988 at iteration 57\n",
            "loss:5604.044866012315 at iteration 58\n",
            "loss:5612.713234456381 at iteration 59\n",
            "loss:5572.330708488089 at iteration 60\n",
            "loss:5538.61473624937 at iteration 61\n",
            "loss:5480.738986545139 at iteration 62\n",
            "loss:5433.38204574585 at iteration 63\n",
            "loss:5385.69697641226 at iteration 64\n",
            "loss:5346.5331698330965 at iteration 65\n",
            "loss:5296.42868178638 at iteration 66\n",
            "loss:5247.267262178309 at iteration 67\n",
            "loss:5203.809970137002 at iteration 68\n",
            "loss:5186.440199497768 at iteration 69\n",
            "loss:5174.631870323504 at iteration 70\n",
            "loss:5120.4356519911025 at iteration 71\n",
            "loss:5083.672062285959 at iteration 72\n",
            "loss:5058.563427074536 at iteration 73\n",
            "loss:5016.530152994792 at iteration 74\n",
            "loss:4978.919915450247 at iteration 75\n",
            "loss:4942.776024756494 at iteration 76\n",
            "loss:4903.368713378906 at iteration 77\n",
            "loss:4875.219959886768 at iteration 78\n",
            "loss:4852.813926696777 at iteration 79\n",
            "loss:4826.735413351176 at iteration 80\n",
            "loss:4800.0263567668635 at iteration 81\n",
            "loss:4763.426050392978 at iteration 82\n",
            "loss:4726.909133184524 at iteration 83\n",
            "loss:4698.420048253676 at iteration 84\n",
            "loss:4682.057143100473 at iteration 85\n",
            "loss:4665.9061882632905 at iteration 86\n",
            "loss:4640.237068869851 at iteration 87\n",
            "loss:4598.5636507527215 at iteration 88\n",
            "loss:4564.166718207465 at iteration 89\n",
            "loss:4543.815126523867 at iteration 90\n",
            "loss:4515.901838219684 at iteration 91\n",
            "loss:4492.064905966482 at iteration 92\n",
            "loss:4455.952844498005 at iteration 93\n",
            "loss:4428.349200760691 at iteration 94\n",
            "loss:4406.355796813965 at iteration 95\n",
            "loss:4396.029022531411 at iteration 96\n",
            "loss:4378.311311682876 at iteration 97\n",
            "loss:4357.805819424716 at iteration 98\n",
            "loss:4332.269764404296 at iteration 99\n",
            "loss:4313.478127658957 at iteration 100\n",
            "loss:4285.495374492571 at iteration 101\n",
            "loss:4267.079185708055 at iteration 102\n",
            "loss:4242.924034705529 at iteration 103\n",
            "loss:4208.508645484561 at iteration 104\n",
            "loss:4198.521307603368 at iteration 105\n",
            "loss:4176.719374612113 at iteration 106\n",
            "loss:4167.614151000977 at iteration 107\n",
            "loss:4140.175841165245 at iteration 108\n",
            "loss:4116.614557994496 at iteration 109\n",
            "loss:4083.9399787971565 at iteration 110\n",
            "loss:4062.7716336931503 at iteration 111\n",
            "loss:4046.4127197265625 at iteration 112\n",
            "loss:4040.621647349575 at iteration 113\n",
            "loss:4043.21908648947 at iteration 114\n",
            "loss:4024.0516273235453 at iteration 115\n",
            "loss:3997.1753701756143 at iteration 116\n",
            "loss:3969.705257092492 at iteration 117\n",
            "loss:3950.3207659040177 at iteration 118\n",
            "loss:3948.0584106445312 at iteration 119\n",
            "loss:3938.5150782057076 at iteration 120\n",
            "loss:3913.9169901863474 at iteration 121\n",
            "loss:3892.558052869347 at iteration 122\n",
            "loss:3883.1034240722656 at iteration 123\n",
            "loss:3882.9768271484377 at iteration 124\n",
            "loss:3891.04784671844 at iteration 125\n",
            "loss:3900.581199826218 at iteration 126\n",
            "loss:3895.1609926223755 at iteration 127\n",
            "loss:3890.4781380586846 at iteration 128\n",
            "loss:3891.0256169245795 at iteration 129\n",
            "loss:3869.2507361492126 at iteration 130\n",
            "loss:3854.462665904652 at iteration 131\n",
            "loss:3836.040881623003 at iteration 132\n",
            "loss:3824.5699973035216 at iteration 133\n",
            "loss:3824.085599320023 at iteration 134\n",
            "loss:3819.396620806526 at iteration 135\n",
            "loss:3828.092049925867 at iteration 136\n",
            "loss:3822.7226226364355 at iteration 137\n",
            "loss:3819.7063058537547 at iteration 138\n",
            "loss:3813.7610386439733 at iteration 139\n",
            "loss:3801.5849366965867 at iteration 140\n",
            "loss:3788.9279510068222 at iteration 141\n",
            "loss:3787.7420714051573 at iteration 142\n",
            "loss:3801.1028917100693 at iteration 143\n",
            "loss:3812.7557112068966 at iteration 144\n",
            "loss:3808.202727017337 at iteration 145\n",
            "loss:3810.3308719972365 at iteration 146\n",
            "loss:3799.4865838128167 at iteration 147\n",
            "loss:3803.417757379929 at iteration 148\n",
            "loss:3803.390359700521 at iteration 149\n",
            "loss:3806.4262582134725 at iteration 150\n",
            "loss:3802.9931030273438 at iteration 151\n",
            "loss:3800.2340399050245 at iteration 152\n",
            "loss:3800.2136087789163 at iteration 153\n",
            "loss:3800.7750630040323 at iteration 154\n",
            "loss:3791.6712849934897 at iteration 155\n",
            "loss:3792.132709867635 at iteration 156\n",
            "loss:3791.6310262559336 at iteration 157\n",
            "loss:3784.3394168877753 at iteration 158\n",
            "loss:3768.6159660339354 at iteration 159\n",
            "loss:3763.5901796329094 at iteration 160\n",
            "loss:3756.093925570264 at iteration 161\n",
            "loss:3743.817720565328 at iteration 162\n",
            "loss:3737.943153195265 at iteration 163\n",
            "loss:3738.3564978397253 at iteration 164\n",
            "loss:3748.035111392837 at iteration 165\n",
            "loss:3748.8653622929924 at iteration 166\n",
            "loss:3745.0722460065567 at iteration 167\n",
            "loss:3737.5454990003236 at iteration 168\n",
            "loss:3722.2691693474267 at iteration 169\n",
            "loss:3707.1752786915204 at iteration 170\n",
            "loss:3691.430331917696 at iteration 171\n",
            "loss:3676.1745097430457 at iteration 172\n",
            "loss:3662.8980249865303 at iteration 173\n",
            "loss:3649.6097579520087 at iteration 174\n",
            "loss:3633.8892211914062 at iteration 175\n",
            "loss:3618.3509621485478 at iteration 176\n",
            "loss:3605.8373581104065 at iteration 177\n",
            "loss:3597.212802993519 at iteration 178\n",
            "loss:3585.045506117079 at iteration 179\n",
            "loss:3578.254806940068 at iteration 180\n",
            "loss:3566.0082588615 at iteration 181\n",
            "loss:3561.9135338621713 at iteration 182\n",
            "loss:3554.3244811348295 at iteration 183\n",
            "loss:3549.4651007574957 at iteration 184\n",
            "loss:3539.477564329742 at iteration 185\n",
            "loss:3539.5865279416985 at iteration 186\n",
            "loss:3533.0125385040933 at iteration 187\n",
            "loss:3526.1476524393393 at iteration 188\n",
            "loss:3512.4125215229237 at iteration 189\n",
            "loss:3497.3963198037673 at iteration 190\n",
            "loss:3492.8457581202188 at iteration 191\n",
            "loss:3482.550858097373 at iteration 192\n",
            "loss:3468.3738541750563 at iteration 193\n",
            "loss:3461.6259746844953 at iteration 194\n",
            "loss:3453.1156186473613 at iteration 195\n",
            "loss:3442.394789642489 at iteration 196\n",
            "loss:3438.3665222784484 at iteration 197\n",
            "loss:3428.0303869199515 at iteration 198\n",
            "loss:3416.0133905029297 at iteration 199\n",
            "loss:3411.6201360142645 at iteration 200\n",
            "loss:3399.4375836967242 at iteration 201\n",
            "loss:3393.2023916761277 at iteration 202\n",
            "loss:3391.8995938768576 at iteration 203\n",
            "loss:3384.7756445907967 at iteration 204\n",
            "loss:3381.177516603933 at iteration 205\n",
            "loss:3371.340220870603 at iteration 206\n",
            "loss:3367.57716692411 at iteration 207\n",
            "loss:3366.343590841339 at iteration 208\n",
            "loss:3359.7289780389697 at iteration 209\n",
            "loss:3348.7823732204347 at iteration 210\n",
            "loss:3345.406785209224 at iteration 211\n",
            "loss:3340.083057958755 at iteration 212\n",
            "loss:3331.4654315698926 at iteration 213\n",
            "loss:3327.501932969204 at iteration 214\n",
            "loss:3321.379388032136 at iteration 215\n",
            "loss:3309.0565461189517 at iteration 216\n",
            "loss:3298.6045795405676 at iteration 217\n",
            "loss:3289.224117749358 at iteration 218\n",
            "loss:3277.576052856445 at iteration 219\n",
            "loss:3275.6032745223238 at iteration 220\n",
            "loss:3271.4320890409454 at iteration 221\n",
            "loss:3267.3919253498984 at iteration 222\n",
            "loss:3265.639627456665 at iteration 223\n",
            "loss:3258.237925075955 at iteration 224\n",
            "loss:3248.2564556830753 at iteration 225\n",
            "loss:3241.9754826886015 at iteration 226\n",
            "loss:3230.1140243797972 at iteration 227\n",
            "loss:3223.42829408604 at iteration 228\n",
            "loss:3216.321109141474 at iteration 229\n",
            "loss:3213.395512568486 at iteration 230\n",
            "loss:3212.0128210659686 at iteration 231\n",
            "loss:3208.769980238231 at iteration 232\n",
            "loss:3204.6762898763022 at iteration 233\n",
            "loss:3203.7043254446476 at iteration 234\n",
            "loss:3207.032702947067 at iteration 235\n",
            "loss:3206.1576123458926 at iteration 236\n",
            "loss:3207.4286888827796 at iteration 237\n",
            "loss:3201.9598914748954 at iteration 238\n",
            "loss:3197.052881368001 at iteration 239\n",
            "loss:3193.209031480971 at iteration 240\n",
            "loss:3186.707533150665 at iteration 241\n",
            "loss:3183.1756049262153 at iteration 242\n",
            "loss:3181.457112796971 at iteration 243\n",
            "loss:3174.895461973852 at iteration 244\n",
            "loss:3168.2350508527056 at iteration 245\n",
            "loss:3160.098037781503 at iteration 246\n",
            "loss:3157.2996511151714 at iteration 247\n",
            "loss:3156.5678544255147 at iteration 248\n",
            "loss:3150.080798828125 at iteration 249\n",
            "loss:3147.004434410794 at iteration 250\n",
            "loss:3147.572566925533 at iteration 251\n",
            "loss:3143.936718364007 at iteration 252\n",
            "loss:3136.931673785833 at iteration 253\n",
            "loss:3126.5408604042204 at iteration 254\n",
            "loss:3121.8536537885666 at iteration 255\n",
            "loss:3116.0752768906173 at iteration 256\n",
            "loss:3110.319496213928 at iteration 257\n",
            "loss:3102.435878090877 at iteration 258\n",
            "loss:3103.479336665227 at iteration 259\n",
            "loss:3101.37248785377 at iteration 260\n",
            "loss:3093.5181329159336 at iteration 261\n",
            "loss:3083.990052081786 at iteration 262\n",
            "loss:3078.7671089172363 at iteration 263\n",
            "loss:3073.07291662828 at iteration 264\n",
            "loss:3065.234955407623 at iteration 265\n",
            "loss:3058.403700124905 at iteration 266\n",
            "loss:3054.8009519434686 at iteration 267\n",
            "loss:3049.0345117505153 at iteration 268\n",
            "loss:3041.1700167055483 at iteration 269\n",
            "loss:3035.496472911201 at iteration 270\n",
            "loss:3027.632397258983 at iteration 271\n",
            "loss:3020.9299968118635 at iteration 272\n",
            "loss:3013.8313392583473 at iteration 273\n",
            "loss:3010.8245413485442 at iteration 274\n",
            "loss:3004.764585080354 at iteration 275\n",
            "loss:2999.0716013994456 at iteration 276\n",
            "loss:2994.1943222155674 at iteration 277\n",
            "loss:2988.6993450862105 at iteration 278\n",
            "loss:2982.169735608782 at iteration 279\n",
            "loss:2975.0079663911324 at iteration 280\n",
            "loss:2969.9210859799214 at iteration 281\n",
            "loss:2968.0621019774526 at iteration 282\n",
            "loss:2967.130923526388 at iteration 283\n",
            "loss:2961.644517222622 at iteration 284\n",
            "loss:2954.723107504678 at iteration 285\n",
            "loss:2949.2209784212014 at iteration 286\n",
            "loss:2945.9014291763306 at iteration 287\n",
            "loss:2945.0433084560514 at iteration 288\n",
            "loss:2947.3545840559336 at iteration 289\n",
            "loss:2945.3233874343923 at iteration 290\n",
            "epoch:  11\n",
            "loss:1833.09619140625 at iteration 0\n",
            "loss:4033.7880859375 at iteration 1\n",
            "loss:4795.796875 at iteration 2\n",
            "loss:6027.2373046875 at iteration 3\n",
            "loss:5533.778955078125 at iteration 4\n",
            "loss:5233.318033854167 at iteration 5\n",
            "loss:6662.200892857143 at iteration 6\n",
            "loss:7164.4742431640625 at iteration 7\n",
            "loss:6641.436089409723 at iteration 8\n",
            "loss:6163.789208984375 at iteration 9\n",
            "loss:6142.767400568182 at iteration 10\n",
            "loss:6030.8203531901045 at iteration 11\n",
            "loss:5790.6171311598555 at iteration 12\n",
            "loss:5819.986589704241 at iteration 13\n",
            "loss:5738.533837890625 at iteration 14\n",
            "loss:5695.970657348633 at iteration 15\n",
            "loss:5700.407987706802 at iteration 16\n",
            "loss:5677.418307834201 at iteration 17\n",
            "loss:5874.364836040296 at iteration 18\n",
            "loss:5879.353845214844 at iteration 19\n",
            "loss:5863.163771856399 at iteration 20\n",
            "loss:5782.253196022727 at iteration 21\n",
            "loss:5842.105872112772 at iteration 22\n",
            "loss:5863.426005045573 at iteration 23\n",
            "loss:5707.305756835937 at iteration 24\n",
            "loss:5732.8909583458535 at iteration 25\n",
            "loss:5755.289076063368 at iteration 26\n",
            "loss:5666.624097551618 at iteration 27\n",
            "loss:5671.000879748114 at iteration 28\n",
            "loss:5570.015466308594 at iteration 29\n",
            "loss:5584.735465757309 at iteration 30\n",
            "loss:5715.806720733643 at iteration 31\n",
            "loss:5721.9457452947445 at iteration 32\n",
            "loss:5706.1147209616265 at iteration 33\n",
            "loss:5705.279872349331 at iteration 34\n",
            "loss:5700.58790757921 at iteration 35\n",
            "loss:5608.8718360694675 at iteration 36\n",
            "loss:5636.342506810239 at iteration 37\n",
            "loss:5630.429252428886 at iteration 38\n",
            "loss:5716.283413696289 at iteration 39\n",
            "loss:5735.765020603087 at iteration 40\n",
            "loss:5765.27491687593 at iteration 41\n",
            "loss:5742.055894008902 at iteration 42\n",
            "loss:5860.543171275745 at iteration 43\n",
            "loss:5811.400697157118 at iteration 44\n",
            "loss:5769.331290867018 at iteration 45\n",
            "loss:5754.220445998171 at iteration 46\n",
            "loss:5760.349469502767 at iteration 47\n",
            "loss:5871.294485909598 at iteration 48\n",
            "loss:5824.163430175781 at iteration 49\n",
            "loss:5775.8489990234375 at iteration 50\n",
            "loss:5748.303121713491 at iteration 51\n",
            "loss:5734.280284953567 at iteration 52\n",
            "loss:5772.146974916811 at iteration 53\n",
            "loss:5736.239419833097 at iteration 54\n",
            "loss:5675.365973336356 at iteration 55\n",
            "loss:5644.896113880894 at iteration 56\n",
            "loss:5619.47686346646 at iteration 57\n",
            "loss:5568.881771798861 at iteration 58\n",
            "loss:5568.68921101888 at iteration 59\n",
            "loss:5540.109585121029 at iteration 60\n",
            "loss:5501.253049788937 at iteration 61\n",
            "loss:5446.332029312376 at iteration 62\n",
            "loss:5404.285203933716 at iteration 63\n",
            "loss:5359.886942232572 at iteration 64\n",
            "loss:5334.426101222183 at iteration 65\n",
            "loss:5278.987962409631 at iteration 66\n",
            "loss:5228.5307365866265 at iteration 67\n",
            "loss:5193.277039458786 at iteration 68\n",
            "loss:5176.044025530134 at iteration 69\n",
            "loss:5158.934346803477 at iteration 70\n",
            "loss:5101.2134696112735 at iteration 71\n",
            "loss:5058.189714823684 at iteration 72\n",
            "loss:5028.349458436708 at iteration 73\n",
            "loss:4997.866582845052 at iteration 74\n",
            "loss:4968.837926764238 at iteration 75\n",
            "loss:4943.389132412997 at iteration 76\n",
            "loss:4908.938092354017 at iteration 77\n",
            "loss:4883.210820837866 at iteration 78\n",
            "loss:4861.545499420166 at iteration 79\n",
            "loss:4838.055872787664 at iteration 80\n",
            "loss:4815.643186243569 at iteration 81\n",
            "loss:4777.465750452984 at iteration 82\n",
            "loss:4743.8496493384955 at iteration 83\n",
            "loss:4714.036818560432 at iteration 84\n",
            "loss:4691.443469380223 at iteration 85\n",
            "loss:4673.484694206852 at iteration 86\n",
            "loss:4651.195395036178 at iteration 87\n",
            "loss:4606.365457256188 at iteration 88\n",
            "loss:4571.801078965929 at iteration 89\n",
            "loss:4553.7551665253695 at iteration 90\n",
            "loss:4525.762386819591 at iteration 91\n",
            "loss:4504.7831867177 at iteration 92\n",
            "loss:4470.163180087475 at iteration 93\n",
            "loss:4436.108707468134 at iteration 94\n",
            "loss:4410.001911799113 at iteration 95\n",
            "loss:4398.318011411687 at iteration 96\n",
            "loss:4377.922696483379 at iteration 97\n",
            "loss:4357.403499718868 at iteration 98\n",
            "loss:4327.226331176757 at iteration 99\n",
            "loss:4305.19689639252 at iteration 100\n",
            "loss:4281.380449482039 at iteration 101\n",
            "loss:4263.70595217214 at iteration 102\n",
            "loss:4241.760004483736 at iteration 103\n",
            "loss:4210.379660179501 at iteration 104\n",
            "loss:4200.920659479105 at iteration 105\n",
            "loss:4174.742392281506 at iteration 106\n",
            "loss:4165.255307232892 at iteration 107\n",
            "loss:4136.409365592746 at iteration 108\n",
            "loss:4112.579110440341 at iteration 109\n",
            "loss:4082.4928902290962 at iteration 110\n",
            "loss:4068.2526626586914 at iteration 111\n",
            "loss:4052.249151989422 at iteration 112\n",
            "loss:4044.753457588062 at iteration 113\n",
            "loss:4048.78451617697 at iteration 114\n",
            "loss:4028.7953975282867 at iteration 115\n",
            "loss:4004.747843424479 at iteration 116\n",
            "loss:3979.706752971067 at iteration 117\n",
            "loss:3959.65029317391 at iteration 118\n",
            "loss:3956.3910064697266 at iteration 119\n",
            "loss:3953.2983630471977 at iteration 120\n",
            "loss:3930.4720549036247 at iteration 121\n",
            "loss:3906.0268539800877 at iteration 122\n",
            "loss:3894.9187587614983 at iteration 123\n",
            "loss:3903.7629711914065 at iteration 124\n",
            "loss:3907.814443921286 at iteration 125\n",
            "loss:3910.2495487243173 at iteration 126\n",
            "loss:3902.0888085365295 at iteration 127\n",
            "loss:3898.9414691777192 at iteration 128\n",
            "loss:3899.667503474309 at iteration 129\n",
            "loss:3878.1776528394857 at iteration 130\n",
            "loss:3864.0565402869024 at iteration 131\n",
            "loss:3845.026537443462 at iteration 132\n",
            "loss:3829.4257634860364 at iteration 133\n",
            "loss:3824.343405038339 at iteration 134\n",
            "loss:3822.30510262882 at iteration 135\n",
            "loss:3830.6616482699874 at iteration 136\n",
            "loss:3822.4882887688236 at iteration 137\n",
            "loss:3821.127865139529 at iteration 138\n",
            "loss:3816.4472660609654 at iteration 139\n",
            "loss:3804.752074762439 at iteration 140\n",
            "loss:3793.7230607153665 at iteration 141\n",
            "loss:3797.2682119516226 at iteration 142\n",
            "loss:3811.700865427653 at iteration 143\n",
            "loss:3823.717496043238 at iteration 144\n",
            "loss:3819.447590449085 at iteration 145\n",
            "loss:3822.010490157977 at iteration 146\n",
            "loss:3810.0913601437132 at iteration 147\n",
            "loss:3814.62154147769 at iteration 148\n",
            "loss:3813.293141682943 at iteration 149\n",
            "loss:3813.1527936316484 at iteration 150\n",
            "loss:3810.7460202668844 at iteration 151\n",
            "loss:3805.8520096922234 at iteration 152\n",
            "loss:3804.6387610497413 at iteration 153\n",
            "loss:3804.3663893176663 at iteration 154\n",
            "loss:3797.309514363607 at iteration 155\n",
            "loss:3804.8618758863704 at iteration 156\n",
            "loss:3801.68417976476 at iteration 157\n",
            "loss:3793.5848400187942 at iteration 158\n",
            "loss:3777.8799373626707 at iteration 159\n",
            "loss:3771.7201826202204 at iteration 160\n",
            "loss:3764.8145054946713 at iteration 161\n",
            "loss:3752.7637201788966 at iteration 162\n",
            "loss:3746.9213394537205 at iteration 163\n",
            "loss:3747.4612752278645 at iteration 164\n",
            "loss:3755.9699593049936 at iteration 165\n",
            "loss:3753.197039392894 at iteration 166\n",
            "loss:3751.68730708531 at iteration 167\n",
            "loss:3745.105758034971 at iteration 168\n",
            "loss:3729.6765980440027 at iteration 169\n",
            "loss:3714.879225703011 at iteration 170\n",
            "loss:3699.021266848542 at iteration 171\n",
            "loss:3682.7224865510975 at iteration 172\n",
            "loss:3670.64031315946 at iteration 173\n",
            "loss:3660.7204844447547 at iteration 174\n",
            "loss:3644.5662332014604 at iteration 175\n",
            "loss:3629.190874864826 at iteration 176\n",
            "loss:3615.9075704853185 at iteration 177\n",
            "loss:3607.3176525265144 at iteration 178\n",
            "loss:3593.4813758002388 at iteration 179\n",
            "loss:3584.9780229600096 at iteration 180\n",
            "loss:3573.296639914041 at iteration 181\n",
            "loss:3567.9056012930114 at iteration 182\n",
            "loss:3562.662297456161 at iteration 183\n",
            "loss:3556.4980980125633 at iteration 184\n",
            "loss:3547.029982371997 at iteration 185\n",
            "loss:3542.960484795392 at iteration 186\n",
            "loss:3537.994944795649 at iteration 187\n",
            "loss:3530.9770976071636 at iteration 188\n",
            "loss:3518.106534295333 at iteration 189\n",
            "loss:3504.0738049252495 at iteration 190\n",
            "loss:3497.156453768412 at iteration 191\n",
            "loss:3485.1030801565535 at iteration 192\n",
            "loss:3471.5783203754227 at iteration 193\n",
            "loss:3463.616710173778 at iteration 194\n",
            "loss:3452.910914518395 at iteration 195\n",
            "loss:3441.4552005051355 at iteration 196\n",
            "loss:3434.917792117957 at iteration 197\n",
            "loss:3425.3343361705993 at iteration 198\n",
            "loss:3413.2590158081057 at iteration 199\n",
            "loss:3406.1895682111904 at iteration 200\n",
            "loss:3393.7873347820623 at iteration 201\n",
            "loss:3386.6110244525476 at iteration 202\n",
            "loss:3384.223185819738 at iteration 203\n",
            "loss:3378.143762504764 at iteration 204\n",
            "loss:3374.2729995875684 at iteration 205\n",
            "loss:3367.141803243886 at iteration 206\n",
            "loss:3363.0640716552734 at iteration 207\n",
            "loss:3363.9651392886512 at iteration 208\n",
            "loss:3358.063481212798 at iteration 209\n",
            "loss:3346.438270605006 at iteration 210\n",
            "loss:3342.711331349499 at iteration 211\n",
            "loss:3339.276474930311 at iteration 212\n",
            "loss:3334.0675493757303 at iteration 213\n",
            "loss:3331.414852834302 at iteration 214\n",
            "loss:3326.575353551794 at iteration 215\n",
            "loss:3316.3892569124423 at iteration 216\n",
            "loss:3306.9213654404384 at iteration 217\n",
            "loss:3297.48188677226 at iteration 218\n",
            "loss:3285.076790826971 at iteration 219\n",
            "loss:3284.709124396829 at iteration 220\n",
            "loss:3279.157402244774 at iteration 221\n",
            "loss:3274.427000584624 at iteration 222\n",
            "loss:3272.7220085689 at iteration 223\n",
            "loss:3265.302555067274 at iteration 224\n",
            "loss:3255.3871495069657 at iteration 225\n",
            "loss:3247.940025027103 at iteration 226\n",
            "loss:3236.3852126807496 at iteration 227\n",
            "loss:3228.936095391819 at iteration 228\n",
            "loss:3222.1630031419836 at iteration 229\n",
            "loss:3219.2947348062094 at iteration 230\n",
            "loss:3219.7001711089038 at iteration 231\n",
            "loss:3216.3307476780446 at iteration 232\n",
            "loss:3209.149013421474 at iteration 233\n",
            "loss:3207.463698886303 at iteration 234\n",
            "loss:3206.953635005628 at iteration 235\n",
            "loss:3206.7740442461104 at iteration 236\n",
            "loss:3209.1753750328257 at iteration 237\n",
            "loss:3202.7809895152327 at iteration 238\n",
            "loss:3197.1391891479493 at iteration 239\n",
            "loss:3193.170104727211 at iteration 240\n",
            "loss:3188.220288489476 at iteration 241\n",
            "loss:3187.0037545412165 at iteration 242\n",
            "loss:3184.8360115426485 at iteration 243\n",
            "loss:3177.281333705357 at iteration 244\n",
            "loss:3170.2957952235774 at iteration 245\n",
            "loss:3162.373334506263 at iteration 246\n",
            "loss:3159.2386829007055 at iteration 247\n",
            "loss:3158.687941217997 at iteration 248\n",
            "loss:3154.1997998046877 at iteration 249\n",
            "loss:3151.405268574141 at iteration 250\n",
            "loss:3150.846483018663 at iteration 251\n",
            "loss:3146.415477164649 at iteration 252\n",
            "loss:3139.5591916061762 at iteration 253\n",
            "loss:3130.0099022958793 at iteration 254\n",
            "loss:3124.1134746074677 at iteration 255\n",
            "loss:3119.939824323246 at iteration 256\n",
            "loss:3113.758461885674 at iteration 257\n",
            "loss:3106.3274229778744 at iteration 258\n",
            "loss:3107.375987126277 at iteration 259\n",
            "loss:3105.4527791341147 at iteration 260\n",
            "loss:3096.7950637467943 at iteration 261\n",
            "loss:3087.1047481638398 at iteration 262\n",
            "loss:3083.328726797393 at iteration 263\n",
            "loss:3078.7724685381045 at iteration 264\n",
            "loss:3073.1940043743393 at iteration 265\n",
            "loss:3066.1570649450637 at iteration 266\n",
            "loss:3061.0408195381733 at iteration 267\n",
            "loss:3055.5172511671553 at iteration 268\n",
            "loss:3046.69966724537 at iteration 269\n",
            "loss:3040.799221813019 at iteration 270\n",
            "loss:3032.5519570743336 at iteration 271\n",
            "loss:3026.289273551969 at iteration 272\n",
            "loss:3019.7261664397524 at iteration 273\n",
            "loss:3015.38213112571 at iteration 274\n",
            "loss:3009.2726068911347 at iteration 275\n",
            "loss:3002.9557074261056 at iteration 276\n",
            "loss:2997.7264149617804 at iteration 277\n",
            "loss:2992.7113352129536 at iteration 278\n",
            "loss:2987.697978864397 at iteration 279\n",
            "loss:2980.983523983124 at iteration 280\n",
            "loss:2976.6166541999114 at iteration 281\n",
            "loss:2976.076623923366 at iteration 282\n",
            "loss:2974.4161359760124 at iteration 283\n",
            "loss:2968.945493249726 at iteration 284\n",
            "loss:2961.1839127974076 at iteration 285\n",
            "loss:2955.056519618018 at iteration 286\n",
            "loss:2950.357885784573 at iteration 287\n",
            "loss:2948.4592861716724 at iteration 288\n",
            "loss:2951.274548971242 at iteration 289\n",
            "loss:2949.872482457112 at iteration 290\n",
            "epoch:  12\n",
            "loss:2412.596435546875 at iteration 0\n",
            "loss:3948.7867431640625 at iteration 1\n",
            "loss:4346.817626953125 at iteration 2\n",
            "loss:5835.194519042969 at iteration 3\n",
            "loss:5358.159716796875 at iteration 4\n",
            "loss:5010.7036539713545 at iteration 5\n",
            "loss:6287.68865094866 at iteration 6\n",
            "loss:6923.791778564453 at iteration 7\n",
            "loss:6451.783121744792 at iteration 8\n",
            "loss:5989.139477539063 at iteration 9\n",
            "loss:5959.169367009943 at iteration 10\n",
            "loss:5838.622945149739 at iteration 11\n",
            "loss:5642.264028695913 at iteration 12\n",
            "loss:5609.690726143973 at iteration 13\n",
            "loss:5522.035953776041 at iteration 14\n",
            "loss:5492.016647338867 at iteration 15\n",
            "loss:5448.600801355698 at iteration 16\n",
            "loss:5464.8542887369795 at iteration 17\n",
            "loss:5705.178723787007 at iteration 18\n",
            "loss:5765.618103027344 at iteration 19\n",
            "loss:5749.343343098958 at iteration 20\n",
            "loss:5676.3310435901985 at iteration 21\n",
            "loss:5789.420633067255 at iteration 22\n",
            "loss:5801.887929280599 at iteration 23\n",
            "loss:5630.182680664063 at iteration 24\n",
            "loss:5620.5377525916465 at iteration 25\n",
            "loss:5627.085435655382 at iteration 26\n",
            "loss:5529.322017124721 at iteration 27\n",
            "loss:5515.824113516972 at iteration 28\n",
            "loss:5427.042801920573 at iteration 29\n",
            "loss:5488.449750346522 at iteration 30\n",
            "loss:5588.7751121521 at iteration 31\n",
            "loss:5615.1502981474905 at iteration 32\n",
            "loss:5617.8083747414985 at iteration 33\n",
            "loss:5587.79766671317 at iteration 34\n",
            "loss:5575.287987603082 at iteration 35\n",
            "loss:5485.140535921664 at iteration 36\n",
            "loss:5517.080209832442 at iteration 37\n",
            "loss:5508.729845878405 at iteration 38\n",
            "loss:5568.888088989258 at iteration 39\n",
            "loss:5598.801736971227 at iteration 40\n",
            "loss:5619.230878557478 at iteration 41\n",
            "loss:5581.063678120458 at iteration 42\n",
            "loss:5725.444976806641 at iteration 43\n",
            "loss:5700.593812391493 at iteration 44\n",
            "loss:5661.293183699898 at iteration 45\n",
            "loss:5620.413758622839 at iteration 46\n",
            "loss:5640.607714335124 at iteration 47\n",
            "loss:5735.797639807876 at iteration 48\n",
            "loss:5703.5675366210935 at iteration 49\n",
            "loss:5641.088510550705 at iteration 50\n",
            "loss:5623.171234130859 at iteration 51\n",
            "loss:5618.619451558815 at iteration 52\n",
            "loss:5686.12235740379 at iteration 53\n",
            "loss:5642.08974831321 at iteration 54\n",
            "loss:5577.278008597238 at iteration 55\n",
            "loss:5537.933296069764 at iteration 56\n",
            "loss:5504.274622423895 at iteration 57\n",
            "loss:5457.1024583719545 at iteration 58\n",
            "loss:5460.912925211588 at iteration 59\n",
            "loss:5431.151401207096 at iteration 60\n",
            "loss:5387.706667007938 at iteration 61\n",
            "loss:5332.844771127852 at iteration 62\n",
            "loss:5282.084348678589 at iteration 63\n",
            "loss:5239.480654672476 at iteration 64\n",
            "loss:5211.10458651456 at iteration 65\n",
            "loss:5161.2313232421875 at iteration 66\n",
            "loss:5118.678874296301 at iteration 67\n",
            "loss:5087.4899353911915 at iteration 68\n",
            "loss:5060.118043736049 at iteration 69\n",
            "loss:5047.608066612566 at iteration 70\n",
            "loss:4992.93830871582 at iteration 71\n",
            "loss:4956.408515825664 at iteration 72\n",
            "loss:4925.248526908256 at iteration 73\n",
            "loss:4889.2413753255205 at iteration 74\n",
            "loss:4861.687973825555 at iteration 75\n",
            "loss:4829.64952662084 at iteration 76\n",
            "loss:4796.476216634114 at iteration 77\n",
            "loss:4773.823361167425 at iteration 78\n",
            "loss:4758.123265075684 at iteration 79\n",
            "loss:4731.6291097005205 at iteration 80\n",
            "loss:4706.969900735995 at iteration 81\n",
            "loss:4676.8949592314575 at iteration 82\n",
            "loss:4651.639161609468 at iteration 83\n",
            "loss:4620.184600471048 at iteration 84\n",
            "loss:4598.7695440248 at iteration 85\n",
            "loss:4579.822968581627 at iteration 86\n",
            "loss:4557.057221846147 at iteration 87\n",
            "loss:4514.207037422095 at iteration 88\n",
            "loss:4482.36323445638 at iteration 89\n",
            "loss:4465.977527660328 at iteration 90\n",
            "loss:4439.801953523055 at iteration 91\n",
            "loss:4426.409402170489 at iteration 92\n",
            "loss:4394.680236167096 at iteration 93\n",
            "loss:4364.741247558593 at iteration 94\n",
            "loss:4338.263249079387 at iteration 95\n",
            "loss:4327.024901714522 at iteration 96\n",
            "loss:4310.164308509048 at iteration 97\n",
            "loss:4291.653588497277 at iteration 98\n",
            "loss:4263.9659344482425 at iteration 99\n",
            "loss:4247.973494425859 at iteration 100\n",
            "loss:4224.779170616001 at iteration 101\n",
            "loss:4209.589668940572 at iteration 102\n",
            "loss:4181.167218134953 at iteration 103\n",
            "loss:4147.019900367373 at iteration 104\n",
            "loss:4134.321509595187 at iteration 105\n",
            "loss:4109.056897885332 at iteration 106\n",
            "loss:4104.970225581416 at iteration 107\n",
            "loss:4075.9218901188 at iteration 108\n",
            "loss:4050.838653564453 at iteration 109\n",
            "loss:4020.2864830773156 at iteration 110\n",
            "loss:4000.0613855634415 at iteration 111\n",
            "loss:3982.7787194716193 at iteration 112\n",
            "loss:3976.42812360797 at iteration 113\n",
            "loss:3974.917129649287 at iteration 114\n",
            "loss:3957.239629811254 at iteration 115\n",
            "loss:3932.5782882820845 at iteration 116\n",
            "loss:3905.55517216052 at iteration 117\n",
            "loss:3886.971122164686 at iteration 118\n",
            "loss:3882.8708216349282 at iteration 119\n",
            "loss:3875.4411404191956 at iteration 120\n",
            "loss:3849.9618290135118 at iteration 121\n",
            "loss:3829.853848092924 at iteration 122\n",
            "loss:3820.465061310799 at iteration 123\n",
            "loss:3825.0587041015624 at iteration 124\n",
            "loss:3831.444375658792 at iteration 125\n",
            "loss:3831.4841164416216 at iteration 126\n",
            "loss:3825.129168510437 at iteration 127\n",
            "loss:3821.669127944828 at iteration 128\n",
            "loss:3827.557907339243 at iteration 129\n",
            "loss:3806.7927236775404 at iteration 130\n",
            "loss:3792.354325727983 at iteration 131\n",
            "loss:3774.5420252290883 at iteration 132\n",
            "loss:3761.1207102305852 at iteration 133\n",
            "loss:3755.58762749566 at iteration 134\n",
            "loss:3754.505454568302 at iteration 135\n",
            "loss:3763.9763602375115 at iteration 136\n",
            "loss:3756.9226100755773 at iteration 137\n",
            "loss:3755.666952668334 at iteration 138\n",
            "loss:3751.086754499163 at iteration 139\n",
            "loss:3738.828528438054 at iteration 140\n",
            "loss:3726.66220737511 at iteration 141\n",
            "loss:3727.3664499562938 at iteration 142\n",
            "loss:3741.4424743652344 at iteration 143\n",
            "loss:3753.0865941540947 at iteration 144\n",
            "loss:3748.7967479130994 at iteration 145\n",
            "loss:3753.7893116230866 at iteration 146\n",
            "loss:3744.8811530035896 at iteration 147\n",
            "loss:3751.9697200083892 at iteration 148\n",
            "loss:3752.6402115885417 at iteration 149\n",
            "loss:3753.7571027136796 at iteration 150\n",
            "loss:3753.265551115337 at iteration 151\n",
            "loss:3748.4753050959966 at iteration 152\n",
            "loss:3748.070712002841 at iteration 153\n",
            "loss:3748.501376638105 at iteration 154\n",
            "loss:3741.2029966696714 at iteration 155\n",
            "loss:3746.1355555832006 at iteration 156\n",
            "loss:3743.2177873442442 at iteration 157\n",
            "loss:3734.2870633107314 at iteration 158\n",
            "loss:3720.0874168395994 at iteration 159\n",
            "loss:3716.574067868061 at iteration 160\n",
            "loss:3709.2337533456307 at iteration 161\n",
            "loss:3694.8810016655484 at iteration 162\n",
            "loss:3690.794083758098 at iteration 163\n",
            "loss:3690.7562130089964 at iteration 164\n",
            "loss:3698.1421472020897 at iteration 165\n",
            "loss:3697.854866438997 at iteration 166\n",
            "loss:3695.5967901320682 at iteration 167\n",
            "loss:3689.5592163808246 at iteration 168\n",
            "loss:3676.089230526195 at iteration 169\n",
            "loss:3660.352733946683 at iteration 170\n",
            "loss:3647.16760111964 at iteration 171\n",
            "loss:3632.184770705383 at iteration 172\n",
            "loss:3617.3029511550376 at iteration 173\n",
            "loss:3605.9263490513395 at iteration 174\n",
            "loss:3590.4810076626864 at iteration 175\n",
            "loss:3574.9099321095955 at iteration 176\n",
            "loss:3562.0531149874914 at iteration 177\n",
            "loss:3555.105241658301 at iteration 178\n",
            "loss:3541.9713134765625 at iteration 179\n",
            "loss:3534.806536764071 at iteration 180\n",
            "loss:3526.4236671531594 at iteration 181\n",
            "loss:3523.3651663358096 at iteration 182\n",
            "loss:3517.8681627356486 at iteration 183\n",
            "loss:3518.410794974662 at iteration 184\n",
            "loss:3509.085178170153 at iteration 185\n",
            "loss:3502.2851555972175 at iteration 186\n",
            "loss:3499.324505095786 at iteration 187\n",
            "loss:3491.941209258226 at iteration 188\n",
            "loss:3478.021247622841 at iteration 189\n",
            "loss:3462.17191526403 at iteration 190\n",
            "loss:3456.1878019968667 at iteration 191\n",
            "loss:3446.1332002155523 at iteration 192\n",
            "loss:3431.9845732069507 at iteration 193\n",
            "loss:3426.2535425430688 at iteration 194\n",
            "loss:3415.059002311862 at iteration 195\n",
            "loss:3405.4645072820826 at iteration 196\n",
            "loss:3403.1483727657433 at iteration 197\n",
            "loss:3393.0758081177373 at iteration 198\n",
            "loss:3380.3990115356446 at iteration 199\n",
            "loss:3371.9195298531754 at iteration 200\n",
            "loss:3360.1158084680537 at iteration 201\n",
            "loss:3354.6967881677188 at iteration 202\n",
            "loss:3352.9151180491726 at iteration 203\n",
            "loss:3345.356385766006 at iteration 204\n",
            "loss:3342.4629735854064 at iteration 205\n",
            "loss:3334.438467716825 at iteration 206\n",
            "loss:3334.4098246647764 at iteration 207\n",
            "loss:3334.5257474908417 at iteration 208\n",
            "loss:3330.3600963774184 at iteration 209\n",
            "loss:3319.5479111513255 at iteration 210\n",
            "loss:3315.349711292195 at iteration 211\n",
            "loss:3310.7050867215007 at iteration 212\n",
            "loss:3303.7347183940565 at iteration 213\n",
            "loss:3301.090274118823 at iteration 214\n",
            "loss:3294.764708907516 at iteration 215\n",
            "loss:3282.8592211464033 at iteration 216\n",
            "loss:3271.953847062697 at iteration 217\n",
            "loss:3263.4197933946025 at iteration 218\n",
            "loss:3251.6255673495207 at iteration 219\n",
            "loss:3253.2096706752864 at iteration 220\n",
            "loss:3248.373432056324 at iteration 221\n",
            "loss:3244.0636093071225 at iteration 222\n",
            "loss:3241.2353529248917 at iteration 223\n",
            "loss:3232.991280653212 at iteration 224\n",
            "loss:3223.6002232374344 at iteration 225\n",
            "loss:3216.197746108807 at iteration 226\n",
            "loss:3204.8348806280837 at iteration 227\n",
            "loss:3195.416422348356 at iteration 228\n",
            "loss:3192.4309989597486 at iteration 229\n",
            "loss:3191.322422572545 at iteration 230\n",
            "loss:3191.1057334110656 at iteration 231\n",
            "loss:3186.4934391136335 at iteration 232\n",
            "loss:3178.9481566339477 at iteration 233\n",
            "loss:3175.1699301861704 at iteration 234\n",
            "loss:3179.4731176344017 at iteration 235\n",
            "loss:3178.1602087865904 at iteration 236\n",
            "loss:3180.9756156857275 at iteration 237\n",
            "loss:3174.304360617155 at iteration 238\n",
            "loss:3168.718827311198 at iteration 239\n",
            "loss:3164.5868948148986 at iteration 240\n",
            "loss:3157.788279131424 at iteration 241\n",
            "loss:3154.369341061439 at iteration 242\n",
            "loss:3149.199649998399 at iteration 243\n",
            "loss:3142.208986866231 at iteration 244\n",
            "loss:3134.855989781822 at iteration 245\n",
            "loss:3127.3111053343246 at iteration 246\n",
            "loss:3125.1038729759953 at iteration 247\n",
            "loss:3125.232585615901 at iteration 248\n",
            "loss:3119.7500385742187 at iteration 249\n",
            "loss:3117.2400870152205 at iteration 250\n",
            "loss:3117.8819013323105 at iteration 251\n",
            "loss:3113.009136938766 at iteration 252\n",
            "loss:3105.505993460107 at iteration 253\n",
            "loss:3095.915613032322 at iteration 254\n",
            "loss:3092.3465027809143 at iteration 255\n",
            "loss:3089.780731794899 at iteration 256\n",
            "loss:3083.128123202065 at iteration 257\n",
            "loss:3075.306032158693 at iteration 258\n",
            "loss:3078.8601830115686 at iteration 259\n",
            "loss:3076.917133901311 at iteration 260\n",
            "loss:3069.039574775987 at iteration 261\n",
            "loss:3059.1053660577695 at iteration 262\n",
            "loss:3053.9116450223055 at iteration 263\n",
            "loss:3049.2431796091905 at iteration 264\n",
            "loss:3042.619996379193 at iteration 265\n",
            "loss:3036.0395086052713 at iteration 266\n",
            "loss:3030.5915813161364 at iteration 267\n",
            "loss:3024.635257876939 at iteration 268\n",
            "loss:3015.716909790039 at iteration 269\n",
            "loss:3008.5916701876367 at iteration 270\n",
            "loss:3000.4656972324146 at iteration 271\n",
            "loss:2993.061555743654 at iteration 272\n",
            "loss:2986.641288033367 at iteration 273\n",
            "loss:2982.6926789994673 at iteration 274\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-6c9fa4640ad7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# print(\"y shape: \", y.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprints\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;31m# print(\"output\", output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# print(\"output shape after concat: \", output.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-9dd21e98b6a4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, prints)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLBL0hNWr8r-"
      },
      "source": [
        "# def evaluate(model, data_loader,  device='cuda'):\n",
        "#     model.to(device)\n",
        "#     model.eval()\n",
        "#     x_list = []\n",
        "#     y_list = []\n",
        "#     floor_list = []\n",
        "#     prexs_list = []\n",
        "#     preys_list = []\n",
        "#     prefloors_list = []\n",
        "#     for d in tqdm(data_loader):\n",
        "#         data_dict['BSSID_FEATS'] = d['BSSID_FEATS'].to(device).long()\n",
        "#         data_dict['RSSI_FEATS'] = d['RSSI_FEATS'].to(device).float()\n",
        "#         data_dict['site_id'] = d['site_id'].to(device).long()\n",
        "#         x = d['x'].to(device).float()\n",
        "#         y = d['y'].to(device).float()\n",
        "#         floor = d['floor'].to(device).long()\n",
        "#         x_list.append(x.cpu().detach().numpy())\n",
        "#         y_list.append(y.cpu().detach().numpy())\n",
        "#         floor_list.append(floor.cpu().detach().numpy())\n",
        "#         xy, floor = model(data_dict)\n",
        "#         prexs_list.append(xy[:, 0].cpu().detach().numpy())\n",
        "#         preys_list.append(xy[:, 1].cpu().detach().numpy())\n",
        "#         prefloors_list.append(floor.squeeze().cpu().detach().numpy())\n",
        "#     x = np.concatenate(x_list)\n",
        "#     y = np.concatenate(y_list)\n",
        "#     floor = np.concatenate(floor_list)\n",
        "#     prexs = np.concatenate(prexs_list)\n",
        "#     preys =np.concatenate(preys_list)\n",
        "#     prefloors = np.concatenate(prefloors_list)\n",
        "#     eval_score = comp_metric(x, y, floor, prexs, preys, prefloors)\n",
        "#     return eval_score\n",
        "\n",
        "# def get_result(model, data_loader, device='cuda'):\n",
        "#     model.eval()\n",
        "#     model.to(device)\n",
        "#     prexs_list = []\n",
        "#     preys_list = []\n",
        "#     prefloors_list = []\n",
        "#     data_dict = {}\n",
        "#     for d in tqdm(data_loader):\n",
        "#         data_dict['BSSID_FEATS'] = d['BSSID_FEATS'].to(device).long()\n",
        "#         data_dict['RSSI_FEATS'] = d['RSSI_FEATS'].to(device).float()\n",
        "#         data_dict['site_id'] = d['site_id'].to(device).long()\n",
        "#         xy, floor = model(data_dict)\n",
        "#         prexs_list.append(xy[:, 0].cpu().detach().numpy())\n",
        "#         preys_list.append(xy[:, 1].cpu().detach().numpy())\n",
        "#         prefloors_list.append(floor.squeeze(-1).cpu().detach().numpy())\n",
        "#     prexs = np.concatenate(prexs_list)\n",
        "#     preys =np.concatenate(preys_list)\n",
        "#     prefloors = np.concatenate(prefloors_list)\n",
        "#     return prexs, preys, prefloors"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}