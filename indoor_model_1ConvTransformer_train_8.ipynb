{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "indoor_model_1ConvTransformer_train_8.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_deO9NH18_Kb"
      },
      "source": [
        "# Mounting GCS to colab\n",
        "# https://stackoverflow.com/questions/51715268/how-to-import-data-from-google-cloud-storage-to-google-colab\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_w17mjH-0gh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c18e7a84-47f2-4d77-f4bd-dd6be714904a"
      },
      "source": [
        "!echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n",
        "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n",
        "!apt -qq update\n",
        "!apt -qq install gcsfuse"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  2537  100  2537    0     0  72485      0 --:--:-- --:--:-- --:--:-- 70472\n",
            "OK\n",
            "36 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  gcsfuse\n",
            "0 upgraded, 1 newly installed, 0 to remove and 36 not upgraded.\n",
            "Need to get 10.6 MB of archives.\n",
            "After this operation, 22.7 MB of additional disk space will be used.\n",
            "Selecting previously unselected package gcsfuse.\n",
            "(Reading database ... 160690 files and directories currently installed.)\n",
            "Preparing to unpack .../gcsfuse_0.34.1_amd64.deb ...\n",
            "Unpacking gcsfuse (0.34.1) ...\n",
            "Setting up gcsfuse (0.34.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoG6QV8P_FC3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9235f235-ee15-4c1a-dd49-597629d54a5b"
      },
      "source": [
        "!mkdir colab_indoor\n",
        "!gcsfuse indoor-data colab_indoor\n",
        "# !mkdir colab_indoor/train_4\n",
        "# !gcsfuse indoor-data/train_4 colab_indoor/train_4\n",
        "# !mkdir colab_indoor/test_4\n",
        "# !gcsfuse indoor-data/test_4 colab_indoor/test_4"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021/04/26 01:01:11.866642 Using mount point: /content/colab_indoor\n",
            "2021/04/26 01:01:11.875511 Opening GCS connection...\n",
            "2021/04/26 01:01:12.211554 Mounting file system \"indoor-data\"...\n",
            "2021/04/26 01:01:12.228507 File system has been successfully mounted.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LLEkzgi_hq9",
        "outputId": "f0629253-1b1f-4e06-ab85-669e21f8fd5e"
      },
      "source": [
        "!ls -la -h ./colab_indoor/train_4_colcut"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 1.2G\n",
            "-rw-r--r-- 1 root root  43M Apr 14 21:07 5a0546857ecc773753327266_train.csv\n",
            "-rw-r--r-- 1 root root  46M Apr 14 21:07 5c3c44b80379370013e0fd2b_train.csv\n",
            "-rw-r--r-- 1 root root 113M Apr 14 21:08 5d27075f03f801723c2e360f_train.csv\n",
            "-rw-r--r-- 1 root root  43M Apr 14 21:08 5d27096c03f801723c31e5e0_train.csv\n",
            "-rw-r--r-- 1 root root  50M Apr 14 21:08 5d27097f03f801723c320d97_train.csv\n",
            "-rw-r--r-- 1 root root  12M Apr 14 21:08 5d27099f03f801723c32511d_train.csv\n",
            "-rw-r--r-- 1 root root  17M Apr 14 21:08 5d2709a003f801723c3251bf_train.csv\n",
            "-rw-r--r-- 1 root root  72M Apr 14 21:09 5d2709b303f801723c327472_train.csv\n",
            "-rw-r--r-- 1 root root  81M Apr 14 21:09 5d2709bb03f801723c32852c_train.csv\n",
            "-rw-r--r-- 1 root root  48M Apr 14 21:09 5d2709c303f801723c3299ee_train.csv\n",
            "-rw-r--r-- 1 root root  48M Apr 14 21:09 5d2709d403f801723c32bd39_train.csv\n",
            "-rw-r--r-- 1 root root  51M Apr 14 21:09 5d2709e003f801723c32d896_train.csv\n",
            "-rw-r--r-- 1 root root 3.9M Apr 14 21:10 5da138274db8ce0c98bbd3d2_train.csv\n",
            "-rw-r--r-- 1 root root  41M Apr 14 21:10 5da1382d4db8ce0c98bbe92e_train.csv\n",
            "-rw-r--r-- 1 root root  38M Apr 14 21:10 5da138314db8ce0c98bbf3a0_train.csv\n",
            "-rw-r--r-- 1 root root 6.7M Apr 14 21:10 5da138364db8ce0c98bc00f1_train.csv\n",
            "-rw-r--r-- 1 root root  63M Apr 14 21:10 5da1383b4db8ce0c98bc11ab_train.csv\n",
            "-rw-r--r-- 1 root root  35M Apr 14 21:10 5da138754db8ce0c98bca82f_train.csv\n",
            "-rw-r--r-- 1 root root  45M Apr 14 21:10 5da138764db8ce0c98bcaa46_train.csv\n",
            "-rw-r--r-- 1 root root  13M Apr 14 21:11 5da1389e4db8ce0c98bd0547_train.csv\n",
            "-rw-r--r-- 1 root root  82M Apr 14 21:11 5da138b74db8ce0c98bd4774_train.csv\n",
            "-rw-r--r-- 1 root root  71M Apr 14 21:11 5da958dd46f8266d0737457b_train.csv\n",
            "-rw-r--r-- 1 root root  76M Apr 14 21:11 5dbc1d84c1eb61796cf7c010_train.csv\n",
            "-rw-r--r-- 1 root root  75M Apr 14 21:12 5dc8cea7659e181adb076a3f_train.csv\n",
            "drwxr-xr-x 1 root root    0 Apr 26 01:01 .ipynb_checkpoints\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zxo_gtclkLZo",
        "outputId": "f931366c-7197-4ca2-cdce-44d554ed2ec0"
      },
      "source": [
        "import random\n",
        "from random import sample\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.ndimage.filters import uniform_filter1d\n",
        "from scipy.interpolate import interp1d\n",
        "import time\n",
        "from collections import defaultdict\n",
        "import seaborn as sns\n",
        "\n",
        "import scipy.stats as stats\n",
        "from pathlib import Path\n",
        "import glob\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import os\n",
        "import copy\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.autograd import Variable\n",
        "import multiprocessing\n",
        "import math\n",
        "\n",
        "EPOCH = 200 # default at 50\n",
        "BATCH_SIZE = 64\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "FOLDS = 5\n",
        "\n",
        "NUM_CORES = multiprocessing.cpu_count()\n",
        "print(NUM_CORES)\n",
        "\n",
        "OUTPUT_NAME = \"train_8_colcut_Conv1dTransformer\"\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "set_seed()"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImcyWYeuWJEP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "baec48ac-1627-428c-d2f0-4ec8121e0764"
      },
      "source": [
        "# train paths and test paths\n",
        "train_files = sorted(glob.glob(\"./colab_indoor/train_4_colcut/*\"))\n",
        "test_files = sorted(glob.glob(\"./colab_indoor/test_4_colcut/*\"))\n",
        "\n",
        "# load submission file\n",
        "sub_df = pd.read_csv(\"./colab_indoor/sample_submission.csv\", index_col=0)\n",
        "# sub_df[[\"site\", \"file\", \"timestamp\"]] = sub_df[\"site_path_timestamp\"].apply(lambda x: pd.Series(x.split(\"_\")))\n",
        "display(sub_df.head())"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>floor</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>site_path_timestamp</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5a0546857ecc773753327266_046cfa46be49fc10834815c6_0000000000009</th>\n",
              "      <td>0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>75.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5a0546857ecc773753327266_046cfa46be49fc10834815c6_0000000009017</th>\n",
              "      <td>0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>75.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5a0546857ecc773753327266_046cfa46be49fc10834815c6_0000000015326</th>\n",
              "      <td>0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>75.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5a0546857ecc773753327266_046cfa46be49fc10834815c6_0000000018763</th>\n",
              "      <td>0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>75.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5a0546857ecc773753327266_046cfa46be49fc10834815c6_0000000022328</th>\n",
              "      <td>0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>75.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    floor     x     y\n",
              "site_path_timestamp                                                  \n",
              "5a0546857ecc773753327266_046cfa46be49fc10834815...      0  75.0  75.0\n",
              "5a0546857ecc773753327266_046cfa46be49fc10834815...      0  75.0  75.0\n",
              "5a0546857ecc773753327266_046cfa46be49fc10834815...      0  75.0  75.0\n",
              "5a0546857ecc773753327266_046cfa46be49fc10834815...      0  75.0  75.0\n",
              "5a0546857ecc773753327266_046cfa46be49fc10834815...      0  75.0  75.0"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "B2jyhARLkpkk",
        "outputId": "bfe6e5c4-5bea-4d17-887e-2c3a1dfa03f6"
      },
      "source": [
        "# Load train csv and test csv\n",
        "train_df = pd.read_csv(train_files[10])\n",
        "test_df = pd.read_csv(test_files[10])\n",
        "display(train_df.head())\n",
        "display(test_df.head())"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wifi_ts</th>\n",
              "      <th>wps_diff</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>floor</th>\n",
              "      <th>floor_int</th>\n",
              "      <th>file_id</th>\n",
              "      <th>site_id</th>\n",
              "      <th>b1847b7279f12430b70cf177ae9419b2c6563c7e</th>\n",
              "      <th>e78f6a70bb684764884bf5bfc22876354dc4978f</th>\n",
              "      <th>7f92c838def910dc333d6ec1785cc9de7c428514</th>\n",
              "      <th>49baf7f0e5495ee2926baa0e941d265d725dbdd5</th>\n",
              "      <th>9419ecb5700d351a0ca4c6f6dc4f7804c5800ebe</th>\n",
              "      <th>6c598641414c17dfca87a3acc982507ba08902cb</th>\n",
              "      <th>bf8984bf3344f3267b1fb3cb5dc95ddf7e2117d3</th>\n",
              "      <th>24a2a9c3edd47eb479f05d4067368c9e14b8964b</th>\n",
              "      <th>2b3f7594cc8ab2b0413d45d6eea1149a9a7809a7</th>\n",
              "      <th>1cecf9fc6a1ceba0ad7063fdb5816ec43e90e94f</th>\n",
              "      <th>018a066872b67d5b33570ddeb6142c602a22e451</th>\n",
              "      <th>55ee0fec7b7be3e76132b20fca01e8486743a3f6</th>\n",
              "      <th>4f32282342971b17eb8611ac5f145d0b8768f62d</th>\n",
              "      <th>ee2a7ce46e83e2de489c9f78f4e550156d57f484</th>\n",
              "      <th>606fc3f5664630412548bbd099f9c8ad1dc5acb6</th>\n",
              "      <th>40ab9973a268cc79a4a8210e67f9b912723ed8c3</th>\n",
              "      <th>c81b745f26735105787cf9e7b547a7c37a65a851</th>\n",
              "      <th>832743c77af1c7eb12fcd909c438dcf39b6008f3</th>\n",
              "      <th>7b42d018fdfe2ab118d8ec85bcf1d6983750750c</th>\n",
              "      <th>ef99ef623422c284a774e35fc1b1cf3e721dbd03</th>\n",
              "      <th>c1591135c00bca7a723a49df8c9d8de34326fbd3</th>\n",
              "      <th>3956907df9b51fae849a7afced246f127f259504</th>\n",
              "      <th>1359034ef247ed40bf5b3723915b9fc60cc74837</th>\n",
              "      <th>2a5b0895595bcf131a0b5c3e5dc4b9f39e06bd3f</th>\n",
              "      <th>ca7a7877b1dbad8f6ef696b1e88f34dc6f635b0d</th>\n",
              "      <th>396640532a81255d6b75b41e7a184c1393b74ee4</th>\n",
              "      <th>aebc6ae6f9dfe7b548779e39cc9fd03c60a67ecc</th>\n",
              "      <th>70e578e027d0ab0bfeb5959e18f3c8045a32236d</th>\n",
              "      <th>07ccdba1f0a266adf501c867319ac7007e65d290</th>\n",
              "      <th>d7b2ba98b972b65650af520075c9712a3d8994a7</th>\n",
              "      <th>2b844704051b64e47b4800e1d6e932bbdd5356b6</th>\n",
              "      <th>1c390c87d362e628cebc103eb247d2b7aa813542</th>\n",
              "      <th>...</th>\n",
              "      <th>46e35eba345a6366234c028567bbb91c99b872e5</th>\n",
              "      <th>298e1870fda64fe8018ec79e835cf308f81181fa</th>\n",
              "      <th>31b0561e7e9a03156b248da215d7ab7bf8d6d8c8</th>\n",
              "      <th>3ab6773bc6bce7fb154b3d46f6058f0192bfd01b</th>\n",
              "      <th>41d0c04a20a77e8daaba6c585f083ca0ef57affc</th>\n",
              "      <th>a3dfc65c01d171a671cd615236b79c61810de354</th>\n",
              "      <th>06028150b43acb7e11121888ab434cdd5f679f1d</th>\n",
              "      <th>f7853f850bbb98d20bb2b4dd6380c071b5a1cb02</th>\n",
              "      <th>078a75dfda9e932f608fca0837610b97d11d3dd7</th>\n",
              "      <th>fc8fd87104388e513937ac13696b6f72af2add53</th>\n",
              "      <th>422765063ea5b0e5667a240e3b802041ab93b6e3</th>\n",
              "      <th>6cfaf9601b6e2587a321d3b803c20f9eb05fd452</th>\n",
              "      <th>35c0ef8cb2af11a81092979d55c4324b8101332f</th>\n",
              "      <th>764cbb8b20a46c411fe5807df9867b92c0935c08</th>\n",
              "      <th>78209eb1032640dd8f611e310c8619ab2c9cb071</th>\n",
              "      <th>1fc19e52666a95169b365f5ad1352d9369cb045a</th>\n",
              "      <th>14d3489b6de7d970babc8a951bf6ed5bd289dea0</th>\n",
              "      <th>6646a9365ace5164d2ef3dfb39b88a8a924568d3</th>\n",
              "      <th>a7ac17ed71cc594bed820bfbbca833f3f9972592</th>\n",
              "      <th>976e778d614b1e8e9efa8bc7eeaf552b7fe5ccb5</th>\n",
              "      <th>5749b4541786aea857ff1552dfac8cf292044c29</th>\n",
              "      <th>b1f4814d1a8c7885960118015e2c8f47fcdd0f4f</th>\n",
              "      <th>75df7c8888ddbf148407aa76c3d6b72406bc4c27</th>\n",
              "      <th>fc88f6a4f0351f8a2b34d256fcda35579d9e0ead</th>\n",
              "      <th>21f079033442b71f1a870ca0988fa9afcc7dc810</th>\n",
              "      <th>3f8321ce0dd6348fa440eb25acae2be996c3b2e7</th>\n",
              "      <th>9054af7ed2ceb6b130b4fd2a09f36b9b1f611f11</th>\n",
              "      <th>77de2f0f3005949e35e2e2aef7af1ddc5d164695</th>\n",
              "      <th>588f35babb83fab68a9c539567140ba5c17284c7</th>\n",
              "      <th>68962923d8621f6868a762b2344ce1ab8209ecdd</th>\n",
              "      <th>7abbb83f5b877ce5c1c9e835422365cd8bac3b0d</th>\n",
              "      <th>acb4abc93968ad51368a0351fa7fda5401598069</th>\n",
              "      <th>f20fed9f248d4352def744d9a8262b49042ee7f3</th>\n",
              "      <th>437d45cd7c45b040b95abdb483b02d601c761d7d</th>\n",
              "      <th>b083b8279418c48d60a05cff039b0536339a1e4d</th>\n",
              "      <th>fa0d8c168b62f11f34fdf314d81cebdf1ca9ebd0</th>\n",
              "      <th>955eb46cfdee70adab1de9ce909f0cb059fd29d2</th>\n",
              "      <th>48d751207622a3606df95184fd58b32347057af3</th>\n",
              "      <th>5238e869a2d0d2a851ba1f9484c874c57419148e</th>\n",
              "      <th>63781517942f8b63c2189c376cc0cf3db1d27ed1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1573789444679</td>\n",
              "      <td>1918</td>\n",
              "      <td>88.03561</td>\n",
              "      <td>109.90122</td>\n",
              "      <td>B1</td>\n",
              "      <td>-1</td>\n",
              "      <td>5dce2cf294e4900006124d2a</td>\n",
              "      <td>5d2709d403f801723c32bd39</td>\n",
              "      <td>-76</td>\n",
              "      <td>-74</td>\n",
              "      <td>-76</td>\n",
              "      <td>-999</td>\n",
              "      <td>-73</td>\n",
              "      <td>-89</td>\n",
              "      <td>-77</td>\n",
              "      <td>-999</td>\n",
              "      <td>-49</td>\n",
              "      <td>-999</td>\n",
              "      <td>-73</td>\n",
              "      <td>-87</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-46</td>\n",
              "      <td>-66</td>\n",
              "      <td>-75</td>\n",
              "      <td>-84</td>\n",
              "      <td>-999</td>\n",
              "      <td>-76</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-84</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-80</td>\n",
              "      <td>...</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1573789446609</td>\n",
              "      <td>3848</td>\n",
              "      <td>88.03561</td>\n",
              "      <td>109.90122</td>\n",
              "      <td>B1</td>\n",
              "      <td>-1</td>\n",
              "      <td>5dce2cf294e4900006124d2a</td>\n",
              "      <td>5d2709d403f801723c32bd39</td>\n",
              "      <td>-79</td>\n",
              "      <td>-79</td>\n",
              "      <td>-83</td>\n",
              "      <td>-999</td>\n",
              "      <td>-73</td>\n",
              "      <td>-89</td>\n",
              "      <td>-77</td>\n",
              "      <td>-999</td>\n",
              "      <td>-44</td>\n",
              "      <td>-88</td>\n",
              "      <td>-78</td>\n",
              "      <td>-87</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-59</td>\n",
              "      <td>-66</td>\n",
              "      <td>-75</td>\n",
              "      <td>-89</td>\n",
              "      <td>-999</td>\n",
              "      <td>-76</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-84</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-80</td>\n",
              "      <td>...</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1573789448539</td>\n",
              "      <td>5298</td>\n",
              "      <td>91.62208</td>\n",
              "      <td>108.70687</td>\n",
              "      <td>B1</td>\n",
              "      <td>-1</td>\n",
              "      <td>5dce2cf294e4900006124d2a</td>\n",
              "      <td>5d2709d403f801723c32bd39</td>\n",
              "      <td>-68</td>\n",
              "      <td>-67</td>\n",
              "      <td>-67</td>\n",
              "      <td>-78</td>\n",
              "      <td>-73</td>\n",
              "      <td>-89</td>\n",
              "      <td>-78</td>\n",
              "      <td>-85</td>\n",
              "      <td>-46</td>\n",
              "      <td>-88</td>\n",
              "      <td>-78</td>\n",
              "      <td>-87</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-48</td>\n",
              "      <td>-66</td>\n",
              "      <td>-75</td>\n",
              "      <td>-89</td>\n",
              "      <td>-999</td>\n",
              "      <td>-76</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-84</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-80</td>\n",
              "      <td>...</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1573789450452</td>\n",
              "      <td>3385</td>\n",
              "      <td>91.62208</td>\n",
              "      <td>108.70687</td>\n",
              "      <td>B1</td>\n",
              "      <td>-1</td>\n",
              "      <td>5dce2cf294e4900006124d2a</td>\n",
              "      <td>5d2709d403f801723c32bd39</td>\n",
              "      <td>-73</td>\n",
              "      <td>-73</td>\n",
              "      <td>-77</td>\n",
              "      <td>-78</td>\n",
              "      <td>-73</td>\n",
              "      <td>-89</td>\n",
              "      <td>-74</td>\n",
              "      <td>-91</td>\n",
              "      <td>-55</td>\n",
              "      <td>-84</td>\n",
              "      <td>-77</td>\n",
              "      <td>-87</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-42</td>\n",
              "      <td>-66</td>\n",
              "      <td>-75</td>\n",
              "      <td>-89</td>\n",
              "      <td>-999</td>\n",
              "      <td>-76</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-84</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-83</td>\n",
              "      <td>...</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1573789452370</td>\n",
              "      <td>1467</td>\n",
              "      <td>91.62208</td>\n",
              "      <td>108.70687</td>\n",
              "      <td>B1</td>\n",
              "      <td>-1</td>\n",
              "      <td>5dce2cf294e4900006124d2a</td>\n",
              "      <td>5d2709d403f801723c32bd39</td>\n",
              "      <td>-72</td>\n",
              "      <td>-71</td>\n",
              "      <td>-70</td>\n",
              "      <td>-78</td>\n",
              "      <td>-73</td>\n",
              "      <td>-76</td>\n",
              "      <td>-81</td>\n",
              "      <td>-91</td>\n",
              "      <td>-48</td>\n",
              "      <td>-84</td>\n",
              "      <td>-77</td>\n",
              "      <td>-78</td>\n",
              "      <td>-76</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-47</td>\n",
              "      <td>-66</td>\n",
              "      <td>-75</td>\n",
              "      <td>-89</td>\n",
              "      <td>-999</td>\n",
              "      <td>-77</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-86</td>\n",
              "      <td>-84</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-89</td>\n",
              "      <td>...</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 999 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         wifi_ts  ...  63781517942f8b63c2189c376cc0cf3db1d27ed1\n",
              "0  1573789444679  ...                                      -999\n",
              "1  1573789446609  ...                                      -999\n",
              "2  1573789448539  ...                                      -999\n",
              "3  1573789450452  ...                                      -999\n",
              "4  1573789452370  ...                                      -999\n",
              "\n",
              "[5 rows x 999 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>site_path_timestamp</th>\n",
              "      <th>correct_wps_ts</th>\n",
              "      <th>wifi_ts</th>\n",
              "      <th>wps_diff</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>floor</th>\n",
              "      <th>floor_int</th>\n",
              "      <th>file_id</th>\n",
              "      <th>site_id</th>\n",
              "      <th>b1847b7279f12430b70cf177ae9419b2c6563c7e</th>\n",
              "      <th>e78f6a70bb684764884bf5bfc22876354dc4978f</th>\n",
              "      <th>7f92c838def910dc333d6ec1785cc9de7c428514</th>\n",
              "      <th>49baf7f0e5495ee2926baa0e941d265d725dbdd5</th>\n",
              "      <th>9419ecb5700d351a0ca4c6f6dc4f7804c5800ebe</th>\n",
              "      <th>6c598641414c17dfca87a3acc982507ba08902cb</th>\n",
              "      <th>bf8984bf3344f3267b1fb3cb5dc95ddf7e2117d3</th>\n",
              "      <th>24a2a9c3edd47eb479f05d4067368c9e14b8964b</th>\n",
              "      <th>2b3f7594cc8ab2b0413d45d6eea1149a9a7809a7</th>\n",
              "      <th>1cecf9fc6a1ceba0ad7063fdb5816ec43e90e94f</th>\n",
              "      <th>018a066872b67d5b33570ddeb6142c602a22e451</th>\n",
              "      <th>55ee0fec7b7be3e76132b20fca01e8486743a3f6</th>\n",
              "      <th>4f32282342971b17eb8611ac5f145d0b8768f62d</th>\n",
              "      <th>ee2a7ce46e83e2de489c9f78f4e550156d57f484</th>\n",
              "      <th>606fc3f5664630412548bbd099f9c8ad1dc5acb6</th>\n",
              "      <th>40ab9973a268cc79a4a8210e67f9b912723ed8c3</th>\n",
              "      <th>c81b745f26735105787cf9e7b547a7c37a65a851</th>\n",
              "      <th>832743c77af1c7eb12fcd909c438dcf39b6008f3</th>\n",
              "      <th>7b42d018fdfe2ab118d8ec85bcf1d6983750750c</th>\n",
              "      <th>ef99ef623422c284a774e35fc1b1cf3e721dbd03</th>\n",
              "      <th>c1591135c00bca7a723a49df8c9d8de34326fbd3</th>\n",
              "      <th>3956907df9b51fae849a7afced246f127f259504</th>\n",
              "      <th>1359034ef247ed40bf5b3723915b9fc60cc74837</th>\n",
              "      <th>2a5b0895595bcf131a0b5c3e5dc4b9f39e06bd3f</th>\n",
              "      <th>ca7a7877b1dbad8f6ef696b1e88f34dc6f635b0d</th>\n",
              "      <th>396640532a81255d6b75b41e7a184c1393b74ee4</th>\n",
              "      <th>aebc6ae6f9dfe7b548779e39cc9fd03c60a67ecc</th>\n",
              "      <th>70e578e027d0ab0bfeb5959e18f3c8045a32236d</th>\n",
              "      <th>07ccdba1f0a266adf501c867319ac7007e65d290</th>\n",
              "      <th>d7b2ba98b972b65650af520075c9712a3d8994a7</th>\n",
              "      <th>...</th>\n",
              "      <th>46e35eba345a6366234c028567bbb91c99b872e5</th>\n",
              "      <th>298e1870fda64fe8018ec79e835cf308f81181fa</th>\n",
              "      <th>31b0561e7e9a03156b248da215d7ab7bf8d6d8c8</th>\n",
              "      <th>3ab6773bc6bce7fb154b3d46f6058f0192bfd01b</th>\n",
              "      <th>41d0c04a20a77e8daaba6c585f083ca0ef57affc</th>\n",
              "      <th>a3dfc65c01d171a671cd615236b79c61810de354</th>\n",
              "      <th>06028150b43acb7e11121888ab434cdd5f679f1d</th>\n",
              "      <th>f7853f850bbb98d20bb2b4dd6380c071b5a1cb02</th>\n",
              "      <th>078a75dfda9e932f608fca0837610b97d11d3dd7</th>\n",
              "      <th>fc8fd87104388e513937ac13696b6f72af2add53</th>\n",
              "      <th>422765063ea5b0e5667a240e3b802041ab93b6e3</th>\n",
              "      <th>6cfaf9601b6e2587a321d3b803c20f9eb05fd452</th>\n",
              "      <th>35c0ef8cb2af11a81092979d55c4324b8101332f</th>\n",
              "      <th>764cbb8b20a46c411fe5807df9867b92c0935c08</th>\n",
              "      <th>78209eb1032640dd8f611e310c8619ab2c9cb071</th>\n",
              "      <th>1fc19e52666a95169b365f5ad1352d9369cb045a</th>\n",
              "      <th>14d3489b6de7d970babc8a951bf6ed5bd289dea0</th>\n",
              "      <th>6646a9365ace5164d2ef3dfb39b88a8a924568d3</th>\n",
              "      <th>a7ac17ed71cc594bed820bfbbca833f3f9972592</th>\n",
              "      <th>976e778d614b1e8e9efa8bc7eeaf552b7fe5ccb5</th>\n",
              "      <th>5749b4541786aea857ff1552dfac8cf292044c29</th>\n",
              "      <th>b1f4814d1a8c7885960118015e2c8f47fcdd0f4f</th>\n",
              "      <th>75df7c8888ddbf148407aa76c3d6b72406bc4c27</th>\n",
              "      <th>fc88f6a4f0351f8a2b34d256fcda35579d9e0ead</th>\n",
              "      <th>21f079033442b71f1a870ca0988fa9afcc7dc810</th>\n",
              "      <th>3f8321ce0dd6348fa440eb25acae2be996c3b2e7</th>\n",
              "      <th>9054af7ed2ceb6b130b4fd2a09f36b9b1f611f11</th>\n",
              "      <th>77de2f0f3005949e35e2e2aef7af1ddc5d164695</th>\n",
              "      <th>588f35babb83fab68a9c539567140ba5c17284c7</th>\n",
              "      <th>68962923d8621f6868a762b2344ce1ab8209ecdd</th>\n",
              "      <th>7abbb83f5b877ce5c1c9e835422365cd8bac3b0d</th>\n",
              "      <th>acb4abc93968ad51368a0351fa7fda5401598069</th>\n",
              "      <th>f20fed9f248d4352def744d9a8262b49042ee7f3</th>\n",
              "      <th>437d45cd7c45b040b95abdb483b02d601c761d7d</th>\n",
              "      <th>b083b8279418c48d60a05cff039b0536339a1e4d</th>\n",
              "      <th>fa0d8c168b62f11f34fdf314d81cebdf1ca9ebd0</th>\n",
              "      <th>955eb46cfdee70adab1de9ce909f0cb059fd29d2</th>\n",
              "      <th>48d751207622a3606df95184fd58b32347057af3</th>\n",
              "      <th>5238e869a2d0d2a851ba1f9484c874c57419148e</th>\n",
              "      <th>63781517942f8b63c2189c376cc0cf3db1d27ed1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5d2709d403f801723c32bd39_06882da3694b7160c0f10...</td>\n",
              "      <td>1.573706e+12</td>\n",
              "      <td>1573705854189</td>\n",
              "      <td>5859</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>06882da3694b7160c0f105f5</td>\n",
              "      <td>5d2709d403f801723c32bd39</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-87</td>\n",
              "      <td>-999</td>\n",
              "      <td>-78</td>\n",
              "      <td>-999</td>\n",
              "      <td>-91</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>...</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-80</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-76</td>\n",
              "      <td>-85</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-88</td>\n",
              "      <td>-70</td>\n",
              "      <td>-68</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-89</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-68</td>\n",
              "      <td>-999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5d2709d403f801723c32bd39_06882da3694b7160c0f10...</td>\n",
              "      <td>1.573706e+12</td>\n",
              "      <td>1573705854189</td>\n",
              "      <td>174</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>06882da3694b7160c0f105f5</td>\n",
              "      <td>5d2709d403f801723c32bd39</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-87</td>\n",
              "      <td>-999</td>\n",
              "      <td>-78</td>\n",
              "      <td>-999</td>\n",
              "      <td>-91</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>...</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-80</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-76</td>\n",
              "      <td>-85</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-88</td>\n",
              "      <td>-70</td>\n",
              "      <td>-68</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-89</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-68</td>\n",
              "      <td>-999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5d2709d403f801723c32bd39_06882da3694b7160c0f10...</td>\n",
              "      <td>1.573706e+12</td>\n",
              "      <td>1573705856155</td>\n",
              "      <td>67</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>06882da3694b7160c0f105f5</td>\n",
              "      <td>5d2709d403f801723c32bd39</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-87</td>\n",
              "      <td>-999</td>\n",
              "      <td>-80</td>\n",
              "      <td>-999</td>\n",
              "      <td>-91</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>...</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-80</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-76</td>\n",
              "      <td>-85</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-89</td>\n",
              "      <td>-70</td>\n",
              "      <td>-68</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-90</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-68</td>\n",
              "      <td>-999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5d2709d403f801723c32bd39_06882da3694b7160c0f10...</td>\n",
              "      <td>1.573706e+12</td>\n",
              "      <td>1573705862090</td>\n",
              "      <td>898</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>06882da3694b7160c0f105f5</td>\n",
              "      <td>5d2709d403f801723c32bd39</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-87</td>\n",
              "      <td>-999</td>\n",
              "      <td>-68</td>\n",
              "      <td>-999</td>\n",
              "      <td>-91</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>...</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-73</td>\n",
              "      <td>-91</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-89</td>\n",
              "      <td>-70</td>\n",
              "      <td>-68</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-89</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5d2709d403f801723c32bd39_06882da3694b7160c0f10...</td>\n",
              "      <td>1.573706e+12</td>\n",
              "      <td>1573705869915</td>\n",
              "      <td>720</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>06882da3694b7160c0f105f5</td>\n",
              "      <td>5d2709d403f801723c32bd39</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-89</td>\n",
              "      <td>-999</td>\n",
              "      <td>-71</td>\n",
              "      <td>-999</td>\n",
              "      <td>-87</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>...</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-73</td>\n",
              "      <td>-91</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-89</td>\n",
              "      <td>-70</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-91</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-74</td>\n",
              "      <td>-999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1001 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 site_path_timestamp  ...  63781517942f8b63c2189c376cc0cf3db1d27ed1\n",
              "0  5d2709d403f801723c32bd39_06882da3694b7160c0f10...  ...                                      -999\n",
              "1  5d2709d403f801723c32bd39_06882da3694b7160c0f10...  ...                                      -999\n",
              "2  5d2709d403f801723c32bd39_06882da3694b7160c0f10...  ...                                      -999\n",
              "3  5d2709d403f801723c32bd39_06882da3694b7160c0f10...  ...                                      -999\n",
              "4  5d2709d403f801723c32bd39_06882da3694b7160c0f10...  ...                                      -999\n",
              "\n",
              "[5 rows x 1001 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "id": "oaMr1ftymrUB",
        "outputId": "a8b5253a-191b-477c-e083-be2247918b76"
      },
      "source": [
        "# Match train and test columns\n",
        "all_train_cols = list(train_df.columns)\n",
        "all_test_cols = list(test_df.columns)\n",
        "print(\"all train cols: \", len(all_train_cols), \"\\n\", \"all test cols: \", len(all_test_cols))\n",
        "\n",
        "# get all non-overlapping columns\n",
        "no_overlap_col = list(set(all_train_cols) ^ set(all_test_cols))\n",
        "# no_overlap_col += [\"floor\", \"file_id\", \"site_id\"] # add other columns to exclude\n",
        "no_overlap_col += [\"wifi_ts\", \"wps_diff\", \"floor\", \"file_id\", \"site_id\"] # try excluding timestamp and wps_diff\n",
        "train_cols = [x for x in all_train_cols if x not in no_overlap_col]\n",
        "test_cols = [x for x in all_test_cols if x not in no_overlap_col]\n",
        "# test_cols += [\"site_path_timestamp\"] # test_df needs to keep \"site_path_timestamp\"\n",
        "\n",
        "# filter out the df by the columns to leave\n",
        "train_df = train_df[train_cols]\n",
        "test_df = test_df[test_cols]\n",
        "\n",
        "# # Drop some columns not necessary as a feature\n",
        "# drop_cols = [\"wifi_ts\", \"floor\", \"file_id\", \"site_id\"]\n",
        "# for df in [train_df, test_df]:\n",
        "#     df = df.drop(columns=drop_cols, inplace=True)\n",
        "\n",
        "# Convert df object columns to integers and then the whole thing to tensors\n",
        "for df in [train_df, test_df]:\n",
        "    obj_col = list(df.select_dtypes(include=['object']).columns)\n",
        "    for col in obj_col:\n",
        "        le = LabelEncoder()\n",
        "        df[col] = le.fit_transform(df[col].values)\n",
        "\n",
        "print(len(train_df.columns))\n",
        "print(len(test_df.columns))\n",
        "print(len(train_df))\n",
        "print(len(test_df))\n",
        "print(\"object dtype columns in train\", train_df.select_dtypes(include=['object']).columns)\n",
        "print(\"object dtype columns in test\", test_df.select_dtypes(include=['object']).columns)\n",
        "display(train_df.head())\n",
        "display(test_df.head())"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "all train cols:  999 \n",
            " all test cols:  1001\n",
            "994\n",
            "994\n",
            "10027\n",
            "1223\n",
            "object dtype columns in train Index([], dtype='object')\n",
            "object dtype columns in test Index([], dtype='object')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>floor_int</th>\n",
              "      <th>b1847b7279f12430b70cf177ae9419b2c6563c7e</th>\n",
              "      <th>e78f6a70bb684764884bf5bfc22876354dc4978f</th>\n",
              "      <th>7f92c838def910dc333d6ec1785cc9de7c428514</th>\n",
              "      <th>49baf7f0e5495ee2926baa0e941d265d725dbdd5</th>\n",
              "      <th>9419ecb5700d351a0ca4c6f6dc4f7804c5800ebe</th>\n",
              "      <th>6c598641414c17dfca87a3acc982507ba08902cb</th>\n",
              "      <th>bf8984bf3344f3267b1fb3cb5dc95ddf7e2117d3</th>\n",
              "      <th>24a2a9c3edd47eb479f05d4067368c9e14b8964b</th>\n",
              "      <th>2b3f7594cc8ab2b0413d45d6eea1149a9a7809a7</th>\n",
              "      <th>1cecf9fc6a1ceba0ad7063fdb5816ec43e90e94f</th>\n",
              "      <th>018a066872b67d5b33570ddeb6142c602a22e451</th>\n",
              "      <th>55ee0fec7b7be3e76132b20fca01e8486743a3f6</th>\n",
              "      <th>4f32282342971b17eb8611ac5f145d0b8768f62d</th>\n",
              "      <th>ee2a7ce46e83e2de489c9f78f4e550156d57f484</th>\n",
              "      <th>606fc3f5664630412548bbd099f9c8ad1dc5acb6</th>\n",
              "      <th>40ab9973a268cc79a4a8210e67f9b912723ed8c3</th>\n",
              "      <th>c81b745f26735105787cf9e7b547a7c37a65a851</th>\n",
              "      <th>832743c77af1c7eb12fcd909c438dcf39b6008f3</th>\n",
              "      <th>7b42d018fdfe2ab118d8ec85bcf1d6983750750c</th>\n",
              "      <th>ef99ef623422c284a774e35fc1b1cf3e721dbd03</th>\n",
              "      <th>c1591135c00bca7a723a49df8c9d8de34326fbd3</th>\n",
              "      <th>3956907df9b51fae849a7afced246f127f259504</th>\n",
              "      <th>1359034ef247ed40bf5b3723915b9fc60cc74837</th>\n",
              "      <th>2a5b0895595bcf131a0b5c3e5dc4b9f39e06bd3f</th>\n",
              "      <th>ca7a7877b1dbad8f6ef696b1e88f34dc6f635b0d</th>\n",
              "      <th>396640532a81255d6b75b41e7a184c1393b74ee4</th>\n",
              "      <th>aebc6ae6f9dfe7b548779e39cc9fd03c60a67ecc</th>\n",
              "      <th>70e578e027d0ab0bfeb5959e18f3c8045a32236d</th>\n",
              "      <th>07ccdba1f0a266adf501c867319ac7007e65d290</th>\n",
              "      <th>d7b2ba98b972b65650af520075c9712a3d8994a7</th>\n",
              "      <th>2b844704051b64e47b4800e1d6e932bbdd5356b6</th>\n",
              "      <th>1c390c87d362e628cebc103eb247d2b7aa813542</th>\n",
              "      <th>6d70c76ca1d2e44f634d98810313c1c91b07ffa3</th>\n",
              "      <th>ec097c076cbcdbbcda43d0eb6372101151a914e0</th>\n",
              "      <th>eb61afa796d2ebdf9ec651593837743dc6c3ef11</th>\n",
              "      <th>e52f06cc2304cab39cfd6dd1f0918bad158e8764</th>\n",
              "      <th>6f3c758c55fe36ca540b2720d59a0da5c3553efc</th>\n",
              "      <th>...</th>\n",
              "      <th>46e35eba345a6366234c028567bbb91c99b872e5</th>\n",
              "      <th>298e1870fda64fe8018ec79e835cf308f81181fa</th>\n",
              "      <th>31b0561e7e9a03156b248da215d7ab7bf8d6d8c8</th>\n",
              "      <th>3ab6773bc6bce7fb154b3d46f6058f0192bfd01b</th>\n",
              "      <th>41d0c04a20a77e8daaba6c585f083ca0ef57affc</th>\n",
              "      <th>a3dfc65c01d171a671cd615236b79c61810de354</th>\n",
              "      <th>06028150b43acb7e11121888ab434cdd5f679f1d</th>\n",
              "      <th>f7853f850bbb98d20bb2b4dd6380c071b5a1cb02</th>\n",
              "      <th>078a75dfda9e932f608fca0837610b97d11d3dd7</th>\n",
              "      <th>fc8fd87104388e513937ac13696b6f72af2add53</th>\n",
              "      <th>422765063ea5b0e5667a240e3b802041ab93b6e3</th>\n",
              "      <th>6cfaf9601b6e2587a321d3b803c20f9eb05fd452</th>\n",
              "      <th>35c0ef8cb2af11a81092979d55c4324b8101332f</th>\n",
              "      <th>764cbb8b20a46c411fe5807df9867b92c0935c08</th>\n",
              "      <th>78209eb1032640dd8f611e310c8619ab2c9cb071</th>\n",
              "      <th>1fc19e52666a95169b365f5ad1352d9369cb045a</th>\n",
              "      <th>14d3489b6de7d970babc8a951bf6ed5bd289dea0</th>\n",
              "      <th>6646a9365ace5164d2ef3dfb39b88a8a924568d3</th>\n",
              "      <th>a7ac17ed71cc594bed820bfbbca833f3f9972592</th>\n",
              "      <th>976e778d614b1e8e9efa8bc7eeaf552b7fe5ccb5</th>\n",
              "      <th>5749b4541786aea857ff1552dfac8cf292044c29</th>\n",
              "      <th>b1f4814d1a8c7885960118015e2c8f47fcdd0f4f</th>\n",
              "      <th>75df7c8888ddbf148407aa76c3d6b72406bc4c27</th>\n",
              "      <th>fc88f6a4f0351f8a2b34d256fcda35579d9e0ead</th>\n",
              "      <th>21f079033442b71f1a870ca0988fa9afcc7dc810</th>\n",
              "      <th>3f8321ce0dd6348fa440eb25acae2be996c3b2e7</th>\n",
              "      <th>9054af7ed2ceb6b130b4fd2a09f36b9b1f611f11</th>\n",
              "      <th>77de2f0f3005949e35e2e2aef7af1ddc5d164695</th>\n",
              "      <th>588f35babb83fab68a9c539567140ba5c17284c7</th>\n",
              "      <th>68962923d8621f6868a762b2344ce1ab8209ecdd</th>\n",
              "      <th>7abbb83f5b877ce5c1c9e835422365cd8bac3b0d</th>\n",
              "      <th>acb4abc93968ad51368a0351fa7fda5401598069</th>\n",
              "      <th>f20fed9f248d4352def744d9a8262b49042ee7f3</th>\n",
              "      <th>437d45cd7c45b040b95abdb483b02d601c761d7d</th>\n",
              "      <th>b083b8279418c48d60a05cff039b0536339a1e4d</th>\n",
              "      <th>fa0d8c168b62f11f34fdf314d81cebdf1ca9ebd0</th>\n",
              "      <th>955eb46cfdee70adab1de9ce909f0cb059fd29d2</th>\n",
              "      <th>48d751207622a3606df95184fd58b32347057af3</th>\n",
              "      <th>5238e869a2d0d2a851ba1f9484c874c57419148e</th>\n",
              "      <th>63781517942f8b63c2189c376cc0cf3db1d27ed1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>88.03561</td>\n",
              "      <td>109.90122</td>\n",
              "      <td>-1</td>\n",
              "      <td>-76</td>\n",
              "      <td>-74</td>\n",
              "      <td>-76</td>\n",
              "      <td>-999</td>\n",
              "      <td>-73</td>\n",
              "      <td>-89</td>\n",
              "      <td>-77</td>\n",
              "      <td>-999</td>\n",
              "      <td>-49</td>\n",
              "      <td>-999</td>\n",
              "      <td>-73</td>\n",
              "      <td>-87</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-46</td>\n",
              "      <td>-66</td>\n",
              "      <td>-75</td>\n",
              "      <td>-84</td>\n",
              "      <td>-999</td>\n",
              "      <td>-76</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-84</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-80</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>...</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>88.03561</td>\n",
              "      <td>109.90122</td>\n",
              "      <td>-1</td>\n",
              "      <td>-79</td>\n",
              "      <td>-79</td>\n",
              "      <td>-83</td>\n",
              "      <td>-999</td>\n",
              "      <td>-73</td>\n",
              "      <td>-89</td>\n",
              "      <td>-77</td>\n",
              "      <td>-999</td>\n",
              "      <td>-44</td>\n",
              "      <td>-88</td>\n",
              "      <td>-78</td>\n",
              "      <td>-87</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-59</td>\n",
              "      <td>-66</td>\n",
              "      <td>-75</td>\n",
              "      <td>-89</td>\n",
              "      <td>-999</td>\n",
              "      <td>-76</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-84</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-80</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>...</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>91.62208</td>\n",
              "      <td>108.70687</td>\n",
              "      <td>-1</td>\n",
              "      <td>-68</td>\n",
              "      <td>-67</td>\n",
              "      <td>-67</td>\n",
              "      <td>-78</td>\n",
              "      <td>-73</td>\n",
              "      <td>-89</td>\n",
              "      <td>-78</td>\n",
              "      <td>-85</td>\n",
              "      <td>-46</td>\n",
              "      <td>-88</td>\n",
              "      <td>-78</td>\n",
              "      <td>-87</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-48</td>\n",
              "      <td>-66</td>\n",
              "      <td>-75</td>\n",
              "      <td>-89</td>\n",
              "      <td>-999</td>\n",
              "      <td>-76</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-84</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-80</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>...</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>91.62208</td>\n",
              "      <td>108.70687</td>\n",
              "      <td>-1</td>\n",
              "      <td>-73</td>\n",
              "      <td>-73</td>\n",
              "      <td>-77</td>\n",
              "      <td>-78</td>\n",
              "      <td>-73</td>\n",
              "      <td>-89</td>\n",
              "      <td>-74</td>\n",
              "      <td>-91</td>\n",
              "      <td>-55</td>\n",
              "      <td>-84</td>\n",
              "      <td>-77</td>\n",
              "      <td>-87</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-42</td>\n",
              "      <td>-66</td>\n",
              "      <td>-75</td>\n",
              "      <td>-89</td>\n",
              "      <td>-999</td>\n",
              "      <td>-76</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-84</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-83</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>...</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>91.62208</td>\n",
              "      <td>108.70687</td>\n",
              "      <td>-1</td>\n",
              "      <td>-72</td>\n",
              "      <td>-71</td>\n",
              "      <td>-70</td>\n",
              "      <td>-78</td>\n",
              "      <td>-73</td>\n",
              "      <td>-76</td>\n",
              "      <td>-81</td>\n",
              "      <td>-91</td>\n",
              "      <td>-48</td>\n",
              "      <td>-84</td>\n",
              "      <td>-77</td>\n",
              "      <td>-78</td>\n",
              "      <td>-76</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-47</td>\n",
              "      <td>-66</td>\n",
              "      <td>-75</td>\n",
              "      <td>-89</td>\n",
              "      <td>-999</td>\n",
              "      <td>-77</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-86</td>\n",
              "      <td>-84</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-89</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>...</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 994 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          x  ...  63781517942f8b63c2189c376cc0cf3db1d27ed1\n",
              "0  88.03561  ...                                      -999\n",
              "1  88.03561  ...                                      -999\n",
              "2  91.62208  ...                                      -999\n",
              "3  91.62208  ...                                      -999\n",
              "4  91.62208  ...                                      -999\n",
              "\n",
              "[5 rows x 994 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>floor_int</th>\n",
              "      <th>b1847b7279f12430b70cf177ae9419b2c6563c7e</th>\n",
              "      <th>e78f6a70bb684764884bf5bfc22876354dc4978f</th>\n",
              "      <th>7f92c838def910dc333d6ec1785cc9de7c428514</th>\n",
              "      <th>49baf7f0e5495ee2926baa0e941d265d725dbdd5</th>\n",
              "      <th>9419ecb5700d351a0ca4c6f6dc4f7804c5800ebe</th>\n",
              "      <th>6c598641414c17dfca87a3acc982507ba08902cb</th>\n",
              "      <th>bf8984bf3344f3267b1fb3cb5dc95ddf7e2117d3</th>\n",
              "      <th>24a2a9c3edd47eb479f05d4067368c9e14b8964b</th>\n",
              "      <th>2b3f7594cc8ab2b0413d45d6eea1149a9a7809a7</th>\n",
              "      <th>1cecf9fc6a1ceba0ad7063fdb5816ec43e90e94f</th>\n",
              "      <th>018a066872b67d5b33570ddeb6142c602a22e451</th>\n",
              "      <th>55ee0fec7b7be3e76132b20fca01e8486743a3f6</th>\n",
              "      <th>4f32282342971b17eb8611ac5f145d0b8768f62d</th>\n",
              "      <th>ee2a7ce46e83e2de489c9f78f4e550156d57f484</th>\n",
              "      <th>606fc3f5664630412548bbd099f9c8ad1dc5acb6</th>\n",
              "      <th>40ab9973a268cc79a4a8210e67f9b912723ed8c3</th>\n",
              "      <th>c81b745f26735105787cf9e7b547a7c37a65a851</th>\n",
              "      <th>832743c77af1c7eb12fcd909c438dcf39b6008f3</th>\n",
              "      <th>7b42d018fdfe2ab118d8ec85bcf1d6983750750c</th>\n",
              "      <th>ef99ef623422c284a774e35fc1b1cf3e721dbd03</th>\n",
              "      <th>c1591135c00bca7a723a49df8c9d8de34326fbd3</th>\n",
              "      <th>3956907df9b51fae849a7afced246f127f259504</th>\n",
              "      <th>1359034ef247ed40bf5b3723915b9fc60cc74837</th>\n",
              "      <th>2a5b0895595bcf131a0b5c3e5dc4b9f39e06bd3f</th>\n",
              "      <th>ca7a7877b1dbad8f6ef696b1e88f34dc6f635b0d</th>\n",
              "      <th>396640532a81255d6b75b41e7a184c1393b74ee4</th>\n",
              "      <th>aebc6ae6f9dfe7b548779e39cc9fd03c60a67ecc</th>\n",
              "      <th>70e578e027d0ab0bfeb5959e18f3c8045a32236d</th>\n",
              "      <th>07ccdba1f0a266adf501c867319ac7007e65d290</th>\n",
              "      <th>d7b2ba98b972b65650af520075c9712a3d8994a7</th>\n",
              "      <th>2b844704051b64e47b4800e1d6e932bbdd5356b6</th>\n",
              "      <th>1c390c87d362e628cebc103eb247d2b7aa813542</th>\n",
              "      <th>6d70c76ca1d2e44f634d98810313c1c91b07ffa3</th>\n",
              "      <th>ec097c076cbcdbbcda43d0eb6372101151a914e0</th>\n",
              "      <th>eb61afa796d2ebdf9ec651593837743dc6c3ef11</th>\n",
              "      <th>e52f06cc2304cab39cfd6dd1f0918bad158e8764</th>\n",
              "      <th>6f3c758c55fe36ca540b2720d59a0da5c3553efc</th>\n",
              "      <th>...</th>\n",
              "      <th>46e35eba345a6366234c028567bbb91c99b872e5</th>\n",
              "      <th>298e1870fda64fe8018ec79e835cf308f81181fa</th>\n",
              "      <th>31b0561e7e9a03156b248da215d7ab7bf8d6d8c8</th>\n",
              "      <th>3ab6773bc6bce7fb154b3d46f6058f0192bfd01b</th>\n",
              "      <th>41d0c04a20a77e8daaba6c585f083ca0ef57affc</th>\n",
              "      <th>a3dfc65c01d171a671cd615236b79c61810de354</th>\n",
              "      <th>06028150b43acb7e11121888ab434cdd5f679f1d</th>\n",
              "      <th>f7853f850bbb98d20bb2b4dd6380c071b5a1cb02</th>\n",
              "      <th>078a75dfda9e932f608fca0837610b97d11d3dd7</th>\n",
              "      <th>fc8fd87104388e513937ac13696b6f72af2add53</th>\n",
              "      <th>422765063ea5b0e5667a240e3b802041ab93b6e3</th>\n",
              "      <th>6cfaf9601b6e2587a321d3b803c20f9eb05fd452</th>\n",
              "      <th>35c0ef8cb2af11a81092979d55c4324b8101332f</th>\n",
              "      <th>764cbb8b20a46c411fe5807df9867b92c0935c08</th>\n",
              "      <th>78209eb1032640dd8f611e310c8619ab2c9cb071</th>\n",
              "      <th>1fc19e52666a95169b365f5ad1352d9369cb045a</th>\n",
              "      <th>14d3489b6de7d970babc8a951bf6ed5bd289dea0</th>\n",
              "      <th>6646a9365ace5164d2ef3dfb39b88a8a924568d3</th>\n",
              "      <th>a7ac17ed71cc594bed820bfbbca833f3f9972592</th>\n",
              "      <th>976e778d614b1e8e9efa8bc7eeaf552b7fe5ccb5</th>\n",
              "      <th>5749b4541786aea857ff1552dfac8cf292044c29</th>\n",
              "      <th>b1f4814d1a8c7885960118015e2c8f47fcdd0f4f</th>\n",
              "      <th>75df7c8888ddbf148407aa76c3d6b72406bc4c27</th>\n",
              "      <th>fc88f6a4f0351f8a2b34d256fcda35579d9e0ead</th>\n",
              "      <th>21f079033442b71f1a870ca0988fa9afcc7dc810</th>\n",
              "      <th>3f8321ce0dd6348fa440eb25acae2be996c3b2e7</th>\n",
              "      <th>9054af7ed2ceb6b130b4fd2a09f36b9b1f611f11</th>\n",
              "      <th>77de2f0f3005949e35e2e2aef7af1ddc5d164695</th>\n",
              "      <th>588f35babb83fab68a9c539567140ba5c17284c7</th>\n",
              "      <th>68962923d8621f6868a762b2344ce1ab8209ecdd</th>\n",
              "      <th>7abbb83f5b877ce5c1c9e835422365cd8bac3b0d</th>\n",
              "      <th>acb4abc93968ad51368a0351fa7fda5401598069</th>\n",
              "      <th>f20fed9f248d4352def744d9a8262b49042ee7f3</th>\n",
              "      <th>437d45cd7c45b040b95abdb483b02d601c761d7d</th>\n",
              "      <th>b083b8279418c48d60a05cff039b0536339a1e4d</th>\n",
              "      <th>fa0d8c168b62f11f34fdf314d81cebdf1ca9ebd0</th>\n",
              "      <th>955eb46cfdee70adab1de9ce909f0cb059fd29d2</th>\n",
              "      <th>48d751207622a3606df95184fd58b32347057af3</th>\n",
              "      <th>5238e869a2d0d2a851ba1f9484c874c57419148e</th>\n",
              "      <th>63781517942f8b63c2189c376cc0cf3db1d27ed1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-87</td>\n",
              "      <td>-999</td>\n",
              "      <td>-78</td>\n",
              "      <td>-999</td>\n",
              "      <td>-91</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>...</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-80</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-76</td>\n",
              "      <td>-85</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-88</td>\n",
              "      <td>-70</td>\n",
              "      <td>-68</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-89</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-68</td>\n",
              "      <td>-999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-87</td>\n",
              "      <td>-999</td>\n",
              "      <td>-78</td>\n",
              "      <td>-999</td>\n",
              "      <td>-91</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>...</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-80</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-76</td>\n",
              "      <td>-85</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-88</td>\n",
              "      <td>-70</td>\n",
              "      <td>-68</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-89</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-68</td>\n",
              "      <td>-999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-87</td>\n",
              "      <td>-999</td>\n",
              "      <td>-80</td>\n",
              "      <td>-999</td>\n",
              "      <td>-91</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>...</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-80</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-76</td>\n",
              "      <td>-85</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-89</td>\n",
              "      <td>-70</td>\n",
              "      <td>-68</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-90</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-68</td>\n",
              "      <td>-999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-87</td>\n",
              "      <td>-999</td>\n",
              "      <td>-68</td>\n",
              "      <td>-999</td>\n",
              "      <td>-91</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>...</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-73</td>\n",
              "      <td>-91</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-89</td>\n",
              "      <td>-70</td>\n",
              "      <td>-68</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-89</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-89</td>\n",
              "      <td>-999</td>\n",
              "      <td>-71</td>\n",
              "      <td>-999</td>\n",
              "      <td>-87</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>...</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-73</td>\n",
              "      <td>-91</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-89</td>\n",
              "      <td>-70</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-91</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-999</td>\n",
              "      <td>-74</td>\n",
              "      <td>-999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 994 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       x  ...  63781517942f8b63c2189c376cc0cf3db1d27ed1\n",
              "0 -999.0  ...                                      -999\n",
              "1 -999.0  ...                                      -999\n",
              "2 -999.0  ...                                      -999\n",
              "3 -999.0  ...                                      -999\n",
              "4 -999.0  ...                                      -999\n",
              "\n",
              "[5 rows x 994 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "OJA2nDY8ulfl",
        "outputId": "97e41537-44cb-4889-f4f2-41b3f440da80"
      },
      "source": [
        "# Replace nan values to meaningful values and then standardscale\n",
        "\n",
        "# Add 100 to all columns so that it becomes 1-101 rather than -100-0\n",
        "train_df.iloc[:, 3:] = train_df.iloc[:, 3:] + 101\n",
        "test_df.iloc[:, 3:] = test_df.iloc[:, 3:] + 101\n",
        "\n",
        "# Replace -898 with zero so that it represents no signal\n",
        "for df in [train_df, test_df]:\n",
        "    all_cols = df.iloc[:, 3:].columns\n",
        "    for col in all_cols:\n",
        "        df[col] = np.where(df[col] == -898, 0, df[col])\n",
        "\n",
        "# Try without using scalers for now. \n",
        "# Apply MinMaxScaler to each IMU columns\n",
        "# current_cols = list(train_df.columns)\n",
        "# imu_cols = current_cols[:23]\n",
        "# exception_columns = [\"wps_diff\", \"x\", \"y\", \"floor_int\", \"rel_diff\", \"rel_x\", \"rel_y\"]\n",
        "# imu_cols = [x for x in imu_cols if x not in exception_columns]\n",
        "# print(\"imu_cols: \", imu_cols)\n",
        "ss_cols = train_df.iloc[:, 3:].columns\n",
        "for col in ss_cols:\n",
        "    ss_scaler = StandardScaler()\n",
        "    train_df[col] = ss_scaler.fit_transform(train_df[col].values.reshape(-1, 1))\n",
        "    test_df[col] = ss_scaler.transform(test_df[col].values.reshape(-1, 1))\n",
        "\n",
        "display(train_df.head())\n",
        "display(test_df.head())"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>floor_int</th>\n",
              "      <th>b1847b7279f12430b70cf177ae9419b2c6563c7e</th>\n",
              "      <th>e78f6a70bb684764884bf5bfc22876354dc4978f</th>\n",
              "      <th>7f92c838def910dc333d6ec1785cc9de7c428514</th>\n",
              "      <th>49baf7f0e5495ee2926baa0e941d265d725dbdd5</th>\n",
              "      <th>9419ecb5700d351a0ca4c6f6dc4f7804c5800ebe</th>\n",
              "      <th>6c598641414c17dfca87a3acc982507ba08902cb</th>\n",
              "      <th>bf8984bf3344f3267b1fb3cb5dc95ddf7e2117d3</th>\n",
              "      <th>24a2a9c3edd47eb479f05d4067368c9e14b8964b</th>\n",
              "      <th>2b3f7594cc8ab2b0413d45d6eea1149a9a7809a7</th>\n",
              "      <th>1cecf9fc6a1ceba0ad7063fdb5816ec43e90e94f</th>\n",
              "      <th>018a066872b67d5b33570ddeb6142c602a22e451</th>\n",
              "      <th>55ee0fec7b7be3e76132b20fca01e8486743a3f6</th>\n",
              "      <th>4f32282342971b17eb8611ac5f145d0b8768f62d</th>\n",
              "      <th>ee2a7ce46e83e2de489c9f78f4e550156d57f484</th>\n",
              "      <th>606fc3f5664630412548bbd099f9c8ad1dc5acb6</th>\n",
              "      <th>40ab9973a268cc79a4a8210e67f9b912723ed8c3</th>\n",
              "      <th>c81b745f26735105787cf9e7b547a7c37a65a851</th>\n",
              "      <th>832743c77af1c7eb12fcd909c438dcf39b6008f3</th>\n",
              "      <th>7b42d018fdfe2ab118d8ec85bcf1d6983750750c</th>\n",
              "      <th>ef99ef623422c284a774e35fc1b1cf3e721dbd03</th>\n",
              "      <th>c1591135c00bca7a723a49df8c9d8de34326fbd3</th>\n",
              "      <th>3956907df9b51fae849a7afced246f127f259504</th>\n",
              "      <th>1359034ef247ed40bf5b3723915b9fc60cc74837</th>\n",
              "      <th>2a5b0895595bcf131a0b5c3e5dc4b9f39e06bd3f</th>\n",
              "      <th>ca7a7877b1dbad8f6ef696b1e88f34dc6f635b0d</th>\n",
              "      <th>396640532a81255d6b75b41e7a184c1393b74ee4</th>\n",
              "      <th>aebc6ae6f9dfe7b548779e39cc9fd03c60a67ecc</th>\n",
              "      <th>70e578e027d0ab0bfeb5959e18f3c8045a32236d</th>\n",
              "      <th>07ccdba1f0a266adf501c867319ac7007e65d290</th>\n",
              "      <th>d7b2ba98b972b65650af520075c9712a3d8994a7</th>\n",
              "      <th>2b844704051b64e47b4800e1d6e932bbdd5356b6</th>\n",
              "      <th>1c390c87d362e628cebc103eb247d2b7aa813542</th>\n",
              "      <th>6d70c76ca1d2e44f634d98810313c1c91b07ffa3</th>\n",
              "      <th>ec097c076cbcdbbcda43d0eb6372101151a914e0</th>\n",
              "      <th>eb61afa796d2ebdf9ec651593837743dc6c3ef11</th>\n",
              "      <th>e52f06cc2304cab39cfd6dd1f0918bad158e8764</th>\n",
              "      <th>6f3c758c55fe36ca540b2720d59a0da5c3553efc</th>\n",
              "      <th>...</th>\n",
              "      <th>46e35eba345a6366234c028567bbb91c99b872e5</th>\n",
              "      <th>298e1870fda64fe8018ec79e835cf308f81181fa</th>\n",
              "      <th>31b0561e7e9a03156b248da215d7ab7bf8d6d8c8</th>\n",
              "      <th>3ab6773bc6bce7fb154b3d46f6058f0192bfd01b</th>\n",
              "      <th>41d0c04a20a77e8daaba6c585f083ca0ef57affc</th>\n",
              "      <th>a3dfc65c01d171a671cd615236b79c61810de354</th>\n",
              "      <th>06028150b43acb7e11121888ab434cdd5f679f1d</th>\n",
              "      <th>f7853f850bbb98d20bb2b4dd6380c071b5a1cb02</th>\n",
              "      <th>078a75dfda9e932f608fca0837610b97d11d3dd7</th>\n",
              "      <th>fc8fd87104388e513937ac13696b6f72af2add53</th>\n",
              "      <th>422765063ea5b0e5667a240e3b802041ab93b6e3</th>\n",
              "      <th>6cfaf9601b6e2587a321d3b803c20f9eb05fd452</th>\n",
              "      <th>35c0ef8cb2af11a81092979d55c4324b8101332f</th>\n",
              "      <th>764cbb8b20a46c411fe5807df9867b92c0935c08</th>\n",
              "      <th>78209eb1032640dd8f611e310c8619ab2c9cb071</th>\n",
              "      <th>1fc19e52666a95169b365f5ad1352d9369cb045a</th>\n",
              "      <th>14d3489b6de7d970babc8a951bf6ed5bd289dea0</th>\n",
              "      <th>6646a9365ace5164d2ef3dfb39b88a8a924568d3</th>\n",
              "      <th>a7ac17ed71cc594bed820bfbbca833f3f9972592</th>\n",
              "      <th>976e778d614b1e8e9efa8bc7eeaf552b7fe5ccb5</th>\n",
              "      <th>5749b4541786aea857ff1552dfac8cf292044c29</th>\n",
              "      <th>b1f4814d1a8c7885960118015e2c8f47fcdd0f4f</th>\n",
              "      <th>75df7c8888ddbf148407aa76c3d6b72406bc4c27</th>\n",
              "      <th>fc88f6a4f0351f8a2b34d256fcda35579d9e0ead</th>\n",
              "      <th>21f079033442b71f1a870ca0988fa9afcc7dc810</th>\n",
              "      <th>3f8321ce0dd6348fa440eb25acae2be996c3b2e7</th>\n",
              "      <th>9054af7ed2ceb6b130b4fd2a09f36b9b1f611f11</th>\n",
              "      <th>77de2f0f3005949e35e2e2aef7af1ddc5d164695</th>\n",
              "      <th>588f35babb83fab68a9c539567140ba5c17284c7</th>\n",
              "      <th>68962923d8621f6868a762b2344ce1ab8209ecdd</th>\n",
              "      <th>7abbb83f5b877ce5c1c9e835422365cd8bac3b0d</th>\n",
              "      <th>acb4abc93968ad51368a0351fa7fda5401598069</th>\n",
              "      <th>f20fed9f248d4352def744d9a8262b49042ee7f3</th>\n",
              "      <th>437d45cd7c45b040b95abdb483b02d601c761d7d</th>\n",
              "      <th>b083b8279418c48d60a05cff039b0536339a1e4d</th>\n",
              "      <th>fa0d8c168b62f11f34fdf314d81cebdf1ca9ebd0</th>\n",
              "      <th>955eb46cfdee70adab1de9ce909f0cb059fd29d2</th>\n",
              "      <th>48d751207622a3606df95184fd58b32347057af3</th>\n",
              "      <th>5238e869a2d0d2a851ba1f9484c874c57419148e</th>\n",
              "      <th>63781517942f8b63c2189c376cc0cf3db1d27ed1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>88.03561</td>\n",
              "      <td>109.90122</td>\n",
              "      <td>-1</td>\n",
              "      <td>1.022882</td>\n",
              "      <td>1.184672</td>\n",
              "      <td>1.014350</td>\n",
              "      <td>-0.899621</td>\n",
              "      <td>1.065079</td>\n",
              "      <td>0.281054</td>\n",
              "      <td>1.005324</td>\n",
              "      <td>-0.674036</td>\n",
              "      <td>3.526606</td>\n",
              "      <td>-0.644065</td>\n",
              "      <td>1.652452</td>\n",
              "      <td>0.563508</td>\n",
              "      <td>-0.633201</td>\n",
              "      <td>-0.653905</td>\n",
              "      <td>-0.643668</td>\n",
              "      <td>3.935694</td>\n",
              "      <td>1.463049</td>\n",
              "      <td>0.937734</td>\n",
              "      <td>0.882479</td>\n",
              "      <td>-0.624773</td>\n",
              "      <td>1.642440</td>\n",
              "      <td>-0.626779</td>\n",
              "      <td>-0.600276</td>\n",
              "      <td>-0.568125</td>\n",
              "      <td>1.197258</td>\n",
              "      <td>-0.576967</td>\n",
              "      <td>-0.590335</td>\n",
              "      <td>-0.547794</td>\n",
              "      <td>-0.570899</td>\n",
              "      <td>-0.597481</td>\n",
              "      <td>-0.5961</td>\n",
              "      <td>1.716186</td>\n",
              "      <td>-0.564996</td>\n",
              "      <td>-0.572969</td>\n",
              "      <td>-0.555294</td>\n",
              "      <td>-0.577879</td>\n",
              "      <td>-0.583952</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.118862</td>\n",
              "      <td>-0.121666</td>\n",
              "      <td>-0.120341</td>\n",
              "      <td>-0.118334</td>\n",
              "      <td>-0.119345</td>\n",
              "      <td>-0.119231</td>\n",
              "      <td>-0.12043</td>\n",
              "      <td>-0.119883</td>\n",
              "      <td>-0.11911</td>\n",
              "      <td>-0.120531</td>\n",
              "      <td>-0.118977</td>\n",
              "      <td>-0.116515</td>\n",
              "      <td>-0.118411</td>\n",
              "      <td>-0.118145</td>\n",
              "      <td>-0.117152</td>\n",
              "      <td>-0.117642</td>\n",
              "      <td>-0.116978</td>\n",
              "      <td>-0.117779</td>\n",
              "      <td>-0.117048</td>\n",
              "      <td>-0.117863</td>\n",
              "      <td>-0.11337</td>\n",
              "      <td>-0.116881</td>\n",
              "      <td>-0.114437</td>\n",
              "      <td>-0.115313</td>\n",
              "      <td>-0.112192</td>\n",
              "      <td>-0.114322</td>\n",
              "      <td>-0.115178</td>\n",
              "      <td>-0.114371</td>\n",
              "      <td>-0.113408</td>\n",
              "      <td>-0.115074</td>\n",
              "      <td>-0.11419</td>\n",
              "      <td>-0.113179</td>\n",
              "      <td>-0.113412</td>\n",
              "      <td>-0.113032</td>\n",
              "      <td>-0.112219</td>\n",
              "      <td>-0.114332</td>\n",
              "      <td>-0.114511</td>\n",
              "      <td>-0.113153</td>\n",
              "      <td>-0.110336</td>\n",
              "      <td>-0.112768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>88.03561</td>\n",
              "      <td>109.90122</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.771825</td>\n",
              "      <td>0.767445</td>\n",
              "      <td>0.430535</td>\n",
              "      <td>-0.899621</td>\n",
              "      <td>1.065079</td>\n",
              "      <td>0.281054</td>\n",
              "      <td>1.005324</td>\n",
              "      <td>-0.674036</td>\n",
              "      <td>3.928013</td>\n",
              "      <td>0.466885</td>\n",
              "      <td>1.240088</td>\n",
              "      <td>0.563508</td>\n",
              "      <td>-0.633201</td>\n",
              "      <td>-0.653905</td>\n",
              "      <td>-0.643668</td>\n",
              "      <td>2.865722</td>\n",
              "      <td>1.463049</td>\n",
              "      <td>0.937734</td>\n",
              "      <td>0.453276</td>\n",
              "      <td>-0.624773</td>\n",
              "      <td>1.642440</td>\n",
              "      <td>-0.626779</td>\n",
              "      <td>-0.600276</td>\n",
              "      <td>-0.568125</td>\n",
              "      <td>1.197258</td>\n",
              "      <td>-0.576967</td>\n",
              "      <td>-0.590335</td>\n",
              "      <td>-0.547794</td>\n",
              "      <td>-0.570899</td>\n",
              "      <td>-0.597481</td>\n",
              "      <td>-0.5961</td>\n",
              "      <td>1.716186</td>\n",
              "      <td>-0.564996</td>\n",
              "      <td>-0.572969</td>\n",
              "      <td>-0.555294</td>\n",
              "      <td>-0.577879</td>\n",
              "      <td>-0.583952</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.118862</td>\n",
              "      <td>-0.121666</td>\n",
              "      <td>-0.120341</td>\n",
              "      <td>-0.118334</td>\n",
              "      <td>-0.119345</td>\n",
              "      <td>-0.119231</td>\n",
              "      <td>-0.12043</td>\n",
              "      <td>-0.119883</td>\n",
              "      <td>-0.11911</td>\n",
              "      <td>-0.120531</td>\n",
              "      <td>-0.118977</td>\n",
              "      <td>-0.116515</td>\n",
              "      <td>-0.118411</td>\n",
              "      <td>-0.118145</td>\n",
              "      <td>-0.117152</td>\n",
              "      <td>-0.117642</td>\n",
              "      <td>-0.116978</td>\n",
              "      <td>-0.117779</td>\n",
              "      <td>-0.117048</td>\n",
              "      <td>-0.117863</td>\n",
              "      <td>-0.11337</td>\n",
              "      <td>-0.116881</td>\n",
              "      <td>-0.114437</td>\n",
              "      <td>-0.115313</td>\n",
              "      <td>-0.112192</td>\n",
              "      <td>-0.114322</td>\n",
              "      <td>-0.115178</td>\n",
              "      <td>-0.114371</td>\n",
              "      <td>-0.113408</td>\n",
              "      <td>-0.115074</td>\n",
              "      <td>-0.11419</td>\n",
              "      <td>-0.113179</td>\n",
              "      <td>-0.113412</td>\n",
              "      <td>-0.113032</td>\n",
              "      <td>-0.112219</td>\n",
              "      <td>-0.114332</td>\n",
              "      <td>-0.114511</td>\n",
              "      <td>-0.113153</td>\n",
              "      <td>-0.110336</td>\n",
              "      <td>-0.112768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>91.62208</td>\n",
              "      <td>108.70687</td>\n",
              "      <td>-1</td>\n",
              "      <td>1.692367</td>\n",
              "      <td>1.768790</td>\n",
              "      <td>1.764970</td>\n",
              "      <td>0.916465</td>\n",
              "      <td>1.065079</td>\n",
              "      <td>0.281054</td>\n",
              "      <td>0.934167</td>\n",
              "      <td>0.592916</td>\n",
              "      <td>3.767450</td>\n",
              "      <td>0.466885</td>\n",
              "      <td>1.240088</td>\n",
              "      <td>0.563508</td>\n",
              "      <td>-0.633201</td>\n",
              "      <td>-0.653905</td>\n",
              "      <td>-0.643668</td>\n",
              "      <td>3.771083</td>\n",
              "      <td>1.463049</td>\n",
              "      <td>0.937734</td>\n",
              "      <td>0.453276</td>\n",
              "      <td>-0.624773</td>\n",
              "      <td>1.642440</td>\n",
              "      <td>-0.626779</td>\n",
              "      <td>-0.600276</td>\n",
              "      <td>-0.568125</td>\n",
              "      <td>1.197258</td>\n",
              "      <td>-0.576967</td>\n",
              "      <td>-0.590335</td>\n",
              "      <td>-0.547794</td>\n",
              "      <td>-0.570899</td>\n",
              "      <td>-0.597481</td>\n",
              "      <td>-0.5961</td>\n",
              "      <td>1.716186</td>\n",
              "      <td>-0.564996</td>\n",
              "      <td>-0.572969</td>\n",
              "      <td>-0.555294</td>\n",
              "      <td>-0.577879</td>\n",
              "      <td>-0.583952</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.118862</td>\n",
              "      <td>-0.121666</td>\n",
              "      <td>-0.120341</td>\n",
              "      <td>-0.118334</td>\n",
              "      <td>-0.119345</td>\n",
              "      <td>-0.119231</td>\n",
              "      <td>-0.12043</td>\n",
              "      <td>-0.119883</td>\n",
              "      <td>-0.11911</td>\n",
              "      <td>-0.120531</td>\n",
              "      <td>-0.118977</td>\n",
              "      <td>-0.116515</td>\n",
              "      <td>-0.118411</td>\n",
              "      <td>-0.118145</td>\n",
              "      <td>-0.117152</td>\n",
              "      <td>-0.117642</td>\n",
              "      <td>-0.116978</td>\n",
              "      <td>-0.117779</td>\n",
              "      <td>-0.117048</td>\n",
              "      <td>-0.117863</td>\n",
              "      <td>-0.11337</td>\n",
              "      <td>-0.116881</td>\n",
              "      <td>-0.114437</td>\n",
              "      <td>-0.115313</td>\n",
              "      <td>-0.112192</td>\n",
              "      <td>-0.114322</td>\n",
              "      <td>-0.115178</td>\n",
              "      <td>-0.114371</td>\n",
              "      <td>-0.113408</td>\n",
              "      <td>-0.115074</td>\n",
              "      <td>-0.11419</td>\n",
              "      <td>-0.113179</td>\n",
              "      <td>-0.113412</td>\n",
              "      <td>-0.113032</td>\n",
              "      <td>-0.112219</td>\n",
              "      <td>-0.114332</td>\n",
              "      <td>-0.114511</td>\n",
              "      <td>-0.113153</td>\n",
              "      <td>-0.110336</td>\n",
              "      <td>-0.112768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>91.62208</td>\n",
              "      <td>108.70687</td>\n",
              "      <td>-1</td>\n",
              "      <td>1.273939</td>\n",
              "      <td>1.268117</td>\n",
              "      <td>0.930948</td>\n",
              "      <td>0.916465</td>\n",
              "      <td>1.065079</td>\n",
              "      <td>0.281054</td>\n",
              "      <td>1.218795</td>\n",
              "      <td>0.117809</td>\n",
              "      <td>3.044918</td>\n",
              "      <td>0.808716</td>\n",
              "      <td>1.322560</td>\n",
              "      <td>0.563508</td>\n",
              "      <td>-0.633201</td>\n",
              "      <td>-0.653905</td>\n",
              "      <td>-0.643668</td>\n",
              "      <td>4.264916</td>\n",
              "      <td>1.463049</td>\n",
              "      <td>0.937734</td>\n",
              "      <td>0.453276</td>\n",
              "      <td>-0.624773</td>\n",
              "      <td>1.642440</td>\n",
              "      <td>-0.626779</td>\n",
              "      <td>-0.600276</td>\n",
              "      <td>-0.568125</td>\n",
              "      <td>1.197258</td>\n",
              "      <td>-0.576967</td>\n",
              "      <td>-0.590335</td>\n",
              "      <td>-0.547794</td>\n",
              "      <td>-0.570899</td>\n",
              "      <td>-0.597481</td>\n",
              "      <td>-0.5961</td>\n",
              "      <td>1.392628</td>\n",
              "      <td>-0.564996</td>\n",
              "      <td>-0.572969</td>\n",
              "      <td>-0.555294</td>\n",
              "      <td>-0.577879</td>\n",
              "      <td>-0.583952</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.118862</td>\n",
              "      <td>-0.121666</td>\n",
              "      <td>-0.120341</td>\n",
              "      <td>-0.118334</td>\n",
              "      <td>-0.119345</td>\n",
              "      <td>-0.119231</td>\n",
              "      <td>-0.12043</td>\n",
              "      <td>-0.119883</td>\n",
              "      <td>-0.11911</td>\n",
              "      <td>-0.120531</td>\n",
              "      <td>-0.118977</td>\n",
              "      <td>-0.116515</td>\n",
              "      <td>-0.118411</td>\n",
              "      <td>-0.118145</td>\n",
              "      <td>-0.117152</td>\n",
              "      <td>-0.117642</td>\n",
              "      <td>-0.116978</td>\n",
              "      <td>-0.117779</td>\n",
              "      <td>-0.117048</td>\n",
              "      <td>-0.117863</td>\n",
              "      <td>-0.11337</td>\n",
              "      <td>-0.116881</td>\n",
              "      <td>-0.114437</td>\n",
              "      <td>-0.115313</td>\n",
              "      <td>-0.112192</td>\n",
              "      <td>-0.114322</td>\n",
              "      <td>-0.115178</td>\n",
              "      <td>-0.114371</td>\n",
              "      <td>-0.113408</td>\n",
              "      <td>-0.115074</td>\n",
              "      <td>-0.11419</td>\n",
              "      <td>-0.113179</td>\n",
              "      <td>-0.113412</td>\n",
              "      <td>-0.113032</td>\n",
              "      <td>-0.112219</td>\n",
              "      <td>-0.114332</td>\n",
              "      <td>-0.114511</td>\n",
              "      <td>-0.113153</td>\n",
              "      <td>-0.110336</td>\n",
              "      <td>-0.112768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>91.62208</td>\n",
              "      <td>108.70687</td>\n",
              "      <td>-1</td>\n",
              "      <td>1.357624</td>\n",
              "      <td>1.435008</td>\n",
              "      <td>1.514763</td>\n",
              "      <td>0.916465</td>\n",
              "      <td>1.065079</td>\n",
              "      <td>1.366072</td>\n",
              "      <td>0.720696</td>\n",
              "      <td>0.117809</td>\n",
              "      <td>3.606888</td>\n",
              "      <td>0.808716</td>\n",
              "      <td>1.322560</td>\n",
              "      <td>1.331164</td>\n",
              "      <td>1.476360</td>\n",
              "      <td>-0.653905</td>\n",
              "      <td>-0.643668</td>\n",
              "      <td>3.853388</td>\n",
              "      <td>1.463049</td>\n",
              "      <td>0.937734</td>\n",
              "      <td>0.453276</td>\n",
              "      <td>-0.624773</td>\n",
              "      <td>1.553499</td>\n",
              "      <td>-0.626779</td>\n",
              "      <td>-0.600276</td>\n",
              "      <td>0.839807</td>\n",
              "      <td>1.197258</td>\n",
              "      <td>-0.576967</td>\n",
              "      <td>-0.590335</td>\n",
              "      <td>-0.547794</td>\n",
              "      <td>-0.570899</td>\n",
              "      <td>-0.597481</td>\n",
              "      <td>-0.5961</td>\n",
              "      <td>0.745513</td>\n",
              "      <td>-0.564996</td>\n",
              "      <td>-0.572969</td>\n",
              "      <td>-0.555294</td>\n",
              "      <td>-0.577879</td>\n",
              "      <td>-0.583952</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.118862</td>\n",
              "      <td>-0.121666</td>\n",
              "      <td>-0.120341</td>\n",
              "      <td>-0.118334</td>\n",
              "      <td>-0.119345</td>\n",
              "      <td>-0.119231</td>\n",
              "      <td>-0.12043</td>\n",
              "      <td>-0.119883</td>\n",
              "      <td>-0.11911</td>\n",
              "      <td>-0.120531</td>\n",
              "      <td>-0.118977</td>\n",
              "      <td>-0.116515</td>\n",
              "      <td>-0.118411</td>\n",
              "      <td>-0.118145</td>\n",
              "      <td>-0.117152</td>\n",
              "      <td>-0.117642</td>\n",
              "      <td>-0.116978</td>\n",
              "      <td>-0.117779</td>\n",
              "      <td>-0.117048</td>\n",
              "      <td>-0.117863</td>\n",
              "      <td>-0.11337</td>\n",
              "      <td>-0.116881</td>\n",
              "      <td>-0.114437</td>\n",
              "      <td>-0.115313</td>\n",
              "      <td>-0.112192</td>\n",
              "      <td>-0.114322</td>\n",
              "      <td>-0.115178</td>\n",
              "      <td>-0.114371</td>\n",
              "      <td>-0.113408</td>\n",
              "      <td>-0.115074</td>\n",
              "      <td>-0.11419</td>\n",
              "      <td>-0.113179</td>\n",
              "      <td>-0.113412</td>\n",
              "      <td>-0.113032</td>\n",
              "      <td>-0.112219</td>\n",
              "      <td>-0.114332</td>\n",
              "      <td>-0.114511</td>\n",
              "      <td>-0.113153</td>\n",
              "      <td>-0.110336</td>\n",
              "      <td>-0.112768</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 994 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          x  ...  63781517942f8b63c2189c376cc0cf3db1d27ed1\n",
              "0  88.03561  ...                                 -0.112768\n",
              "1  88.03561  ...                                 -0.112768\n",
              "2  91.62208  ...                                 -0.112768\n",
              "3  91.62208  ...                                 -0.112768\n",
              "4  91.62208  ...                                 -0.112768\n",
              "\n",
              "[5 rows x 994 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>floor_int</th>\n",
              "      <th>b1847b7279f12430b70cf177ae9419b2c6563c7e</th>\n",
              "      <th>e78f6a70bb684764884bf5bfc22876354dc4978f</th>\n",
              "      <th>7f92c838def910dc333d6ec1785cc9de7c428514</th>\n",
              "      <th>49baf7f0e5495ee2926baa0e941d265d725dbdd5</th>\n",
              "      <th>9419ecb5700d351a0ca4c6f6dc4f7804c5800ebe</th>\n",
              "      <th>6c598641414c17dfca87a3acc982507ba08902cb</th>\n",
              "      <th>bf8984bf3344f3267b1fb3cb5dc95ddf7e2117d3</th>\n",
              "      <th>24a2a9c3edd47eb479f05d4067368c9e14b8964b</th>\n",
              "      <th>2b3f7594cc8ab2b0413d45d6eea1149a9a7809a7</th>\n",
              "      <th>1cecf9fc6a1ceba0ad7063fdb5816ec43e90e94f</th>\n",
              "      <th>018a066872b67d5b33570ddeb6142c602a22e451</th>\n",
              "      <th>55ee0fec7b7be3e76132b20fca01e8486743a3f6</th>\n",
              "      <th>4f32282342971b17eb8611ac5f145d0b8768f62d</th>\n",
              "      <th>ee2a7ce46e83e2de489c9f78f4e550156d57f484</th>\n",
              "      <th>606fc3f5664630412548bbd099f9c8ad1dc5acb6</th>\n",
              "      <th>40ab9973a268cc79a4a8210e67f9b912723ed8c3</th>\n",
              "      <th>c81b745f26735105787cf9e7b547a7c37a65a851</th>\n",
              "      <th>832743c77af1c7eb12fcd909c438dcf39b6008f3</th>\n",
              "      <th>7b42d018fdfe2ab118d8ec85bcf1d6983750750c</th>\n",
              "      <th>ef99ef623422c284a774e35fc1b1cf3e721dbd03</th>\n",
              "      <th>c1591135c00bca7a723a49df8c9d8de34326fbd3</th>\n",
              "      <th>3956907df9b51fae849a7afced246f127f259504</th>\n",
              "      <th>1359034ef247ed40bf5b3723915b9fc60cc74837</th>\n",
              "      <th>2a5b0895595bcf131a0b5c3e5dc4b9f39e06bd3f</th>\n",
              "      <th>ca7a7877b1dbad8f6ef696b1e88f34dc6f635b0d</th>\n",
              "      <th>396640532a81255d6b75b41e7a184c1393b74ee4</th>\n",
              "      <th>aebc6ae6f9dfe7b548779e39cc9fd03c60a67ecc</th>\n",
              "      <th>70e578e027d0ab0bfeb5959e18f3c8045a32236d</th>\n",
              "      <th>07ccdba1f0a266adf501c867319ac7007e65d290</th>\n",
              "      <th>d7b2ba98b972b65650af520075c9712a3d8994a7</th>\n",
              "      <th>2b844704051b64e47b4800e1d6e932bbdd5356b6</th>\n",
              "      <th>1c390c87d362e628cebc103eb247d2b7aa813542</th>\n",
              "      <th>6d70c76ca1d2e44f634d98810313c1c91b07ffa3</th>\n",
              "      <th>ec097c076cbcdbbcda43d0eb6372101151a914e0</th>\n",
              "      <th>eb61afa796d2ebdf9ec651593837743dc6c3ef11</th>\n",
              "      <th>e52f06cc2304cab39cfd6dd1f0918bad158e8764</th>\n",
              "      <th>6f3c758c55fe36ca540b2720d59a0da5c3553efc</th>\n",
              "      <th>...</th>\n",
              "      <th>46e35eba345a6366234c028567bbb91c99b872e5</th>\n",
              "      <th>298e1870fda64fe8018ec79e835cf308f81181fa</th>\n",
              "      <th>31b0561e7e9a03156b248da215d7ab7bf8d6d8c8</th>\n",
              "      <th>3ab6773bc6bce7fb154b3d46f6058f0192bfd01b</th>\n",
              "      <th>41d0c04a20a77e8daaba6c585f083ca0ef57affc</th>\n",
              "      <th>a3dfc65c01d171a671cd615236b79c61810de354</th>\n",
              "      <th>06028150b43acb7e11121888ab434cdd5f679f1d</th>\n",
              "      <th>f7853f850bbb98d20bb2b4dd6380c071b5a1cb02</th>\n",
              "      <th>078a75dfda9e932f608fca0837610b97d11d3dd7</th>\n",
              "      <th>fc8fd87104388e513937ac13696b6f72af2add53</th>\n",
              "      <th>422765063ea5b0e5667a240e3b802041ab93b6e3</th>\n",
              "      <th>6cfaf9601b6e2587a321d3b803c20f9eb05fd452</th>\n",
              "      <th>35c0ef8cb2af11a81092979d55c4324b8101332f</th>\n",
              "      <th>764cbb8b20a46c411fe5807df9867b92c0935c08</th>\n",
              "      <th>78209eb1032640dd8f611e310c8619ab2c9cb071</th>\n",
              "      <th>1fc19e52666a95169b365f5ad1352d9369cb045a</th>\n",
              "      <th>14d3489b6de7d970babc8a951bf6ed5bd289dea0</th>\n",
              "      <th>6646a9365ace5164d2ef3dfb39b88a8a924568d3</th>\n",
              "      <th>a7ac17ed71cc594bed820bfbbca833f3f9972592</th>\n",
              "      <th>976e778d614b1e8e9efa8bc7eeaf552b7fe5ccb5</th>\n",
              "      <th>5749b4541786aea857ff1552dfac8cf292044c29</th>\n",
              "      <th>b1f4814d1a8c7885960118015e2c8f47fcdd0f4f</th>\n",
              "      <th>75df7c8888ddbf148407aa76c3d6b72406bc4c27</th>\n",
              "      <th>fc88f6a4f0351f8a2b34d256fcda35579d9e0ead</th>\n",
              "      <th>21f079033442b71f1a870ca0988fa9afcc7dc810</th>\n",
              "      <th>3f8321ce0dd6348fa440eb25acae2be996c3b2e7</th>\n",
              "      <th>9054af7ed2ceb6b130b4fd2a09f36b9b1f611f11</th>\n",
              "      <th>77de2f0f3005949e35e2e2aef7af1ddc5d164695</th>\n",
              "      <th>588f35babb83fab68a9c539567140ba5c17284c7</th>\n",
              "      <th>68962923d8621f6868a762b2344ce1ab8209ecdd</th>\n",
              "      <th>7abbb83f5b877ce5c1c9e835422365cd8bac3b0d</th>\n",
              "      <th>acb4abc93968ad51368a0351fa7fda5401598069</th>\n",
              "      <th>f20fed9f248d4352def744d9a8262b49042ee7f3</th>\n",
              "      <th>437d45cd7c45b040b95abdb483b02d601c761d7d</th>\n",
              "      <th>b083b8279418c48d60a05cff039b0536339a1e4d</th>\n",
              "      <th>fa0d8c168b62f11f34fdf314d81cebdf1ca9ebd0</th>\n",
              "      <th>955eb46cfdee70adab1de9ce909f0cb059fd29d2</th>\n",
              "      <th>48d751207622a3606df95184fd58b32347057af3</th>\n",
              "      <th>5238e869a2d0d2a851ba1f9484c874c57419148e</th>\n",
              "      <th>63781517942f8b63c2189c376cc0cf3db1d27ed1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-1.069261</td>\n",
              "      <td>-1.068354</td>\n",
              "      <td>-1.070703</td>\n",
              "      <td>0.205823</td>\n",
              "      <td>-0.809806</td>\n",
              "      <td>1.199146</td>\n",
              "      <td>-0.702444</td>\n",
              "      <td>0.117809</td>\n",
              "      <td>-0.648023</td>\n",
              "      <td>-0.644065</td>\n",
              "      <td>-0.656789</td>\n",
              "      <td>-0.630624</td>\n",
              "      <td>-0.633201</td>\n",
              "      <td>-0.653905</td>\n",
              "      <td>-0.643668</td>\n",
              "      <td>-0.591111</td>\n",
              "      <td>-0.622907</td>\n",
              "      <td>-0.608863</td>\n",
              "      <td>-0.576811</td>\n",
              "      <td>-0.624773</td>\n",
              "      <td>-0.581083</td>\n",
              "      <td>-0.626779</td>\n",
              "      <td>-0.600276</td>\n",
              "      <td>-0.568125</td>\n",
              "      <td>-0.573546</td>\n",
              "      <td>-0.576967</td>\n",
              "      <td>-0.590335</td>\n",
              "      <td>-0.547794</td>\n",
              "      <td>-0.570899</td>\n",
              "      <td>-0.597481</td>\n",
              "      <td>-0.5961</td>\n",
              "      <td>-0.548717</td>\n",
              "      <td>-0.564996</td>\n",
              "      <td>-0.572969</td>\n",
              "      <td>-0.555294</td>\n",
              "      <td>-0.577879</td>\n",
              "      <td>-0.583952</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.118862</td>\n",
              "      <td>-0.121666</td>\n",
              "      <td>-0.120341</td>\n",
              "      <td>-0.118334</td>\n",
              "      <td>-0.119345</td>\n",
              "      <td>-0.119231</td>\n",
              "      <td>-0.12043</td>\n",
              "      <td>6.851501</td>\n",
              "      <td>-0.11911</td>\n",
              "      <td>-0.120531</td>\n",
              "      <td>-0.118977</td>\n",
              "      <td>7.380220</td>\n",
              "      <td>7.876908</td>\n",
              "      <td>-0.118145</td>\n",
              "      <td>-0.117152</td>\n",
              "      <td>-0.117642</td>\n",
              "      <td>-0.116978</td>\n",
              "      <td>-0.117779</td>\n",
              "      <td>-0.117048</td>\n",
              "      <td>-0.117863</td>\n",
              "      <td>-0.11337</td>\n",
              "      <td>-0.116881</td>\n",
              "      <td>-0.114437</td>\n",
              "      <td>-0.115313</td>\n",
              "      <td>-0.112192</td>\n",
              "      <td>-0.114322</td>\n",
              "      <td>-0.115178</td>\n",
              "      <td>-0.114371</td>\n",
              "      <td>-0.113408</td>\n",
              "      <td>8.545438</td>\n",
              "      <td>8.917473</td>\n",
              "      <td>10.805117</td>\n",
              "      <td>-0.113412</td>\n",
              "      <td>-0.113032</td>\n",
              "      <td>7.697278</td>\n",
              "      <td>-0.114332</td>\n",
              "      <td>-0.114511</td>\n",
              "      <td>-0.113153</td>\n",
              "      <td>11.206805</td>\n",
              "      <td>-0.112768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-1.069261</td>\n",
              "      <td>-1.068354</td>\n",
              "      <td>-1.070703</td>\n",
              "      <td>0.205823</td>\n",
              "      <td>-0.809806</td>\n",
              "      <td>1.199146</td>\n",
              "      <td>-0.702444</td>\n",
              "      <td>0.117809</td>\n",
              "      <td>-0.648023</td>\n",
              "      <td>-0.644065</td>\n",
              "      <td>-0.656789</td>\n",
              "      <td>-0.630624</td>\n",
              "      <td>-0.633201</td>\n",
              "      <td>-0.653905</td>\n",
              "      <td>-0.643668</td>\n",
              "      <td>-0.591111</td>\n",
              "      <td>-0.622907</td>\n",
              "      <td>-0.608863</td>\n",
              "      <td>-0.576811</td>\n",
              "      <td>-0.624773</td>\n",
              "      <td>-0.581083</td>\n",
              "      <td>-0.626779</td>\n",
              "      <td>-0.600276</td>\n",
              "      <td>-0.568125</td>\n",
              "      <td>-0.573546</td>\n",
              "      <td>-0.576967</td>\n",
              "      <td>-0.590335</td>\n",
              "      <td>-0.547794</td>\n",
              "      <td>-0.570899</td>\n",
              "      <td>-0.597481</td>\n",
              "      <td>-0.5961</td>\n",
              "      <td>-0.548717</td>\n",
              "      <td>-0.564996</td>\n",
              "      <td>-0.572969</td>\n",
              "      <td>-0.555294</td>\n",
              "      <td>-0.577879</td>\n",
              "      <td>-0.583952</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.118862</td>\n",
              "      <td>-0.121666</td>\n",
              "      <td>-0.120341</td>\n",
              "      <td>-0.118334</td>\n",
              "      <td>-0.119345</td>\n",
              "      <td>-0.119231</td>\n",
              "      <td>-0.12043</td>\n",
              "      <td>6.851501</td>\n",
              "      <td>-0.11911</td>\n",
              "      <td>-0.120531</td>\n",
              "      <td>-0.118977</td>\n",
              "      <td>7.380220</td>\n",
              "      <td>7.876908</td>\n",
              "      <td>-0.118145</td>\n",
              "      <td>-0.117152</td>\n",
              "      <td>-0.117642</td>\n",
              "      <td>-0.116978</td>\n",
              "      <td>-0.117779</td>\n",
              "      <td>-0.117048</td>\n",
              "      <td>-0.117863</td>\n",
              "      <td>-0.11337</td>\n",
              "      <td>-0.116881</td>\n",
              "      <td>-0.114437</td>\n",
              "      <td>-0.115313</td>\n",
              "      <td>-0.112192</td>\n",
              "      <td>-0.114322</td>\n",
              "      <td>-0.115178</td>\n",
              "      <td>-0.114371</td>\n",
              "      <td>-0.113408</td>\n",
              "      <td>8.545438</td>\n",
              "      <td>8.917473</td>\n",
              "      <td>10.805117</td>\n",
              "      <td>-0.113412</td>\n",
              "      <td>-0.113032</td>\n",
              "      <td>7.697278</td>\n",
              "      <td>-0.114332</td>\n",
              "      <td>-0.114511</td>\n",
              "      <td>-0.113153</td>\n",
              "      <td>11.206805</td>\n",
              "      <td>-0.112768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-1.069261</td>\n",
              "      <td>-1.068354</td>\n",
              "      <td>-1.070703</td>\n",
              "      <td>0.205823</td>\n",
              "      <td>-0.809806</td>\n",
              "      <td>1.032220</td>\n",
              "      <td>-0.702444</td>\n",
              "      <td>0.117809</td>\n",
              "      <td>-0.648023</td>\n",
              "      <td>-0.644065</td>\n",
              "      <td>-0.656789</td>\n",
              "      <td>-0.630624</td>\n",
              "      <td>-0.633201</td>\n",
              "      <td>-0.653905</td>\n",
              "      <td>-0.643668</td>\n",
              "      <td>-0.591111</td>\n",
              "      <td>-0.622907</td>\n",
              "      <td>-0.608863</td>\n",
              "      <td>-0.576811</td>\n",
              "      <td>-0.624773</td>\n",
              "      <td>-0.581083</td>\n",
              "      <td>-0.626779</td>\n",
              "      <td>-0.600276</td>\n",
              "      <td>-0.568125</td>\n",
              "      <td>-0.573546</td>\n",
              "      <td>-0.576967</td>\n",
              "      <td>-0.590335</td>\n",
              "      <td>-0.547794</td>\n",
              "      <td>-0.570899</td>\n",
              "      <td>-0.597481</td>\n",
              "      <td>-0.5961</td>\n",
              "      <td>-0.548717</td>\n",
              "      <td>-0.564996</td>\n",
              "      <td>-0.572969</td>\n",
              "      <td>-0.555294</td>\n",
              "      <td>-0.577879</td>\n",
              "      <td>-0.583952</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.118862</td>\n",
              "      <td>-0.121666</td>\n",
              "      <td>-0.120341</td>\n",
              "      <td>-0.118334</td>\n",
              "      <td>-0.119345</td>\n",
              "      <td>-0.119231</td>\n",
              "      <td>-0.12043</td>\n",
              "      <td>6.851501</td>\n",
              "      <td>-0.11911</td>\n",
              "      <td>-0.120531</td>\n",
              "      <td>-0.118977</td>\n",
              "      <td>7.380220</td>\n",
              "      <td>7.876908</td>\n",
              "      <td>-0.118145</td>\n",
              "      <td>-0.117152</td>\n",
              "      <td>-0.117642</td>\n",
              "      <td>-0.116978</td>\n",
              "      <td>-0.117779</td>\n",
              "      <td>-0.117048</td>\n",
              "      <td>-0.117863</td>\n",
              "      <td>-0.11337</td>\n",
              "      <td>-0.116881</td>\n",
              "      <td>-0.114437</td>\n",
              "      <td>-0.115313</td>\n",
              "      <td>-0.112192</td>\n",
              "      <td>-0.114322</td>\n",
              "      <td>-0.115178</td>\n",
              "      <td>-0.114371</td>\n",
              "      <td>-0.113408</td>\n",
              "      <td>7.879245</td>\n",
              "      <td>8.917473</td>\n",
              "      <td>10.805117</td>\n",
              "      <td>-0.113412</td>\n",
              "      <td>-0.113032</td>\n",
              "      <td>7.046486</td>\n",
              "      <td>-0.114332</td>\n",
              "      <td>-0.114511</td>\n",
              "      <td>-0.113153</td>\n",
              "      <td>11.206805</td>\n",
              "      <td>-0.112768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-1.069261</td>\n",
              "      <td>-1.068354</td>\n",
              "      <td>-1.070703</td>\n",
              "      <td>0.205823</td>\n",
              "      <td>-0.809806</td>\n",
              "      <td>2.033776</td>\n",
              "      <td>-0.702444</td>\n",
              "      <td>0.117809</td>\n",
              "      <td>-0.648023</td>\n",
              "      <td>-0.644065</td>\n",
              "      <td>-0.656789</td>\n",
              "      <td>-0.630624</td>\n",
              "      <td>-0.633201</td>\n",
              "      <td>-0.653905</td>\n",
              "      <td>-0.643668</td>\n",
              "      <td>-0.591111</td>\n",
              "      <td>-0.622907</td>\n",
              "      <td>-0.608863</td>\n",
              "      <td>-0.576811</td>\n",
              "      <td>-0.624773</td>\n",
              "      <td>-0.581083</td>\n",
              "      <td>-0.626779</td>\n",
              "      <td>-0.600276</td>\n",
              "      <td>-0.568125</td>\n",
              "      <td>-0.573546</td>\n",
              "      <td>-0.576967</td>\n",
              "      <td>-0.590335</td>\n",
              "      <td>-0.547794</td>\n",
              "      <td>-0.570899</td>\n",
              "      <td>-0.597481</td>\n",
              "      <td>-0.5961</td>\n",
              "      <td>-0.548717</td>\n",
              "      <td>-0.564996</td>\n",
              "      <td>-0.572969</td>\n",
              "      <td>-0.555294</td>\n",
              "      <td>-0.577879</td>\n",
              "      <td>-0.583952</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.118862</td>\n",
              "      <td>-0.121666</td>\n",
              "      <td>-0.120341</td>\n",
              "      <td>-0.118334</td>\n",
              "      <td>-0.119345</td>\n",
              "      <td>-0.119231</td>\n",
              "      <td>-0.12043</td>\n",
              "      <td>-0.119883</td>\n",
              "      <td>-0.11911</td>\n",
              "      <td>-0.120531</td>\n",
              "      <td>-0.118977</td>\n",
              "      <td>8.279828</td>\n",
              "      <td>4.878663</td>\n",
              "      <td>-0.118145</td>\n",
              "      <td>-0.117152</td>\n",
              "      <td>-0.117642</td>\n",
              "      <td>-0.116978</td>\n",
              "      <td>-0.117779</td>\n",
              "      <td>-0.117048</td>\n",
              "      <td>-0.117863</td>\n",
              "      <td>-0.11337</td>\n",
              "      <td>-0.116881</td>\n",
              "      <td>-0.114437</td>\n",
              "      <td>-0.115313</td>\n",
              "      <td>-0.112192</td>\n",
              "      <td>-0.114322</td>\n",
              "      <td>-0.115178</td>\n",
              "      <td>-0.114371</td>\n",
              "      <td>-0.113408</td>\n",
              "      <td>7.879245</td>\n",
              "      <td>8.917473</td>\n",
              "      <td>10.805117</td>\n",
              "      <td>-0.113412</td>\n",
              "      <td>-0.113032</td>\n",
              "      <td>7.697278</td>\n",
              "      <td>-0.114332</td>\n",
              "      <td>-0.114511</td>\n",
              "      <td>-0.113153</td>\n",
              "      <td>-0.110336</td>\n",
              "      <td>-0.112768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>-1.069261</td>\n",
              "      <td>-1.068354</td>\n",
              "      <td>-1.070703</td>\n",
              "      <td>0.047902</td>\n",
              "      <td>-0.809806</td>\n",
              "      <td>1.783387</td>\n",
              "      <td>-0.702444</td>\n",
              "      <td>0.434547</td>\n",
              "      <td>-0.648023</td>\n",
              "      <td>-0.644065</td>\n",
              "      <td>-0.656789</td>\n",
              "      <td>-0.630624</td>\n",
              "      <td>-0.633201</td>\n",
              "      <td>-0.653905</td>\n",
              "      <td>-0.643668</td>\n",
              "      <td>-0.591111</td>\n",
              "      <td>-0.622907</td>\n",
              "      <td>-0.608863</td>\n",
              "      <td>-0.576811</td>\n",
              "      <td>-0.624773</td>\n",
              "      <td>-0.581083</td>\n",
              "      <td>-0.626779</td>\n",
              "      <td>-0.600276</td>\n",
              "      <td>-0.568125</td>\n",
              "      <td>-0.573546</td>\n",
              "      <td>-0.576967</td>\n",
              "      <td>-0.590335</td>\n",
              "      <td>-0.547794</td>\n",
              "      <td>-0.570899</td>\n",
              "      <td>-0.597481</td>\n",
              "      <td>-0.5961</td>\n",
              "      <td>-0.548717</td>\n",
              "      <td>-0.564996</td>\n",
              "      <td>-0.572969</td>\n",
              "      <td>-0.555294</td>\n",
              "      <td>-0.577879</td>\n",
              "      <td>-0.583952</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.118862</td>\n",
              "      <td>-0.121666</td>\n",
              "      <td>-0.120341</td>\n",
              "      <td>-0.118334</td>\n",
              "      <td>-0.119345</td>\n",
              "      <td>-0.119231</td>\n",
              "      <td>-0.12043</td>\n",
              "      <td>-0.119883</td>\n",
              "      <td>-0.11911</td>\n",
              "      <td>-0.120531</td>\n",
              "      <td>-0.118977</td>\n",
              "      <td>8.279828</td>\n",
              "      <td>4.878663</td>\n",
              "      <td>-0.118145</td>\n",
              "      <td>-0.117152</td>\n",
              "      <td>-0.117642</td>\n",
              "      <td>-0.116978</td>\n",
              "      <td>-0.117779</td>\n",
              "      <td>-0.117048</td>\n",
              "      <td>-0.117863</td>\n",
              "      <td>-0.11337</td>\n",
              "      <td>-0.116881</td>\n",
              "      <td>-0.114437</td>\n",
              "      <td>-0.115313</td>\n",
              "      <td>-0.112192</td>\n",
              "      <td>-0.114322</td>\n",
              "      <td>-0.115178</td>\n",
              "      <td>-0.114371</td>\n",
              "      <td>-0.113408</td>\n",
              "      <td>7.879245</td>\n",
              "      <td>8.917473</td>\n",
              "      <td>-0.113179</td>\n",
              "      <td>-0.113412</td>\n",
              "      <td>-0.113032</td>\n",
              "      <td>6.395695</td>\n",
              "      <td>-0.114332</td>\n",
              "      <td>-0.114511</td>\n",
              "      <td>-0.113153</td>\n",
              "      <td>9.149143</td>\n",
              "      <td>-0.112768</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 994 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       x  ...  63781517942f8b63c2189c376cc0cf3db1d27ed1\n",
              "0 -999.0  ...                                 -0.112768\n",
              "1 -999.0  ...                                 -0.112768\n",
              "2 -999.0  ...                                 -0.112768\n",
              "3 -999.0  ...                                 -0.112768\n",
              "4 -999.0  ...                                 -0.112768\n",
              "\n",
              "[5 rows x 994 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnDOQsyFny1q"
      },
      "source": [
        "# # Use when we need to consider timetamps\n",
        "\n",
        "# # get timestamp and sort by time\n",
        "# test_df[[\"site\", \"file\", \"timestamp\"]] = test_df[\"site_path_timestamp\"].apply(lambda x: pd.Series(x.split(\"_\")))\n",
        "# test_df = test_df.drop(columns=[\"site_path_timestamp\", \"site\", \"file\"])\n",
        "# test_df[\"timestamp\"] = test_df[\"timestamp\"].astype(int)\n",
        "# # display(test_df.head())\n",
        "\n",
        "# # sort by time\n",
        "# train_df = train_df.sort_values(by=[\"file_id\", \"wifi_ts\"])\n",
        "# test_df = test_df.sort_values(by=[\"file_id\", \"timestamp\"])\n",
        "# # display(train_df.head(20))\n",
        "# # display(test_df.head(20))\n",
        "# # print(len(test_df.columns))"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ePebfXPvPui"
      },
      "source": [
        "---\n",
        "## 1Conv + Transformer Implementation\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNgXfNr2rnyk"
      },
      "source": [
        "class IndoorDataset(Dataset):\n",
        "    def __init__(self, data, flag=\"train\"):\n",
        "        self.flag = flag\n",
        "        self.data = data\n",
        "\n",
        "        all_cols = list(data.columns)\n",
        "        target_cols = [\"x\", \"y\", \"floor_int\"]\n",
        "        non_target_cols = [col for col in all_cols if col not in target_cols]\n",
        "        self.features = data[non_target_cols]\n",
        "\n",
        "        if self.flag == \"train\":\n",
        "            self.x = data.loc[:, \"x\"]\n",
        "            self.y = data.loc[:, \"y\"]\n",
        "            # self.f = data.loc[:, \"floor_int\"]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def feat_width(self):\n",
        "        return self.features.shape[1]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        features = self.features.iloc[index, :]\n",
        "        features_out = torch.tensor(features.to_numpy())\n",
        "        if self.flag == \"train\":\n",
        "            x = self.x[index]\n",
        "            y = self.y[index]\n",
        "            # f = self.f[index]\n",
        "            x_out = torch.tensor(x)\n",
        "            y_out = torch.tensor(y)\n",
        "            # f_out = torch.tensor(f)\n",
        "            return features_out, x_out, y_out\n",
        "        else:\n",
        "            return features_out"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZNpNu_psGuE",
        "outputId": "30064f45-d6da-46c1-fe1a-084981aa44fd"
      },
      "source": [
        "# Create train and test Dataset\n",
        "train_ds = IndoorDataset(train_df)\n",
        "test_ds = IndoorDataset(test_df, flag=\"test\")\n",
        "\n",
        "one_train_ds = train_ds.__getitem__(1000)\n",
        "print(\"train ds len: \", train_ds.__len__())\n",
        "# print(\"train ds features: \", one_train_ds[0])\n",
        "print(\"train ds x: \", one_train_ds[1])\n",
        "print(\"train ds y: \", one_train_ds[2])\n",
        "# print(\"train ds f: \", one_train_ds[3])\n",
        "\n",
        "one_test_ds = test_ds.__getitem__(0)\n",
        "print(\"test ds len: \", test_ds.__len__())\n",
        "# print(\"test ds features: \", one_test_ds[0])\n",
        "# print(\"test ds: \", one_test_ds)\n",
        "\n",
        "print(train_ds.feat_width())\n",
        "print(test_ds.feat_width())"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train ds len:  10027\n",
            "train ds x:  tensor(104.6150, dtype=torch.float64)\n",
            "train ds y:  tensor(83.2759, dtype=torch.float64)\n",
            "test ds len:  1223\n",
            "991\n",
            "991\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsDBm9wbv8JS"
      },
      "source": [
        "# Create Dataloader\n",
        "train_dataloader = DataLoader(train_ds, batch_size=BATCH_SIZE)\n",
        "test_dataloader = DataLoader(test_ds, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51XdnWYay8SP"
      },
      "source": [
        "class Conv1dMaxPool(nn.Module):\n",
        "    def __init__(self, in_channels, kernel_size, stride, padding):\n",
        "        super(Conv1dMaxPool, self).__init__()\n",
        "        self.conv_11 = nn.Conv1d(in_channels, 16, kernel_size, stride, padding)\n",
        "        self.conv_12 = nn.Conv1d(16, 16, kernel_size, stride, padding)\n",
        "        self.max_pool_1 = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
        "        self.conv_21 = nn.Conv1d(16, 32, kernel_size, stride, padding)\n",
        "        self.conv_22 = nn.Conv1d(32, 32, kernel_size, stride, padding)\n",
        "        self.max_pool_2 = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
        "        self.conv_31 = nn.Conv1d(32, 64, kernel_size, stride, padding)\n",
        "        self.conv_32 = nn.Conv1d(64, 64, kernel_size, stride, padding)\n",
        "        self.max_pool_3 = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
        "        self.fc_encoder = nn.Linear(64*2, 512)\n",
        "        self.batch_norm = nn.BatchNorm1d(512)\n",
        "        self.out_encoder = nn.Linear(512, 64)\n",
        "\n",
        "    def forward(self, x, prints=False):\n",
        "        x = x.unsqueeze(0)\n",
        "        x = torch.transpose(x, 0, 1)\n",
        "        if prints: print(\"before conv 1: \", x.shape)\n",
        "        x = F.relu(self.conv_11(x))\n",
        "        x = F.relu(self.conv_12(x))\n",
        "        x = self.max_pool_1(x)\n",
        "        if prints: print(\"after conv & max_pool 1: \", x.shape)\n",
        "\n",
        "        x = F.relu(self.conv_21(x))\n",
        "        x = F.relu(self.conv_22(x))\n",
        "        x = self.max_pool_2(x)\n",
        "        if prints: print(\"after conv & max_pool 2: \", x.shape)\n",
        "\n",
        "        x = F.relu(self.conv_31(x))\n",
        "        x = F.relu(self.conv_32(x))\n",
        "        x = self.max_pool_3(x)\n",
        "        if prints: print(\"after conv & max_pool 3: \", x.shape)\n",
        "\n",
        "        # if prints: print(\"checking reshaping: \", x[0])\n",
        "        x = x.view(x.size(0), -1) # flatten last two dimensions\n",
        "        # if prints: print(\"checking reshaping: \", x[0])\n",
        "        if prints: print(\"flatten last two dims: \", x.shape)\n",
        "        x = self.batch_norm(self.fc_encoder(x))\n",
        "        x = self.out_encoder(x)\n",
        "        if prints: print(\"final output: \", x.shape)\n",
        "        return x"
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJPs3O4323xO",
        "outputId": "d5970ffc-01e0-4bf1-ded7-98f6215d85d3"
      },
      "source": [
        "train_length = train_ds.__len__()\n",
        "train_width = train_ds.feat_width()\n",
        "\n",
        "conv_1d_maxpool = Conv1dMaxPool(in_channels=1, kernel_size=3, stride=2, padding=1).to(DEVICE)\n",
        "print(conv_1d_maxpool)\n",
        "\n",
        "# input_size = num of features, so length of columns\n",
        "# sequence_length = 5\n",
        "\n",
        "# Check if it works\n",
        "train_batch_sample = next(iter(train_dataloader))\n",
        "print(\"feature shape: \", train_batch_sample[0].shape)\n",
        "print(\"x shape: \", train_batch_sample[1].shape)\n",
        "print(\"y shape: \", train_batch_sample[2].shape)\n",
        "train_batch_sample = train_batch_sample[0]\n",
        "print(\"input shape: \", train_batch_sample.shape)\n",
        "outputs = conv_1d_maxpool(train_batch_sample.float(), prints=True)\n",
        "print(\"final output shape: \", outputs.shape)\n",
        "print(\"final output: \", outputs)"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Conv1dMaxPool(\n",
            "  (conv_11): Conv1d(1, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
            "  (conv_12): Conv1d(16, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
            "  (max_pool_1): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (conv_21): Conv1d(16, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
            "  (conv_22): Conv1d(32, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
            "  (max_pool_2): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (conv_31): Conv1d(32, 64, kernel_size=(3,), stride=(2,), padding=(1,))\n",
            "  (conv_32): Conv1d(64, 64, kernel_size=(3,), stride=(2,), padding=(1,))\n",
            "  (max_pool_3): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (fc_encoder): Linear(in_features=128, out_features=512, bias=True)\n",
            "  (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (out_encoder): Linear(in_features=512, out_features=64, bias=True)\n",
            ")\n",
            "feature shape:  torch.Size([32, 991])\n",
            "x shape:  torch.Size([32])\n",
            "y shape:  torch.Size([32])\n",
            "input shape:  torch.Size([32, 991])\n",
            "before conv 1:  torch.Size([32, 1, 991])\n",
            "after conv & max_pool 1:  torch.Size([32, 16, 124])\n",
            "after conv & max_pool 2:  torch.Size([32, 32, 16])\n",
            "after conv & max_pool 3:  torch.Size([32, 64, 2])\n",
            "flatten last two dims:  torch.Size([32, 128])\n",
            "final output:  torch.Size([32, 64])\n",
            "final output shape:  torch.Size([32, 64])\n",
            "final output:  tensor([[-0.5728, -0.0369,  0.1191,  ...,  0.0973, -0.1320,  0.6371],\n",
            "        [-0.5437,  0.0396,  0.1028,  ..., -0.1527, -0.2160,  0.3884],\n",
            "        [-0.4350,  0.0846,  0.2024,  ..., -0.0873, -0.0485,  0.5082],\n",
            "        ...,\n",
            "        [ 0.0231, -0.0034, -0.1347,  ...,  0.0244, -0.0090, -0.4565],\n",
            "        [-0.0509, -0.0379, -0.0540,  ...,  0.1019, -0.0349, -0.4576],\n",
            "        [ 0.0357,  0.0032, -0.0873,  ...,  0.1191,  0.0342, -0.5442]],\n",
            "       grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IREBqLnPERaz"
      },
      "source": [
        "# Transformer: -> conv1d output -> pe -> (embed thru TransformerEncoderLayer)\n",
        "# -> encoder -> decoder\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, feature_dim, batch_len):\n",
        "        super(PositionalEncoding, self).__init__()       \n",
        "        pe = torch.zeros(batch_len, feature_dim)\n",
        "        # print(\"pe shape\", pe.shape)\n",
        "        position = torch.arange(0, batch_len, dtype=torch.float).unsqueeze(1)\n",
        "        # print(\"position shape\", position.shape)\n",
        "        div_term = torch.exp(torch.arange(0, feature_dim, 2).float() * (-math.log(10000.0) / feature_dim))\n",
        "        # print(\"div_term shape\", div_term.shape)\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe.requires_grad = False\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:x.size(0), :]\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, feature_dim, batch_len, num_layers=1, dropout=0.1):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.src_mask = None\n",
        "        self.pos_encoder = PositionalEncoding(feature_dim, batch_len)\n",
        "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=feature_dim, nhead=2, dropout=dropout)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)        \n",
        "        self.decoder = nn.Linear(feature_dim, 2)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.kaiming_uniform_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x, prints=False):\n",
        "        if prints: print(\"x dims: \", x.shape)\n",
        "        if self.src_mask is None or self.src_mask.size(0) != len(x):\n",
        "            mask = self._generate_square_subsequent_mask(len(x)).to(DEVICE)\n",
        "            if prints: print(\"mask shape\", mask.shape)\n",
        "            # print(\"mask 0\", mask[0])\n",
        "            # print(\"mask 1\", mask[1])\n",
        "            # print(\"mask -2\", mask[-2])\n",
        "            # print(\"mask -1\", mask[-1])\n",
        "            self.src_mask = mask\n",
        "\n",
        "        x = self.pos_encoder(x)\n",
        "        if prints: print(\"x after pos_encoder: \", x.shape)\n",
        "        x = x.unsqueeze(1)\n",
        "        if prints: print(\"x after unsqueeze: \", x.shape)\n",
        "        output = self.transformer_encoder(x, self.src_mask)\n",
        "        if prints: print(\"x after transformer_encoder: \", x.shape)\n",
        "        output = self.decoder(output)\n",
        "        output = output.squeeze(1)\n",
        "        return output\n",
        "\n",
        "    def _generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "        return mask"
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrgkU-Zlvw0D",
        "outputId": "f69a341d-7589-448b-d91d-c584017b969d"
      },
      "source": [
        "# testing transformer block\n",
        "Conv = Conv1dMaxPool(in_channels=1, kernel_size=3, stride=2, padding=1).to(DEVICE)\n",
        "\n",
        "# Check if it works\n",
        "train_batch_sample = next(iter(train_dataloader))\n",
        "train_batch_sample = train_batch_sample[0]\n",
        "print(train_batch_sample)\n",
        "conv_outputs = Conv(train_batch_sample.float(), prints=True)\n",
        "print(\"final output shape: \", conv_outputs.shape)\n",
        "print(\"final output: \", conv_outputs[0])\n",
        "print(conv_outputs.shape[1])\n",
        "print(conv_outputs.requires_grad)\n",
        "\n",
        "# check pe\n",
        "batch_len = conv_outputs.shape[0]\n",
        "feature_dim = conv_outputs.shape[1]\n",
        "pe = PositionalEncoding(feature_dim, batch_len)\n",
        "pe_out = pe(conv_outputs)\n",
        "print(pe_out[0])\n",
        "print(pe_out.shape)\n",
        "print(pe_out.requires_grad)\n",
        "\n",
        "# check transformer\n",
        "ts = Transformer(feature_dim, batch_len, num_layers=1, dropout=0.1)\n",
        "ts_out = ts(conv_outputs, prints=True)\n",
        "print(ts_out[:3])\n",
        "print(ts_out.shape)\n",
        "print(ts_out.requires_grad)"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1.0229,  1.1847,  1.0144,  ..., -0.1132, -0.1103, -0.1128],\n",
            "        [ 0.7718,  0.7674,  0.4305,  ..., -0.1132, -0.1103, -0.1128],\n",
            "        [ 1.6924,  1.7688,  1.7650,  ..., -0.1132, -0.1103, -0.1128],\n",
            "        ...,\n",
            "        [ 1.4413,  1.4350,  1.2646,  ..., -0.1132, -0.1103, -0.1128],\n",
            "        [ 1.4413,  1.1847,  1.4314,  ..., -0.1132, -0.1103, -0.1128],\n",
            "        [ 1.6924,  1.6853,  1.6816,  ..., -0.1132, -0.1103, -0.1128]],\n",
            "       dtype=torch.float64)\n",
            "before conv 1:  torch.Size([32, 1, 991])\n",
            "after conv & max_pool 1:  torch.Size([32, 16, 124])\n",
            "after conv & max_pool 2:  torch.Size([32, 32, 16])\n",
            "after conv & max_pool 3:  torch.Size([32, 64, 2])\n",
            "flatten last two dims:  torch.Size([32, 128])\n",
            "final output:  torch.Size([32, 64])\n",
            "final output shape:  torch.Size([32, 64])\n",
            "final output:  tensor([-0.0047,  0.1706,  0.2983,  0.0277,  0.1307, -0.2316, -0.0338, -0.1821,\n",
            "        -0.0214,  0.2069, -0.0817, -0.4830,  0.1511, -0.0813,  0.3203,  0.3543,\n",
            "        -0.3748, -0.0575,  0.0444, -0.3303, -0.2680, -0.2607,  0.3174, -0.2400,\n",
            "        -0.1607, -1.0135, -0.1503,  0.6739, -0.2163,  0.2579,  0.4246, -0.2369,\n",
            "        -0.1034, -0.1284,  0.2056, -0.4243,  0.0960, -0.2494,  0.0279, -0.0824,\n",
            "        -0.5458, -0.0266, -0.1166,  0.1772, -0.1110,  0.4042, -0.1793,  0.0106,\n",
            "         0.1982, -0.2138,  0.1505, -0.1986,  0.2905, -0.1531, -0.2665, -0.1006,\n",
            "        -0.0177, -0.6034, -0.3441,  0.6441, -0.0441, -0.3439, -0.0593, -0.4103],\n",
            "       grad_fn=<SelectBackward>)\n",
            "64\n",
            "True\n",
            "tensor([-0.0047,  1.1706,  0.2983,  1.0277,  0.1307,  0.7684, -0.0338,  0.8179,\n",
            "        -0.0214,  1.2069, -0.0817,  0.5170,  0.1511,  0.9187,  0.3203,  1.3543,\n",
            "        -0.3748,  0.9425,  0.0444,  0.6697, -0.2680,  0.7393,  0.3174,  0.7600,\n",
            "        -0.1607, -0.0135, -0.1503,  1.6739, -0.2163,  1.2579,  0.4246,  0.7631,\n",
            "        -0.1034,  0.8716,  0.2056,  0.5757,  0.0960,  0.7506,  0.0279,  0.9176,\n",
            "        -0.5458,  0.9734, -0.1166,  1.1772, -0.1110,  1.4042, -0.1793,  1.0106,\n",
            "         0.1982,  0.7862,  0.1505,  0.8014,  0.2905,  0.8469, -0.2665,  0.8994,\n",
            "        -0.0177,  0.3966, -0.3441,  1.6441, -0.0441,  0.6561, -0.0593,  0.5897],\n",
            "       grad_fn=<SelectBackward>)\n",
            "torch.Size([32, 64])\n",
            "True\n",
            "x dims:  torch.Size([32, 64])\n",
            "mask shape torch.Size([32, 32])\n",
            "x after pos_encoder:  torch.Size([32, 64])\n",
            "x after unsqueeze:  torch.Size([32, 1, 64])\n",
            "x after transformer_encoder:  torch.Size([32, 1, 64])\n",
            "tensor([[-0.4618, -0.3998],\n",
            "        [ 0.9615, -0.7132],\n",
            "        [-1.2090, -0.1971]], grad_fn=<SliceBackward>)\n",
            "torch.Size([32, 2])\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4LYWCfobjKA"
      },
      "source": [
        "# Define model\n",
        "class Conv1dTransformer(nn.Module):\n",
        "    def __init__(self, in_channels, kernel_size, stride, padding, feature_dim, batch_len, num_layers=1, dropout=0.1):\n",
        "        super(Conv1dTransformer, self).__init__()\n",
        "        self.conv = Conv1dMaxPool(in_channels, kernel_size, stride, padding)\n",
        "        self.transformer = Transformer(feature_dim, batch_len, num_layers, dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.transformer(x)\n",
        "        return x"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWQGc5DVdqq1",
        "outputId": "a211a3bd-9d24-4724-bdd9-92ed3a7d2f11"
      },
      "source": [
        "# Run conv to output the feature_dim\n",
        "Conv = Conv1dMaxPool(in_channels=1, kernel_size=3, stride=2, padding=1).to(DEVICE)\n",
        "\n",
        "# Check that it works\n",
        "train_batch_sample = next(iter(train_dataloader))\n",
        "train_batch_sample = train_batch_sample[0]\n",
        "conv_outputs = Conv(train_batch_sample.float())\n",
        "feature_dim = conv_outputs.shape[1]\n",
        "print(feature_dim)\n",
        "\n",
        "# set model with params\n",
        "model = Conv1dTransformer(in_channels=1, kernel_size=3, stride=2, padding=1, \\\n",
        "                             feature_dim=feature_dim, batch_len=BATCH_SIZE, num_layers=1, dropout=0.3).to(DEVICE)\n",
        "print(model)"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "64\n",
            "Conv1dTransformer(\n",
            "  (conv): Conv1dMaxPool(\n",
            "    (conv_11): Conv1d(1, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
            "    (conv_12): Conv1d(16, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
            "    (max_pool_1): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (conv_21): Conv1d(16, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
            "    (conv_22): Conv1d(32, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
            "    (max_pool_2): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (conv_31): Conv1d(32, 64, kernel_size=(3,), stride=(2,), padding=(1,))\n",
            "    (conv_32): Conv1d(64, 64, kernel_size=(3,), stride=(2,), padding=(1,))\n",
            "    (max_pool_3): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (fc_encoder): Linear(in_features=128, out_features=512, bias=True)\n",
            "    (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (out_encoder): Linear(in_features=512, out_features=64, bias=True)\n",
            "  )\n",
            "  (transformer): Transformer(\n",
            "    (pos_encoder): PositionalEncoding()\n",
            "    (encoder_layer): TransformerEncoderLayer(\n",
            "      (self_attn): MultiheadAttention(\n",
            "        (out_proj): _LinearWithBias(in_features=64, out_features=64, bias=True)\n",
            "      )\n",
            "      (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
            "      (dropout): Dropout(p=0.3, inplace=False)\n",
            "      (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
            "      (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout1): Dropout(p=0.3, inplace=False)\n",
            "      (dropout2): Dropout(p=0.3, inplace=False)\n",
            "    )\n",
            "    (transformer_encoder): TransformerEncoder(\n",
            "      (layers): ModuleList(\n",
            "        (0): TransformerEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): _LinearWithBias(in_features=64, out_features=64, bias=True)\n",
            "          )\n",
            "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
            "          (dropout): Dropout(p=0.3, inplace=False)\n",
            "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
            "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout1): Dropout(p=0.3, inplace=False)\n",
            "          (dropout2): Dropout(p=0.3, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (decoder): Linear(in_features=64, out_features=2, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wM_NRmwNpoyl",
        "outputId": "04a55817-5d6b-449c-b903-bf53f239b66b"
      },
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # default lr: 5e-3\n",
        "\n",
        "data_dict ={}\n",
        "best_loss = 1000\n",
        "best_epoch = 0\n",
        "model.train()\n",
        "\n",
        "for epoch in range(EPOCH):\n",
        "    print(\"epoch: \", epoch)\n",
        "    losses = []\n",
        "    for i, data in enumerate(train_dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        # print(data[0])\n",
        "        features = Variable(data[0].float(), requires_grad=True).to(DEVICE)\n",
        "        # print(\"Backward prop-able\", features.requires_grad)\n",
        "        # print(features[0])\n",
        "        # features = features.unsqueeze(0)\n",
        "        # print(\"imu shape: \", imu_features.shape)\n",
        "        x = data[1].float().unsqueeze(-1).to(DEVICE)\n",
        "        # print(\"x shape: \", x.shape)\n",
        "        y = data[2].float().unsqueeze(-1).to(DEVICE)\n",
        "        # print(\"y shape: \", y.shape)\n",
        "\n",
        "        # output = model(features, prints=False)\n",
        "        # print(\"output\", output)\n",
        "        # print(\"output shape after concat: \", output.shape)\n",
        "        # conv_outputs = (features)\n",
        "        # print(\"conv output\", conv_outputs[0])\n",
        "        # ts_out = ts(conv_outputs)\n",
        "        output = model(features)\n",
        "        # print(\"batch \", i, \" : \", ts_out)\n",
        "\n",
        "        x = Variable(x, requires_grad=True)\n",
        "        y = Variable(y, requires_grad=True)\n",
        "        label = torch.cat([x, y], dim=-1)\n",
        "        # print(\"ts_out[0]: \", ts_out[0])\n",
        "        # print(\"label[0]: \", label[0])\n",
        "        # print(\"label\", label)\n",
        "        # print(\"label shape after concat: \", label.shape)\n",
        "        loss = criterion(output, label)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        losses.append(loss.item())\n",
        "        # print(\"loss: \", loss.item())\n",
        "        print(f\"loss:{np.mean(losses)} at iteration {i}\")\n",
        "\n",
        "print(\"Training finished\")"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:  0\n",
            "loss:8108.80859375 at iteration 0\n",
            "loss:7387.6220703125 at iteration 1\n",
            "loss:8375.52734375 at iteration 2\n",
            "loss:9137.82763671875 at iteration 3\n",
            "loss:8740.3361328125 at iteration 4\n",
            "loss:8285.5478515625 at iteration 5\n",
            "loss:8306.580357142857 at iteration 6\n",
            "loss:8676.038330078125 at iteration 7\n",
            "loss:8755.967881944445 at iteration 8\n",
            "loss:8934.27841796875 at iteration 9\n",
            "loss:8528.599786931818 at iteration 10\n",
            "loss:8149.25634765625 at iteration 11\n",
            "loss:7955.671987680288 at iteration 12\n",
            "loss:7656.371442522322 at iteration 13\n",
            "loss:7650.001399739584 at iteration 14\n",
            "loss:7643.634552001953 at iteration 15\n",
            "loss:7585.103687959559 at iteration 16\n",
            "loss:7465.230902777777 at iteration 17\n",
            "loss:7608.623612253289 at iteration 18\n",
            "loss:7414.103247070312 at iteration 19\n",
            "loss:7338.254836309524 at iteration 20\n",
            "loss:7191.557750355114 at iteration 21\n",
            "loss:7212.344917629076 at iteration 22\n",
            "loss:7378.356058756511 at iteration 23\n",
            "loss:7566.27423828125 at iteration 24\n",
            "loss:7783.442626953125 at iteration 25\n",
            "loss:7966.4756763599535 at iteration 26\n",
            "loss:8029.434797014509 at iteration 27\n",
            "loss:7824.739283068427 at iteration 28\n",
            "loss:8009.716625976563 at iteration 29\n",
            "loss:7858.676686932964 at iteration 30\n",
            "loss:7781.562568664551 at iteration 31\n",
            "loss:7692.942552971117 at iteration 32\n",
            "loss:7690.900211109834 at iteration 33\n",
            "loss:7735.8736537388395 at iteration 34\n",
            "loss:7641.728535970052 at iteration 35\n",
            "loss:7606.00329259924 at iteration 36\n",
            "loss:7448.692951403166 at iteration 37\n",
            "loss:7458.287600786258 at iteration 38\n",
            "loss:7448.601907348633 at iteration 39\n",
            "loss:7462.873823956746 at iteration 40\n",
            "loss:7530.849158877418 at iteration 41\n",
            "loss:7530.73180016806 at iteration 42\n",
            "loss:7609.681698885831 at iteration 43\n",
            "loss:7556.929375542535 at iteration 44\n",
            "loss:7527.406146505605 at iteration 45\n",
            "loss:7461.248568920379 at iteration 46\n",
            "loss:7454.6494064331055 at iteration 47\n",
            "loss:7535.393846161512 at iteration 48\n",
            "loss:7553.240480957032 at iteration 49\n",
            "loss:7451.011103611367 at iteration 50\n",
            "loss:7371.270481989934 at iteration 51\n",
            "loss:7368.78514934036 at iteration 52\n",
            "loss:7398.728147153502 at iteration 53\n",
            "loss:7448.652905273438 at iteration 54\n",
            "loss:7532.101119995117 at iteration 55\n",
            "loss:7520.296363161321 at iteration 56\n",
            "loss:7482.639861008217 at iteration 57\n",
            "loss:7463.939744852357 at iteration 58\n",
            "loss:7482.448822021484 at iteration 59\n",
            "loss:7513.287951860271 at iteration 60\n",
            "loss:7580.934076124622 at iteration 61\n",
            "loss:7637.401686895461 at iteration 62\n",
            "loss:7615.976327896118 at iteration 63\n",
            "loss:7592.002308067908 at iteration 64\n",
            "loss:7602.168125961766 at iteration 65\n",
            "loss:7614.363844230994 at iteration 66\n",
            "loss:7553.547813864316 at iteration 67\n",
            "loss:7517.6254582059555 at iteration 68\n",
            "loss:7462.635203334264 at iteration 69\n",
            "loss:7475.036495584837 at iteration 70\n",
            "loss:7474.741880628798 at iteration 71\n",
            "loss:7530.013422717787 at iteration 72\n",
            "loss:7508.91904263883 at iteration 73\n",
            "loss:7451.257797851563 at iteration 74\n",
            "loss:7383.43140130294 at iteration 75\n",
            "loss:7333.514802214388 at iteration 76\n",
            "loss:7294.366512983273 at iteration 77\n",
            "loss:7237.693147683445 at iteration 78\n",
            "loss:7171.015226745605 at iteration 79\n",
            "loss:7126.256807303723 at iteration 80\n",
            "loss:7072.25061481755 at iteration 81\n",
            "loss:7051.938866305064 at iteration 82\n",
            "loss:7026.302235921224 at iteration 83\n",
            "loss:6963.681086282169 at iteration 84\n",
            "loss:6954.81404717024 at iteration 85\n",
            "loss:6889.658107713722 at iteration 86\n",
            "loss:6895.8329523259945 at iteration 87\n",
            "loss:6897.827428239115 at iteration 88\n",
            "loss:6864.946354166666 at iteration 89\n",
            "loss:6825.983403803228 at iteration 90\n",
            "loss:6784.140975288723 at iteration 91\n",
            "loss:6757.603536626344 at iteration 92\n",
            "loss:6727.522185629987 at iteration 93\n",
            "loss:6731.405787417763 at iteration 94\n",
            "loss:6707.574778238933 at iteration 95\n",
            "loss:6688.967667727126 at iteration 96\n",
            "loss:6655.562285754146 at iteration 97\n",
            "loss:6624.444617069129 at iteration 98\n",
            "loss:6604.031879882812 at iteration 99\n",
            "loss:6575.064291170328 at iteration 100\n",
            "loss:6577.308194029565 at iteration 101\n",
            "loss:6570.270623957069 at iteration 102\n",
            "loss:6536.522489107572 at iteration 103\n",
            "loss:6510.960239955357 at iteration 104\n",
            "loss:6482.14089217276 at iteration 105\n",
            "loss:6470.947420779789 at iteration 106\n",
            "loss:6445.8931884765625 at iteration 107\n",
            "loss:6432.841801354644 at iteration 108\n",
            "loss:6412.234694602273 at iteration 109\n",
            "loss:6401.482813379786 at iteration 110\n",
            "loss:6399.66936819894 at iteration 111\n",
            "loss:6377.030308006084 at iteration 112\n",
            "loss:6367.141327439693 at iteration 113\n",
            "loss:6356.864478600543 at iteration 114\n",
            "loss:6348.2638570851295 at iteration 115\n",
            "loss:6334.655820145566 at iteration 116\n",
            "loss:6315.544379800053 at iteration 117\n",
            "loss:6307.780593487395 at iteration 118\n",
            "loss:6284.225113932292 at iteration 119\n",
            "loss:6254.747231727789 at iteration 120\n",
            "loss:6228.026193087218 at iteration 121\n",
            "loss:6226.714218511814 at iteration 122\n",
            "loss:6233.634909352949 at iteration 123\n",
            "loss:6230.287587890625 at iteration 124\n",
            "loss:6234.132651677207 at iteration 125\n",
            "loss:6230.317042553519 at iteration 126\n",
            "loss:6222.050085067749 at iteration 127\n",
            "loss:6203.394858663396 at iteration 128\n",
            "loss:6189.1436354417065 at iteration 129\n",
            "loss:6168.694201753339 at iteration 130\n",
            "loss:6139.10185842803 at iteration 131\n",
            "loss:6123.7400563175515 at iteration 132\n",
            "loss:6100.473018817048 at iteration 133\n",
            "loss:6097.2226906105325 at iteration 134\n",
            "loss:6100.398356718176 at iteration 135\n",
            "loss:6090.8324678518475 at iteration 136\n",
            "loss:6089.4991172016535 at iteration 137\n",
            "loss:6085.804489025967 at iteration 138\n",
            "loss:6073.294341169085 at iteration 139\n",
            "loss:6051.0114261275485 at iteration 140\n",
            "loss:6021.599141725352 at iteration 141\n",
            "loss:5998.071246380572 at iteration 142\n",
            "loss:5973.2373606363935 at iteration 143\n",
            "loss:5949.430366042565 at iteration 144\n",
            "loss:5923.664167848352 at iteration 145\n",
            "loss:5893.009832057823 at iteration 146\n",
            "loss:5873.422937341638 at iteration 147\n",
            "loss:5863.57182649958 at iteration 148\n",
            "loss:5854.014554036458 at iteration 149\n",
            "loss:5830.438250206954 at iteration 150\n",
            "loss:5804.253507915296 at iteration 151\n",
            "loss:5785.218689363766 at iteration 152\n",
            "loss:5771.389455027394 at iteration 153\n",
            "loss:5761.652290196573 at iteration 154\n",
            "loss:5754.401364057492 at iteration 155\n",
            "loss:5735.66953778115 at iteration 156\n",
            "epoch:  1\n",
            "loss:5264.51025390625 at iteration 0\n",
            "loss:4868.852294921875 at iteration 1\n",
            "loss:5978.36669921875 at iteration 2\n",
            "loss:6753.4100341796875 at iteration 3\n",
            "loss:6439.15400390625 at iteration 4\n",
            "loss:6078.954915364583 at iteration 5\n",
            "loss:6131.967703683035 at iteration 6\n",
            "loss:6502.555358886719 at iteration 7\n",
            "loss:6613.864583333333 at iteration 8\n",
            "loss:6789.73291015625 at iteration 9\n",
            "loss:6459.368607954545 at iteration 10\n",
            "loss:6140.7543538411455 at iteration 11\n",
            "loss:5967.037146935096 at iteration 12\n",
            "loss:5713.589634486607 at iteration 13\n",
            "loss:5698.41123046875 at iteration 14\n",
            "loss:5680.768035888672 at iteration 15\n",
            "loss:5619.867359834559 at iteration 16\n",
            "loss:5513.473090277777 at iteration 17\n",
            "loss:5647.950041118421 at iteration 18\n",
            "loss:5485.609545898437 at iteration 19\n",
            "loss:5427.271647135417 at iteration 20\n",
            "loss:5296.900945490057 at iteration 21\n",
            "loss:5305.628587805707 at iteration 22\n",
            "loss:5437.032165527344 at iteration 23\n",
            "loss:5586.32646484375 at iteration 24\n",
            "loss:5774.743295522837 at iteration 25\n",
            "loss:5922.041395399306 at iteration 26\n",
            "loss:5974.405133928572 at iteration 27\n",
            "loss:5807.02298710264 at iteration 28\n",
            "loss:5958.697448730469 at iteration 29\n",
            "loss:5830.5505883001515 at iteration 30\n",
            "loss:5757.190410614014 at iteration 31\n",
            "loss:5673.9778904770355 at iteration 32\n",
            "loss:5666.5747321633735 at iteration 33\n",
            "loss:5698.728958565848 at iteration 34\n",
            "loss:5617.827714708116 at iteration 35\n",
            "loss:5582.068329682222 at iteration 36\n",
            "loss:5452.227429841694 at iteration 37\n",
            "loss:5449.957776191907 at iteration 38\n",
            "loss:5430.742962646485 at iteration 39\n",
            "loss:5431.783185261052 at iteration 40\n",
            "loss:5489.514735630581 at iteration 41\n",
            "loss:5481.2197776617 at iteration 42\n",
            "loss:5539.951732288708 at iteration 43\n",
            "loss:5494.667171223959 at iteration 44\n",
            "loss:5464.9324208135195 at iteration 45\n",
            "loss:5402.420010181184 at iteration 46\n",
            "loss:5388.366409301758 at iteration 47\n",
            "loss:5450.804682517538 at iteration 48\n",
            "loss:5459.016342773438 at iteration 49\n",
            "loss:5374.992063036152 at iteration 50\n",
            "loss:5309.255389873798 at iteration 51\n",
            "loss:5298.294461232312 at iteration 52\n",
            "loss:5312.334508825232 at iteration 53\n",
            "loss:5342.713796164773 at iteration 54\n",
            "loss:5408.664951869419 at iteration 55\n",
            "loss:5391.929173519737 at iteration 56\n",
            "loss:5351.935698410561 at iteration 57\n",
            "loss:5326.852435613083 at iteration 58\n",
            "loss:5334.910868326823 at iteration 59\n",
            "loss:5350.454049532531 at iteration 60\n",
            "loss:5398.426407352571 at iteration 61\n",
            "loss:5439.409695095486 at iteration 62\n",
            "loss:5417.460124969482 at iteration 63\n",
            "loss:5390.8032076322115 at iteration 64\n",
            "loss:5390.699359315814 at iteration 65\n",
            "loss:5392.566595732276 at iteration 66\n",
            "loss:5339.827539780561 at iteration 67\n",
            "loss:5303.306962607563 at iteration 68\n",
            "loss:5254.123388671875 at iteration 69\n",
            "loss:5261.076687665053 at iteration 70\n",
            "loss:5255.625223795573 at iteration 71\n",
            "loss:5291.41872458262 at iteration 72\n",
            "loss:5267.105505041174 at iteration 73\n",
            "loss:5220.555192057292 at iteration 74\n",
            "loss:5165.67816483347 at iteration 75\n",
            "loss:5124.6592129794035 at iteration 76\n",
            "loss:5089.649791228466 at iteration 77\n",
            "loss:5041.424881947191 at iteration 78\n",
            "loss:4986.815932464599 at iteration 79\n",
            "loss:4950.410452383536 at iteration 80\n",
            "loss:4905.007009366664 at iteration 81\n",
            "loss:4885.63375155897 at iteration 82\n",
            "loss:4861.674846104213 at iteration 83\n",
            "loss:4811.60480598001 at iteration 84\n",
            "loss:4798.772671721702 at iteration 85\n",
            "loss:4751.739271142017 at iteration 86\n",
            "loss:4748.49508597634 at iteration 87\n",
            "loss:4745.148313372322 at iteration 88\n",
            "loss:4720.827652316623 at iteration 89\n",
            "loss:4690.434210138006 at iteration 90\n",
            "loss:4657.189603722613 at iteration 91\n",
            "loss:4635.343478951403 at iteration 92\n",
            "loss:4610.069046994473 at iteration 93\n",
            "loss:4609.572971705386 at iteration 94\n",
            "loss:4585.645819981893 at iteration 95\n",
            "loss:4568.340922876731 at iteration 96\n",
            "loss:4539.563356360611 at iteration 97\n",
            "loss:4511.481729526712 at iteration 98\n",
            "loss:4490.679690551758 at iteration 99\n",
            "loss:4463.920135195893 at iteration 100\n",
            "loss:4457.675552068972 at iteration 101\n",
            "loss:4445.375704570882 at iteration 102\n",
            "loss:4415.9854577871465 at iteration 103\n",
            "loss:4391.526452636719 at iteration 104\n",
            "loss:4365.182617763303 at iteration 105\n",
            "loss:4352.728764899423 at iteration 106\n",
            "loss:4330.342150087709 at iteration 107\n",
            "loss:4316.284372872169 at iteration 108\n",
            "loss:4299.603092262962 at iteration 109\n",
            "loss:4290.196157644461 at iteration 110\n",
            "loss:4282.901805877686 at iteration 111\n",
            "loss:4262.713805072075 at iteration 112\n",
            "loss:4248.476094028406 at iteration 113\n",
            "loss:4234.290347422724 at iteration 114\n",
            "loss:4222.2132300015155 at iteration 115\n",
            "loss:4206.933235364083 at iteration 116\n",
            "loss:4188.472100209382 at iteration 117\n",
            "loss:4176.928789411272 at iteration 118\n",
            "loss:4156.7306788126625 at iteration 119\n",
            "loss:4133.469903614895 at iteration 120\n",
            "loss:4111.729303578862 at iteration 121\n",
            "loss:4104.650280960207 at iteration 122\n",
            "loss:4102.7253078337635 at iteration 123\n",
            "loss:4093.9335483398436 at iteration 124\n",
            "loss:4089.8465532575333 at iteration 125\n",
            "loss:4080.4380031795954 at iteration 126\n",
            "loss:4068.2390475273132 at iteration 127\n",
            "loss:4050.826777022014 at iteration 128\n",
            "loss:4036.850700026292 at iteration 129\n",
            "loss:4018.2320747666686 at iteration 130\n",
            "loss:3993.497460105202 at iteration 131\n",
            "loss:3977.51738492349 at iteration 132\n",
            "loss:3957.157483912226 at iteration 133\n",
            "loss:3948.9683652524595 at iteration 134\n",
            "loss:3945.3362233779008 at iteration 135\n",
            "loss:3933.4930468928205 at iteration 136\n",
            "loss:3926.309657442397 at iteration 137\n",
            "loss:3918.496794995644 at iteration 138\n",
            "loss:3904.5965597970144 at iteration 139\n",
            "loss:3885.3690588119184 at iteration 140\n",
            "loss:3861.679275727608 at iteration 141\n",
            "loss:3841.573731749208 at iteration 142\n",
            "loss:3820.7198469373916 at iteration 143\n",
            "loss:3800.5342680832437 at iteration 144\n",
            "loss:3779.2205455205212 at iteration 145\n",
            "loss:3755.2763420675888 at iteration 146\n",
            "loss:3737.4309855280694 at iteration 147\n",
            "loss:3725.8745049598233 at iteration 148\n",
            "loss:3714.7375518798826 at iteration 149\n",
            "loss:3697.133621518975 at iteration 150\n",
            "loss:3677.033398477655 at iteration 151\n",
            "loss:3661.4419314315896 at iteration 152\n",
            "loss:3649.2224432214516 at iteration 153\n",
            "loss:3638.70602023217 at iteration 154\n",
            "loss:3629.9396724211865 at iteration 155\n",
            "loss:3614.2524804765253 at iteration 156\n",
            "epoch:  2\n",
            "loss:2476.568115234375 at iteration 0\n",
            "loss:2184.7274780273438 at iteration 1\n",
            "loss:3143.5968017578125 at iteration 2\n",
            "loss:3770.794403076172 at iteration 3\n",
            "loss:3510.4697998046877 at iteration 4\n",
            "loss:3238.2664184570312 at iteration 5\n",
            "loss:3291.9712437220983 at iteration 6\n",
            "loss:3623.3768768310547 at iteration 7\n",
            "loss:3752.512464735243 at iteration 8\n",
            "loss:3893.1581909179686 at iteration 9\n",
            "loss:3671.390613902699 at iteration 10\n",
            "loss:3444.553151448568 at iteration 11\n",
            "loss:3292.122596153846 at iteration 12\n",
            "loss:3112.564034598214 at iteration 13\n",
            "loss:3080.134033203125 at iteration 14\n",
            "loss:3040.0989379882812 at iteration 15\n",
            "loss:2977.6365751378676 at iteration 16\n",
            "loss:2897.121086968316 at iteration 17\n",
            "loss:3014.877820466694 at iteration 18\n",
            "loss:2921.1313354492186 at iteration 19\n",
            "loss:2894.5215192522323 at iteration 20\n",
            "loss:2797.474786931818 at iteration 21\n",
            "loss:2790.0435313349185 at iteration 22\n",
            "loss:2868.4483337402344 at iteration 23\n",
            "loss:2958.418720703125 at iteration 24\n",
            "loss:3098.8744084284854 at iteration 25\n",
            "loss:3192.672535083912 at iteration 26\n",
            "loss:3238.924586704799 at iteration 27\n",
            "loss:3145.7825969827586 at iteration 28\n",
            "loss:3258.8624186197917 at iteration 29\n",
            "loss:3175.7446879725303 at iteration 30\n",
            "loss:3118.172836303711 at iteration 31\n",
            "loss:3052.7327159534802 at iteration 32\n",
            "loss:3041.920264748966 at iteration 33\n",
            "loss:3063.5804949079243 at iteration 34\n",
            "loss:3012.032943725586 at iteration 35\n",
            "loss:2987.6046686945733 at iteration 36\n",
            "loss:2912.5723290694386 at iteration 37\n",
            "loss:2903.800530066857 at iteration 38\n",
            "loss:2880.5869010925294 at iteration 39\n",
            "loss:2872.40223582198 at iteration 40\n",
            "loss:2922.3125690278553 at iteration 41\n",
            "loss:2913.1599341104197 at iteration 42\n",
            "loss:2951.080071882768 at iteration 43\n",
            "loss:2928.9441643608943 at iteration 44\n",
            "loss:2911.832563980766 at iteration 45\n",
            "loss:2866.647662872964 at iteration 46\n",
            "loss:2852.0503482818604 at iteration 47\n",
            "loss:2898.3397683902663 at iteration 48\n",
            "loss:2901.777650756836 at iteration 49\n",
            "loss:2854.9146782370176 at iteration 50\n",
            "loss:2820.3469361525317 at iteration 51\n",
            "loss:2808.723635691517 at iteration 52\n",
            "loss:2810.4403601752388 at iteration 53\n",
            "loss:2823.3517117587003 at iteration 54\n",
            "loss:2873.2903687613352 at iteration 55\n",
            "loss:2860.2328528688663 at iteration 56\n",
            "loss:2827.6122041899584 at iteration 57\n",
            "loss:2804.050775560282 at iteration 58\n",
            "loss:2808.216844177246 at iteration 59\n",
            "loss:2812.94463861184 at iteration 60\n",
            "loss:2843.60817644673 at iteration 61\n",
            "loss:2874.611613440135 at iteration 62\n",
            "loss:2861.4468903541565 at iteration 63\n",
            "loss:2842.4037189190203 at iteration 64\n",
            "loss:2837.6737287116775 at iteration 65\n",
            "loss:2834.4131629146746 at iteration 66\n",
            "loss:2802.8272332584156 at iteration 67\n",
            "loss:2775.263309644616 at iteration 68\n",
            "loss:2743.0405452183313 at iteration 69\n",
            "loss:2751.870987583214 at iteration 70\n",
            "loss:2749.4881969028047 at iteration 71\n",
            "loss:2769.438781320232 at iteration 72\n",
            "loss:2751.2629910030882 at iteration 73\n",
            "loss:2728.94262898763 at iteration 74\n",
            "loss:2700.4753197117857 at iteration 75\n",
            "loss:2680.917666348544 at iteration 76\n",
            "loss:2660.7725959190957 at iteration 77\n",
            "loss:2632.279696307605 at iteration 78\n",
            "loss:2602.301608848572 at iteration 79\n",
            "loss:2585.6785939534507 at iteration 80\n",
            "loss:2559.417435622797 at iteration 81\n",
            "loss:2550.75325453425 at iteration 82\n",
            "loss:2537.5072208586193 at iteration 83\n",
            "loss:2511.6876538444967 at iteration 84\n",
            "loss:2502.4972351429074 at iteration 85\n",
            "loss:2485.991685363068 at iteration 86\n",
            "loss:2479.9042582078414 at iteration 87\n",
            "loss:2477.719490822781 at iteration 88\n",
            "loss:2466.333545091417 at iteration 89\n",
            "loss:2452.5308437137815 at iteration 90\n",
            "loss:2437.3825804668923 at iteration 91\n",
            "loss:2427.9597419000443 at iteration 92\n",
            "loss:2415.0509775039995 at iteration 93\n",
            "loss:2415.143121819747 at iteration 94\n",
            "loss:2398.828099091848 at iteration 95\n",
            "loss:2388.796383729915 at iteration 96\n",
            "loss:2373.882211646255 at iteration 97\n",
            "loss:2357.817017988725 at iteration 98\n",
            "loss:2344.543808746338 at iteration 99\n",
            "loss:2328.588875798896 at iteration 100\n",
            "loss:2321.835551093606 at iteration 101\n",
            "loss:2311.6953576837927 at iteration 102\n",
            "loss:2294.2431471898008 at iteration 103\n",
            "loss:2278.842515491304 at iteration 104\n",
            "loss:2262.780175119076 at iteration 105\n",
            "loss:2255.6221508846106 at iteration 106\n",
            "loss:2242.8182577910247 at iteration 107\n",
            "loss:2235.033113672099 at iteration 108\n",
            "loss:2227.1384811401367 at iteration 109\n",
            "loss:2225.2101007409997 at iteration 110\n",
            "loss:2218.762882913862 at iteration 111\n",
            "loss:2208.223111177968 at iteration 112\n",
            "loss:2196.419907017758 at iteration 113\n",
            "loss:2185.1882463538127 at iteration 114\n",
            "loss:2176.827834688384 at iteration 115\n",
            "loss:2167.0881943661943 at iteration 116\n",
            "loss:2155.260751627259 at iteration 117\n",
            "loss:2146.5073653790128 at iteration 118\n",
            "loss:2135.86311861674 at iteration 119\n",
            "loss:2125.136063630916 at iteration 120\n",
            "loss:2115.1667596785746 at iteration 121\n",
            "loss:2109.1220540612694 at iteration 122\n",
            "loss:2105.0843807343513 at iteration 123\n",
            "loss:2097.1935562744143 at iteration 124\n",
            "loss:2091.6526514689126 at iteration 125\n",
            "loss:2083.016971257728 at iteration 126\n",
            "loss:2073.291280388832 at iteration 127\n",
            "loss:2063.036862513816 at iteration 128\n",
            "loss:2055.0315778292143 at iteration 129\n",
            "loss:2044.8384572968228 at iteration 130\n",
            "loss:2031.3418954791446 at iteration 131\n",
            "loss:2021.1690532713008 at iteration 132\n",
            "loss:2009.8196241464188 at iteration 133\n",
            "loss:2002.905879607024 at iteration 134\n",
            "loss:1998.8702333113727 at iteration 135\n",
            "loss:1990.8895917460866 at iteration 136\n",
            "loss:1984.1382750359135 at iteration 137\n",
            "loss:1978.2943996731326 at iteration 138\n",
            "loss:1969.0041725158692 at iteration 139\n",
            "loss:1958.434873648569 at iteration 140\n",
            "loss:1946.101290313291 at iteration 141\n",
            "loss:1935.0506373051996 at iteration 142\n",
            "loss:1923.8341870837742 at iteration 143\n",
            "loss:1912.799286414837 at iteration 144\n",
            "loss:1901.3871603142725 at iteration 145\n",
            "loss:1889.4205488347682 at iteration 146\n",
            "loss:1879.148192122176 at iteration 147\n",
            "loss:1871.6094925643613 at iteration 148\n",
            "loss:1864.6430249023438 at iteration 149\n",
            "loss:1857.6506569969733 at iteration 150\n",
            "loss:1848.559051915219 at iteration 151\n",
            "loss:1841.4857891805812 at iteration 152\n",
            "loss:1836.1590171913049 at iteration 153\n",
            "loss:1830.2891471616683 at iteration 154\n",
            "loss:1825.546633598132 at iteration 155\n",
            "loss:1818.0943751244029 at iteration 156\n",
            "epoch:  3\n",
            "loss:928.8670654296875 at iteration 0\n",
            "loss:735.8595275878906 at iteration 1\n",
            "loss:1581.984639485677 at iteration 2\n",
            "loss:2074.100845336914 at iteration 3\n",
            "loss:1866.1025756835938 at iteration 4\n",
            "loss:1676.0902913411458 at iteration 5\n",
            "loss:1743.3261021205358 at iteration 6\n",
            "loss:2042.6493530273438 at iteration 7\n",
            "loss:2193.7529296875 at iteration 8\n",
            "loss:2314.423291015625 at iteration 9\n",
            "loss:2182.9861117276278 at iteration 10\n",
            "loss:2037.5843861897786 at iteration 11\n",
            "loss:1907.92629300631 at iteration 12\n",
            "loss:1795.9907749720983 at iteration 13\n",
            "loss:1745.450390625 at iteration 14\n",
            "loss:1691.9411354064941 at iteration 15\n",
            "loss:1631.6895823759191 at iteration 16\n",
            "loss:1574.1134880913628 at iteration 17\n",
            "loss:1688.0050402189556 at iteration 18\n",
            "loss:1654.0867645263672 at iteration 19\n",
            "loss:1651.0344790504091 at iteration 20\n",
            "loss:1582.6192793412642 at iteration 21\n",
            "loss:1562.698146654212 at iteration 22\n",
            "loss:1602.3965657552083 at iteration 23\n",
            "loss:1647.36123046875 at iteration 24\n",
            "loss:1753.4259314903845 at iteration 25\n",
            "loss:1809.1216634114583 at iteration 26\n",
            "loss:1850.77001953125 at iteration 27\n",
            "loss:1819.1163287984914 at iteration 28\n",
            "loss:1904.4362630208334 at iteration 29\n",
            "loss:1854.5486361595893 at iteration 30\n",
            "loss:1811.4810457229614 at iteration 31\n",
            "loss:1762.1805734345407 at iteration 32\n",
            "loss:1752.4414439481848 at iteration 33\n",
            "loss:1766.899813406808 at iteration 34\n",
            "loss:1738.0585225423176 at iteration 35\n",
            "loss:1721.4653980152027 at iteration 36\n",
            "loss:1690.6244795949835 at iteration 37\n",
            "loss:1678.0165201822917 at iteration 38\n",
            "loss:1654.1433471679688 at iteration 39\n",
            "loss:1642.0639291158536 at iteration 40\n",
            "loss:1686.3010312034971 at iteration 41\n",
            "loss:1677.9790890715842 at iteration 42\n",
            "loss:1701.6564220081675 at iteration 43\n",
            "loss:1697.8023247612848 at iteration 44\n",
            "loss:1692.360274605129 at iteration 45\n",
            "loss:1662.2188610320395 at iteration 46\n",
            "loss:1648.5843041737874 at iteration 47\n",
            "loss:1684.160967768455 at iteration 48\n",
            "loss:1686.1467254638671 at iteration 49\n",
            "loss:1668.5946792901732 at iteration 50\n",
            "loss:1659.3571102435772 at iteration 51\n",
            "loss:1648.2178638386276 at iteration 52\n",
            "loss:1642.5587096037689 at iteration 53\n",
            "loss:1644.4457258744674 at iteration 54\n",
            "loss:1684.0826595851354 at iteration 55\n",
            "loss:1674.5514178359717 at iteration 56\n",
            "loss:1649.0315543865336 at iteration 57\n",
            "loss:1628.186752836583 at iteration 58\n",
            "loss:1631.1733355204265 at iteration 59\n",
            "loss:1630.356569133821 at iteration 60\n",
            "loss:1651.9911516251102 at iteration 61\n",
            "loss:1677.4356900169737 at iteration 62\n",
            "loss:1671.4899156093597 at iteration 63\n",
            "loss:1659.5747950627253 at iteration 64\n",
            "loss:1653.2598967118697 at iteration 65\n",
            "loss:1648.2550429159137 at iteration 66\n",
            "loss:1633.2479030384736 at iteration 67\n",
            "loss:1613.6999911985536 at iteration 68\n",
            "loss:1595.3575703212193 at iteration 69\n",
            "loss:1607.2210661122497 at iteration 70\n",
            "loss:1609.1725432078044 at iteration 71\n",
            "loss:1619.739682759324 at iteration 72\n",
            "loss:1607.272617030788 at iteration 73\n",
            "loss:1603.0636549886067 at iteration 74\n",
            "loss:1594.1602054395173 at iteration 75\n",
            "loss:1589.5956343613661 at iteration 76\n",
            "loss:1581.0199899917993 at iteration 77\n",
            "loss:1566.226991484437 at iteration 78\n",
            "loss:1553.1983552932738 at iteration 79\n",
            "loss:1548.8232815589433 at iteration 80\n",
            "loss:1535.0004103125596 at iteration 81\n",
            "loss:1533.5143860966327 at iteration 82\n",
            "loss:1528.2368042355492 at iteration 83\n",
            "loss:1514.9518919103286 at iteration 84\n",
            "loss:1512.1680218009062 at iteration 85\n",
            "loss:1509.777584207469 at iteration 86\n",
            "loss:1510.5134629336271 at iteration 87\n",
            "loss:1513.710559459215 at iteration 88\n",
            "loss:1509.2808992173937 at iteration 89\n",
            "loss:1503.5115334647041 at iteration 90\n",
            "loss:1496.5585053485372 at iteration 91\n",
            "loss:1496.6157651511571 at iteration 92\n",
            "loss:1490.103547278871 at iteration 93\n",
            "loss:1493.705677393863 at iteration 94\n",
            "loss:1483.0114550590515 at iteration 95\n",
            "loss:1477.8920144936474 at iteration 96\n",
            "loss:1471.5975362038125 at iteration 97\n",
            "loss:1461.7391442192925 at iteration 98\n",
            "loss:1452.6190782165527 at iteration 99\n",
            "loss:1444.3945915297707 at iteration 100\n",
            "loss:1437.602933247884 at iteration 101\n",
            "loss:1429.9935609391591 at iteration 102\n",
            "loss:1419.8321382082427 at iteration 103\n",
            "loss:1410.941899617513 at iteration 104\n",
            "loss:1402.015310467414 at iteration 105\n",
            "loss:1397.7473690710335 at iteration 106\n",
            "loss:1390.753059528492 at iteration 107\n",
            "loss:1387.0029676244894 at iteration 108\n",
            "loss:1384.5712767167524 at iteration 109\n",
            "loss:1388.2327813500756 at iteration 110\n",
            "loss:1382.2156310762678 at iteration 111\n",
            "loss:1376.8602001899112 at iteration 112\n",
            "loss:1367.3581605877794 at iteration 113\n",
            "loss:1358.9085824717647 at iteration 114\n",
            "loss:1353.9251423539786 at iteration 115\n",
            "loss:1348.9971755590195 at iteration 116\n",
            "loss:1341.6873896970587 at iteration 117\n",
            "loss:1335.9440578172187 at iteration 118\n",
            "loss:1332.1418155670167 at iteration 119\n",
            "loss:1328.9959851729968 at iteration 120\n",
            "loss:1324.5343276477251 at iteration 121\n",
            "loss:1319.8022395188245 at iteration 122\n",
            "loss:1315.4765353049002 at iteration 123\n",
            "loss:1308.9400989990233 at iteration 124\n",
            "loss:1304.264017135378 at iteration 125\n",
            "loss:1297.0351039856437 at iteration 126\n",
            "loss:1289.5789905786514 at iteration 127\n",
            "loss:1282.802912630776 at iteration 128\n",
            "loss:1277.9908892118015 at iteration 129\n",
            "loss:1272.8943927561054 at iteration 130\n",
            "loss:1266.440977269953 at iteration 131\n",
            "loss:1260.2603031244494 at iteration 132\n",
            "loss:1254.7587372509402 at iteration 133\n",
            "loss:1250.309291020146 at iteration 134\n",
            "loss:1246.6757423176484 at iteration 135\n",
            "loss:1241.598154443894 at iteration 136\n",
            "loss:1235.65290533978 at iteration 137\n",
            "loss:1231.6347905440296 at iteration 138\n",
            "loss:1225.5226007734027 at iteration 139\n",
            "loss:1220.5001665480593 at iteration 140\n",
            "loss:1215.2984826531208 at iteration 141\n",
            "loss:1210.06898583899 at iteration 142\n",
            "loss:1204.748314857483 at iteration 143\n",
            "loss:1199.2626507989291 at iteration 144\n",
            "loss:1193.9745386202042 at iteration 145\n",
            "loss:1189.1436972066658 at iteration 146\n",
            "loss:1183.4451237240353 at iteration 147\n",
            "loss:1178.7212662664836 at iteration 148\n",
            "loss:1173.8989075724285 at iteration 149\n",
            "loss:1173.9606340420958 at iteration 150\n",
            "loss:1171.7920444890071 at iteration 151\n",
            "loss:1170.1950676612605 at iteration 152\n",
            "loss:1169.2699863384296 at iteration 153\n",
            "loss:1166.647418508222 at iteration 154\n",
            "loss:1165.18414355547 at iteration 155\n",
            "loss:1162.4423218745335 at iteration 156\n",
            "epoch:  4\n",
            "loss:640.5758056640625 at iteration 0\n",
            "loss:437.62451171875 at iteration 1\n",
            "loss:1271.8653157552083 at iteration 2\n",
            "loss:1654.4379272460938 at iteration 3\n",
            "loss:1448.1075805664063 at iteration 4\n",
            "loss:1279.7230122884114 at iteration 5\n",
            "loss:1315.075674874442 at iteration 6\n",
            "loss:1577.2411422729492 at iteration 7\n",
            "loss:1728.227532280816 at iteration 8\n",
            "loss:1823.374041748047 at iteration 9\n",
            "loss:1743.7036410245028 at iteration 10\n",
            "loss:1639.5362803141277 at iteration 11\n",
            "loss:1519.9618318997896 at iteration 12\n",
            "loss:1443.7208666120257 at iteration 13\n",
            "loss:1381.9189921061197 at iteration 14\n",
            "loss:1319.3312301635742 at iteration 15\n",
            "loss:1257.923948400161 at iteration 16\n",
            "loss:1208.018283420139 at iteration 17\n",
            "loss:1299.0930561266448 at iteration 18\n",
            "loss:1295.7503784179687 at iteration 19\n",
            "loss:1296.8531784784227 at iteration 20\n",
            "loss:1240.8545532226562 at iteration 21\n",
            "loss:1219.4944006878397 at iteration 22\n",
            "loss:1239.7987569173176 at iteration 23\n",
            "loss:1261.87240234375 at iteration 24\n",
            "loss:1346.490994966947 at iteration 25\n",
            "loss:1382.5972855179398 at iteration 26\n",
            "loss:1419.6322980608259 at iteration 27\n",
            "loss:1420.0537530307113 at iteration 28\n",
            "loss:1488.878084309896 at iteration 29\n",
            "loss:1455.4713774650327 at iteration 30\n",
            "loss:1418.770209312439 at iteration 31\n",
            "loss:1377.917700102835 at iteration 32\n",
            "loss:1366.2155146879309 at iteration 33\n",
            "loss:1375.2715641566685 at iteration 34\n",
            "loss:1359.1526586744521 at iteration 35\n",
            "loss:1348.5997607256916 at iteration 36\n",
            "loss:1339.7206673873097 at iteration 37\n",
            "loss:1324.067592131786 at iteration 38\n",
            "loss:1300.4242198944091 at iteration 39\n",
            "loss:1285.9208161889053 at iteration 40\n",
            "loss:1327.8283644176665 at iteration 41\n",
            "loss:1318.795734849087 at iteration 42\n",
            "loss:1337.4067060297186 at iteration 43\n",
            "loss:1340.81970316569 at iteration 44\n",
            "loss:1340.1393973309061 at iteration 45\n",
            "loss:1317.2222351723528 at iteration 46\n",
            "loss:1303.4682970046997 at iteration 47\n",
            "loss:1333.6489404172314 at iteration 48\n",
            "loss:1332.8195407104492 at iteration 49\n",
            "loss:1330.2559308818743 at iteration 50\n",
            "loss:1331.8418998718262 at iteration 51\n",
            "loss:1319.9263821008071 at iteration 52\n",
            "loss:1310.7229713157371 at iteration 53\n",
            "loss:1307.0160164572976 at iteration 54\n",
            "loss:1340.2869619641986 at iteration 55\n",
            "loss:1332.6157256009285 at iteration 56\n",
            "loss:1310.6679099510457 at iteration 57\n",
            "loss:1291.3997160054869 at iteration 58\n",
            "loss:1293.0739439646402 at iteration 59\n",
            "loss:1288.4496238583424 at iteration 60\n",
            "loss:1302.8630497840143 at iteration 61\n",
            "loss:1324.3463588896252 at iteration 62\n",
            "loss:1318.547351717949 at iteration 63\n",
            "loss:1309.4756928663987 at iteration 64\n",
            "loss:1302.4114064303312 at iteration 65\n",
            "loss:1296.7825425560795 at iteration 66\n",
            "loss:1289.429313098683 at iteration 67\n",
            "loss:1273.68769980168 at iteration 68\n",
            "loss:1262.3322622026717 at iteration 69\n",
            "loss:1275.2663272266657 at iteration 70\n",
            "loss:1280.517916255527 at iteration 71\n",
            "loss:1286.018618962536 at iteration 72\n",
            "loss:1276.1313599251412 at iteration 73\n",
            "loss:1281.6904255167644 at iteration 74\n",
            "loss:1282.4653841319837 at iteration 75\n",
            "loss:1282.9576169298841 at iteration 76\n",
            "loss:1281.2030458694849 at iteration 77\n",
            "loss:1273.046353400508 at iteration 78\n",
            "loss:1271.1255103111266 at iteration 79\n",
            "loss:1270.8577073650595 at iteration 80\n",
            "loss:1262.7502209733173 at iteration 81\n",
            "loss:1263.120644351086 at iteration 82\n",
            "loss:1264.5686535608202 at iteration 83\n",
            "loss:1260.3162496230182 at iteration 84\n",
            "loss:1255.9679983272108 at iteration 85\n",
            "loss:1267.762126264901 at iteration 86\n",
            "loss:1262.7160643664274 at iteration 87\n",
            "loss:1263.5184119578157 at iteration 88\n",
            "loss:1265.5957111782498 at iteration 89\n",
            "loss:1264.049218397874 at iteration 90\n",
            "loss:1259.4743140676746 at iteration 91\n",
            "loss:1260.472056973365 at iteration 92\n",
            "loss:1257.0113693399633 at iteration 93\n",
            "loss:1261.4659461573551 at iteration 94\n",
            "loss:1253.6766788959503 at iteration 95\n",
            "loss:1250.7654204221117 at iteration 96\n",
            "loss:1245.673388344901 at iteration 97\n",
            "loss:1239.9986324888287 at iteration 98\n",
            "loss:1232.286331100464 at iteration 99\n",
            "loss:1225.8273091080166 at iteration 100\n",
            "loss:1219.9843509898467 at iteration 101\n",
            "loss:1212.6262037406848 at iteration 102\n",
            "loss:1206.1680699128372 at iteration 103\n",
            "loss:1199.5361312866212 at iteration 104\n",
            "loss:1192.6629082301877 at iteration 105\n",
            "loss:1190.6044017043068 at iteration 106\n",
            "loss:1187.2386075479012 at iteration 107\n",
            "loss:1186.0617179520634 at iteration 108\n",
            "loss:1185.4828243602406 at iteration 109\n",
            "loss:1190.1605639071079 at iteration 110\n",
            "loss:1185.2734649521965 at iteration 111\n",
            "loss:1182.1939569658937 at iteration 112\n",
            "loss:1173.340733912953 at iteration 113\n",
            "loss:1165.62969579282 at iteration 114\n",
            "loss:1161.9649650968354 at iteration 115\n",
            "loss:1158.5876869788538 at iteration 116\n",
            "loss:1153.136191998498 at iteration 117\n",
            "loss:1147.1278381988782 at iteration 118\n",
            "loss:1144.9540500005087 at iteration 119\n",
            "loss:1144.2600706116227 at iteration 120\n",
            "loss:1142.0455715617195 at iteration 121\n",
            "loss:1136.8575710513728 at iteration 122\n",
            "loss:1132.6361564513177 at iteration 123\n",
            "loss:1127.1600173950196 at iteration 124\n",
            "loss:1121.926787906223 at iteration 125\n",
            "loss:1115.406529043603 at iteration 126\n",
            "loss:1108.8540175557137 at iteration 127\n",
            "loss:1103.5614397507306 at iteration 128\n",
            "loss:1099.6290673475999 at iteration 129\n",
            "loss:1095.7431170631 at iteration 130\n",
            "loss:1092.1550372152617 at iteration 131\n",
            "loss:1086.174116837351 at iteration 132\n",
            "loss:1082.4176618092097 at iteration 133\n",
            "loss:1078.491902725785 at iteration 134\n",
            "loss:1074.9156934513765 at iteration 135\n",
            "loss:1072.0243285798679 at iteration 136\n",
            "loss:1066.3766577347465 at iteration 137\n",
            "loss:1062.9371241837098 at iteration 138\n",
            "loss:1057.9494511740547 at iteration 139\n",
            "loss:1054.8821680055441 at iteration 140\n",
            "loss:1051.7374839782715 at iteration 141\n",
            "loss:1047.9590096106897 at iteration 142\n",
            "loss:1044.387112988366 at iteration 143\n",
            "loss:1040.3525532163424 at iteration 144\n",
            "loss:1036.9607554919098 at iteration 145\n",
            "loss:1033.7165048300815 at iteration 146\n",
            "loss:1029.2704488908923 at iteration 147\n",
            "loss:1024.4372178148103 at iteration 148\n",
            "loss:1020.1427867126465 at iteration 149\n",
            "loss:1021.4889330832374 at iteration 150\n",
            "loss:1019.8564584129736 at iteration 151\n",
            "loss:1019.3664932250977 at iteration 152\n",
            "loss:1019.4065486858417 at iteration 153\n",
            "loss:1018.886290174915 at iteration 154\n",
            "loss:1018.8182794130765 at iteration 155\n",
            "loss:1016.9562570851319 at iteration 156\n",
            "epoch:  5\n",
            "loss:668.7784423828125 at iteration 0\n",
            "loss:487.60133361816406 at iteration 1\n",
            "loss:1229.5887145996094 at iteration 2\n",
            "loss:1578.9743118286133 at iteration 3\n",
            "loss:1379.077410888672 at iteration 4\n",
            "loss:1217.9011840820312 at iteration 5\n",
            "loss:1255.0317557198662 at iteration 6\n",
            "loss:1531.4836883544922 at iteration 7\n",
            "loss:1672.1270209418403 at iteration 8\n",
            "loss:1767.7662963867188 at iteration 9\n",
            "loss:1688.821327903054 at iteration 10\n",
            "loss:1585.7858072916667 at iteration 11\n",
            "loss:1473.8453897329478 at iteration 12\n",
            "loss:1407.0556215558734 at iteration 13\n",
            "loss:1348.521635945638 at iteration 14\n",
            "loss:1287.6779584884644 at iteration 15\n",
            "loss:1226.3285809685203 at iteration 16\n",
            "loss:1173.9022589789497 at iteration 17\n",
            "loss:1257.808937474301 at iteration 18\n",
            "loss:1259.1268829345704 at iteration 19\n",
            "loss:1260.70799328032 at iteration 20\n",
            "loss:1207.0210751620207 at iteration 21\n",
            "loss:1181.8322528341541 at iteration 22\n",
            "loss:1196.884449005127 at iteration 23\n",
            "loss:1211.8165417480468 at iteration 24\n",
            "loss:1287.0559915395884 at iteration 25\n",
            "loss:1313.0215917516637 at iteration 26\n",
            "loss:1340.456663949149 at iteration 27\n",
            "loss:1351.6590397275727 at iteration 28\n",
            "loss:1413.6373565673828 at iteration 29\n",
            "loss:1384.7223815917969 at iteration 30\n",
            "loss:1352.1118516921997 at iteration 31\n",
            "loss:1313.5492098259203 at iteration 32\n",
            "loss:1301.9607622483197 at iteration 33\n",
            "loss:1306.6704770769393 at iteration 34\n",
            "loss:1294.1454745398628 at iteration 35\n",
            "loss:1284.0806132136165 at iteration 36\n",
            "loss:1285.3706638938502 at iteration 37\n",
            "loss:1267.551141787798 at iteration 38\n",
            "loss:1242.095265007019 at iteration 39\n",
            "loss:1224.24909470721 at iteration 40\n",
            "loss:1259.077433086577 at iteration 41\n",
            "loss:1248.5373263691747 at iteration 42\n",
            "loss:1260.9081405292857 at iteration 43\n",
            "loss:1261.2639307657878 at iteration 44\n",
            "loss:1259.536903547204 at iteration 45\n",
            "loss:1239.0041203600294 at iteration 46\n",
            "loss:1223.9904834429424 at iteration 47\n",
            "loss:1253.129792972487 at iteration 48\n",
            "loss:1251.0603538513183 at iteration 49\n",
            "loss:1252.4207498887006 at iteration 50\n",
            "loss:1251.014904168936 at iteration 51\n",
            "loss:1239.7973838662201 at iteration 52\n",
            "loss:1229.0624614291721 at iteration 53\n",
            "loss:1225.7926112781872 at iteration 54\n",
            "loss:1253.350117138454 at iteration 55\n",
            "loss:1245.4360178897255 at iteration 56\n",
            "loss:1225.0129960816482 at iteration 57\n",
            "loss:1208.6694054684397 at iteration 58\n",
            "loss:1208.8516487757365 at iteration 59\n",
            "loss:1212.2300453186035 at iteration 60\n",
            "loss:1229.3924292902793 at iteration 61\n",
            "loss:1248.3760161021398 at iteration 62\n",
            "loss:1242.4481018185616 at iteration 63\n",
            "loss:1233.8338358365572 at iteration 64\n",
            "loss:1227.008178537542 at iteration 65\n",
            "loss:1221.6183971006478 at iteration 66\n",
            "loss:1216.8968522127936 at iteration 67\n",
            "loss:1202.2771133754563 at iteration 68\n",
            "loss:1193.4783757346017 at iteration 69\n",
            "loss:1208.384617389088 at iteration 70\n",
            "loss:1215.7809291945564 at iteration 71\n",
            "loss:1219.9420496796909 at iteration 72\n",
            "loss:1210.2639791643298 at iteration 73\n",
            "loss:1219.6944145202638 at iteration 74\n",
            "loss:1226.176849816975 at iteration 75\n",
            "loss:1232.9418046133858 at iteration 76\n",
            "loss:1233.6022233718481 at iteration 77\n",
            "loss:1229.6378379049181 at iteration 78\n",
            "loss:1231.8225819110871 at iteration 79\n",
            "loss:1237.791837386143 at iteration 80\n",
            "loss:1233.3614595459728 at iteration 81\n",
            "loss:1234.713567572904 at iteration 82\n",
            "loss:1236.1812021618798 at iteration 83\n",
            "loss:1236.32936334049 at iteration 84\n",
            "loss:1231.5882586545722 at iteration 85\n",
            "loss:1246.4657295051663 at iteration 86\n",
            "loss:1238.237896008925 at iteration 87\n",
            "loss:1238.1526609699379 at iteration 88\n",
            "loss:1240.615686416626 at iteration 89\n",
            "loss:1243.5336689791836 at iteration 90\n",
            "loss:1243.7063005281532 at iteration 91\n",
            "loss:1244.826621147894 at iteration 92\n",
            "loss:1241.7330222028368 at iteration 93\n",
            "loss:1244.1069519444516 at iteration 94\n",
            "loss:1236.9419451157253 at iteration 95\n",
            "loss:1236.558122811858 at iteration 96\n",
            "loss:1234.9190932682582 at iteration 97\n",
            "loss:1228.7158613493948 at iteration 98\n",
            "loss:1223.2776089859008 at iteration 99\n",
            "loss:1217.07371630527 at iteration 100\n",
            "loss:1212.9616529053333 at iteration 101\n",
            "loss:1206.713167097962 at iteration 102\n",
            "loss:1198.9039054650527 at iteration 103\n",
            "loss:1193.2459932236445 at iteration 104\n",
            "loss:1185.9666837656273 at iteration 105\n",
            "loss:1183.4580554783902 at iteration 106\n",
            "loss:1179.563526612741 at iteration 107\n",
            "loss:1176.789075693953 at iteration 108\n",
            "loss:1174.8035508936102 at iteration 109\n",
            "loss:1179.9547413662747 at iteration 110\n",
            "loss:1174.089972121375 at iteration 111\n",
            "loss:1171.3458141563212 at iteration 112\n",
            "loss:1162.2373009731896 at iteration 113\n",
            "loss:1154.1066109367039 at iteration 114\n",
            "loss:1150.5056568343064 at iteration 115\n",
            "loss:1147.2633051749988 at iteration 116\n",
            "loss:1141.7740070213706 at iteration 117\n",
            "loss:1137.087304411816 at iteration 118\n",
            "loss:1136.7195836702983 at iteration 119\n",
            "loss:1136.6566207822689 at iteration 120\n",
            "loss:1134.3097234319468 at iteration 121\n",
            "loss:1130.2009610121813 at iteration 122\n",
            "loss:1126.4616684759817 at iteration 123\n",
            "loss:1121.1853808898925 at iteration 124\n",
            "loss:1116.399558445764 at iteration 125\n",
            "loss:1109.7791750750205 at iteration 126\n",
            "loss:1102.8924252092838 at iteration 127\n",
            "loss:1098.4420725800271 at iteration 128\n",
            "loss:1096.492959037194 at iteration 129\n",
            "loss:1092.8278879937325 at iteration 130\n",
            "loss:1088.7603816697092 at iteration 131\n",
            "loss:1083.751995029306 at iteration 132\n",
            "loss:1080.2800139526823 at iteration 133\n",
            "loss:1075.56068355419 at iteration 134\n",
            "loss:1071.447588892544 at iteration 135\n",
            "loss:1066.5500503038838 at iteration 136\n",
            "loss:1060.854175871697 at iteration 137\n",
            "loss:1057.8731148534541 at iteration 138\n",
            "loss:1052.9329092025757 at iteration 139\n",
            "loss:1049.184075889858 at iteration 140\n",
            "loss:1046.7209282727308 at iteration 141\n",
            "loss:1043.1174849130057 at iteration 142\n",
            "loss:1039.8747515413497 at iteration 143\n",
            "loss:1036.5541414721258 at iteration 144\n",
            "loss:1033.211841243587 at iteration 145\n",
            "loss:1031.2081015710116 at iteration 146\n",
            "loss:1026.914602460088 at iteration 147\n",
            "loss:1022.7569941834315 at iteration 148\n",
            "loss:1018.9085188039144 at iteration 149\n",
            "loss:1020.4896579009808 at iteration 150\n",
            "loss:1019.8926708070856 at iteration 151\n",
            "loss:1019.5443218206268 at iteration 152\n",
            "loss:1018.9626012281938 at iteration 153\n",
            "loss:1016.9181368181783 at iteration 154\n",
            "loss:1016.7317175498375 at iteration 155\n",
            "loss:1015.3879833099949 at iteration 156\n",
            "epoch:  6\n",
            "loss:534.0531616210938 at iteration 0\n",
            "loss:403.39781188964844 at iteration 1\n",
            "loss:1127.7964579264324 at iteration 2\n",
            "loss:1439.4209518432617 at iteration 3\n",
            "loss:1284.5596252441405 at iteration 4\n",
            "loss:1139.8018900553386 at iteration 5\n",
            "loss:1189.0821620396205 at iteration 6\n",
            "loss:1450.9473495483398 at iteration 7\n",
            "loss:1612.7680324978298 at iteration 8\n",
            "loss:1694.4676940917968 at iteration 9\n",
            "loss:1622.8719094016335 at iteration 10\n",
            "loss:1523.8966013590496 at iteration 11\n",
            "loss:1415.1932637141301 at iteration 12\n",
            "loss:1349.755439213344 at iteration 13\n",
            "loss:1293.0065760294597 at iteration 14\n",
            "loss:1229.8807797431946 at iteration 15\n",
            "loss:1167.3360743803137 at iteration 16\n",
            "loss:1126.7439274258084 at iteration 17\n",
            "loss:1207.27251594945 at iteration 18\n",
            "loss:1222.61526222229 at iteration 19\n",
            "loss:1225.963533310663 at iteration 20\n",
            "loss:1181.8017463684082 at iteration 21\n",
            "loss:1152.6450165458348 at iteration 22\n",
            "loss:1161.672131538391 at iteration 23\n",
            "loss:1173.1866329956056 at iteration 24\n",
            "loss:1237.8543815612793 at iteration 25\n",
            "loss:1262.9335143477829 at iteration 26\n",
            "loss:1290.6449386051722 at iteration 27\n",
            "loss:1306.8990749490672 at iteration 28\n",
            "loss:1388.3352272033692 at iteration 29\n",
            "loss:1356.8171571300875 at iteration 30\n",
            "loss:1322.4237973690033 at iteration 31\n",
            "loss:1286.5364437681255 at iteration 32\n",
            "loss:1273.1551659527947 at iteration 33\n",
            "loss:1278.0666854858398 at iteration 34\n",
            "loss:1264.0930364396836 at iteration 35\n",
            "loss:1251.347049403835 at iteration 36\n",
            "loss:1255.332497245387 at iteration 37\n",
            "loss:1235.929312877166 at iteration 38\n",
            "loss:1210.6174165725708 at iteration 39\n",
            "loss:1192.8035637460105 at iteration 40\n",
            "loss:1231.5146907624744 at iteration 41\n",
            "loss:1221.1264337938885 at iteration 42\n",
            "loss:1230.220417542891 at iteration 43\n",
            "loss:1235.8337539672852 at iteration 44\n",
            "loss:1238.1662413555644 at iteration 45\n",
            "loss:1218.685910001714 at iteration 46\n",
            "loss:1202.5432957013447 at iteration 47\n",
            "loss:1230.0738365017637 at iteration 48\n",
            "loss:1226.7469398498536 at iteration 49\n",
            "loss:1230.9345932006836 at iteration 50\n",
            "loss:1235.435005921584 at iteration 51\n",
            "loss:1224.1959529372882 at iteration 52\n",
            "loss:1213.5295773258915 at iteration 53\n",
            "loss:1207.5560093272816 at iteration 54\n",
            "loss:1232.851408958435 at iteration 55\n",
            "loss:1224.5983074255157 at iteration 56\n",
            "loss:1204.3404669926085 at iteration 57\n",
            "loss:1186.0488728668731 at iteration 58\n",
            "loss:1187.0669019063314 at iteration 59\n",
            "loss:1182.0944036264889 at iteration 60\n",
            "loss:1195.7366365002047 at iteration 61\n",
            "loss:1219.7053854806084 at iteration 62\n",
            "loss:1216.527508020401 at iteration 63\n",
            "loss:1209.15103125939 at iteration 64\n",
            "loss:1202.1754467126095 at iteration 65\n",
            "loss:1196.9468823333284 at iteration 66\n",
            "loss:1194.6720969256232 at iteration 67\n",
            "loss:1182.5945277559586 at iteration 68\n",
            "loss:1174.0253960745674 at iteration 69\n",
            "loss:1185.0538229069239 at iteration 70\n",
            "loss:1189.9851076338027 at iteration 71\n",
            "loss:1192.4115878588532 at iteration 72\n",
            "loss:1183.307002093341 at iteration 73\n",
            "loss:1188.6758107503256 at iteration 74\n",
            "loss:1192.9803757918507 at iteration 75\n",
            "loss:1196.6160304081905 at iteration 76\n",
            "loss:1194.1237380198943 at iteration 77\n",
            "loss:1189.2478191520595 at iteration 78\n",
            "loss:1189.8054788589477 at iteration 79\n",
            "loss:1191.898649427626 at iteration 80\n",
            "loss:1190.2329468145604 at iteration 81\n",
            "loss:1193.7488361036922 at iteration 82\n",
            "loss:1198.315352121989 at iteration 83\n",
            "loss:1197.8287046544692 at iteration 84\n",
            "loss:1193.1601202321608 at iteration 85\n",
            "loss:1209.0636009128614 at iteration 86\n",
            "loss:1202.5805110931396 at iteration 87\n",
            "loss:1205.5571002745896 at iteration 88\n",
            "loss:1207.1179119533963 at iteration 89\n",
            "loss:1209.9928167992896 at iteration 90\n",
            "loss:1214.8110724739406 at iteration 91\n",
            "loss:1219.2450543475406 at iteration 92\n",
            "loss:1216.0968493197827 at iteration 93\n",
            "loss:1215.9305183812191 at iteration 94\n",
            "loss:1207.3013831774394 at iteration 95\n",
            "loss:1206.5266055077623 at iteration 96\n",
            "loss:1202.800691409987 at iteration 97\n",
            "loss:1197.1678761183614 at iteration 98\n",
            "loss:1191.281083831787 at iteration 99\n",
            "loss:1186.1168966765451 at iteration 100\n",
            "loss:1184.6343268600165 at iteration 101\n",
            "loss:1178.933879815259 at iteration 102\n",
            "loss:1172.3565408266509 at iteration 103\n",
            "loss:1166.1763025192988 at iteration 104\n",
            "loss:1159.5830165935013 at iteration 105\n",
            "loss:1156.4169347174814 at iteration 106\n",
            "loss:1152.4671914842393 at iteration 107\n",
            "loss:1149.9770083646163 at iteration 108\n",
            "loss:1146.9257652976296 at iteration 109\n",
            "loss:1152.5721882313221 at iteration 110\n",
            "loss:1146.7628319604057 at iteration 111\n",
            "loss:1143.9617815946056 at iteration 112\n",
            "loss:1136.2639107955129 at iteration 113\n",
            "loss:1128.9287577753482 at iteration 114\n",
            "loss:1126.6385494100637 at iteration 115\n",
            "loss:1124.131606533996 at iteration 116\n",
            "loss:1118.0540340876175 at iteration 117\n",
            "loss:1113.074262218315 at iteration 118\n",
            "loss:1112.6884515126546 at iteration 119\n",
            "loss:1111.9742294185419 at iteration 120\n",
            "loss:1110.8777754736727 at iteration 121\n",
            "loss:1106.1030604664872 at iteration 122\n",
            "loss:1102.7944570972074 at iteration 123\n",
            "loss:1097.0991712646485 at iteration 124\n",
            "loss:1093.5061842903258 at iteration 125\n",
            "loss:1087.4193758025883 at iteration 126\n",
            "loss:1080.6997039318085 at iteration 127\n",
            "loss:1077.1420801443646 at iteration 128\n",
            "loss:1074.6715634859524 at iteration 129\n",
            "loss:1071.3194596385229 at iteration 130\n",
            "loss:1067.17991846258 at iteration 131\n",
            "loss:1061.4238033438087 at iteration 132\n",
            "loss:1058.1698494526877 at iteration 133\n",
            "loss:1053.1920823838975 at iteration 134\n",
            "loss:1048.5925073062672 at iteration 135\n",
            "loss:1043.8548392414177 at iteration 136\n",
            "loss:1038.3388444098873 at iteration 137\n",
            "loss:1035.2743115322196 at iteration 138\n",
            "loss:1029.6132208687918 at iteration 139\n",
            "loss:1025.7742324720882 at iteration 140\n",
            "loss:1022.5825855093942 at iteration 141\n",
            "loss:1018.0661239090499 at iteration 142\n",
            "loss:1014.042285071479 at iteration 143\n",
            "loss:1010.0418574892242 at iteration 144\n",
            "loss:1006.423840039397 at iteration 145\n",
            "loss:1003.7865444884009 at iteration 146\n",
            "loss:999.1176042299013 at iteration 147\n",
            "loss:994.3383090640075 at iteration 148\n",
            "loss:989.8952408854167 at iteration 149\n",
            "loss:992.043210465387 at iteration 150\n",
            "loss:992.6836563913446 at iteration 151\n",
            "loss:993.0075922947304 at iteration 152\n",
            "loss:993.714804909446 at iteration 153\n",
            "loss:992.8644972278225 at iteration 154\n",
            "loss:994.1858450082632 at iteration 155\n",
            "loss:992.8186326725468 at iteration 156\n",
            "epoch:  7\n",
            "loss:634.2387084960938 at iteration 0\n",
            "loss:412.4684143066406 at iteration 1\n",
            "loss:1128.728291829427 at iteration 2\n",
            "loss:1467.3109283447266 at iteration 3\n",
            "loss:1324.6809448242188 at iteration 4\n",
            "loss:1186.883794148763 at iteration 5\n",
            "loss:1253.723863874163 at iteration 6\n",
            "loss:1576.0845527648926 at iteration 7\n",
            "loss:1733.2335781521267 at iteration 8\n",
            "loss:1841.4500640869142 at iteration 9\n",
            "loss:1769.6194763183594 at iteration 10\n",
            "loss:1657.5802841186523 at iteration 11\n",
            "loss:1537.5022624089167 at iteration 12\n",
            "loss:1459.7724516732353 at iteration 13\n",
            "loss:1398.9425206502278 at iteration 14\n",
            "loss:1329.0498328208923 at iteration 15\n",
            "loss:1265.7847474042107 at iteration 16\n",
            "loss:1221.3472989400227 at iteration 17\n",
            "loss:1308.4614727622584 at iteration 18\n",
            "loss:1304.6246662139893 at iteration 19\n",
            "loss:1313.18005552746 at iteration 20\n",
            "loss:1262.4101434187455 at iteration 21\n",
            "loss:1234.883941318678 at iteration 22\n",
            "loss:1242.5402154922485 at iteration 23\n",
            "loss:1256.7889584350587 at iteration 24\n",
            "loss:1326.1403934772197 at iteration 25\n",
            "loss:1355.9734098646377 at iteration 26\n",
            "loss:1402.1472982679095 at iteration 27\n",
            "loss:1409.7532188152445 at iteration 28\n",
            "loss:1471.0718777974446 at iteration 29\n",
            "loss:1438.4428413145004 at iteration 30\n",
            "loss:1402.0319049358368 at iteration 31\n",
            "loss:1363.88314148874 at iteration 32\n",
            "loss:1353.6991915983313 at iteration 33\n",
            "loss:1357.3216428484236 at iteration 34\n",
            "loss:1343.3873356713189 at iteration 35\n",
            "loss:1331.0308011029217 at iteration 36\n",
            "loss:1328.4457042091772 at iteration 37\n",
            "loss:1310.079965249086 at iteration 38\n",
            "loss:1285.0167043685913 at iteration 39\n",
            "loss:1264.3637805101348 at iteration 40\n",
            "loss:1299.829158782959 at iteration 41\n",
            "loss:1291.070013534191 at iteration 42\n",
            "loss:1301.2868865620005 at iteration 43\n",
            "loss:1308.0944056193034 at iteration 44\n",
            "loss:1310.5508547243865 at iteration 45\n",
            "loss:1289.3448660018596 at iteration 46\n",
            "loss:1274.8369679450989 at iteration 47\n",
            "loss:1299.844893942074 at iteration 48\n",
            "loss:1298.9660014343262 at iteration 49\n",
            "loss:1298.8726069132488 at iteration 50\n",
            "loss:1305.488396717952 at iteration 51\n",
            "loss:1294.8158631234799 at iteration 52\n",
            "loss:1285.5068001923737 at iteration 53\n",
            "loss:1280.7061505404386 at iteration 54\n",
            "loss:1305.6259878703527 at iteration 55\n",
            "loss:1297.024409110086 at iteration 56\n",
            "loss:1276.0597213218953 at iteration 57\n",
            "loss:1257.149661565231 at iteration 58\n",
            "loss:1257.814993540446 at iteration 59\n",
            "loss:1251.661443241307 at iteration 60\n",
            "loss:1258.37463009742 at iteration 61\n",
            "loss:1280.1975991385323 at iteration 62\n",
            "loss:1275.0220301151276 at iteration 63\n",
            "loss:1268.1012397179236 at iteration 64\n",
            "loss:1261.2658064871123 at iteration 65\n",
            "loss:1252.895367750481 at iteration 66\n",
            "loss:1249.9256863313562 at iteration 67\n",
            "loss:1234.519341731417 at iteration 68\n",
            "loss:1222.7273840767996 at iteration 69\n",
            "loss:1232.6838707722409 at iteration 70\n",
            "loss:1238.5387117597793 at iteration 71\n",
            "loss:1240.3109835271966 at iteration 72\n",
            "loss:1229.576224868362 at iteration 73\n",
            "loss:1236.0578224690755 at iteration 74\n",
            "loss:1240.079423000938 at iteration 75\n",
            "loss:1243.8425326656986 at iteration 76\n",
            "loss:1239.9068261170999 at iteration 77\n",
            "loss:1235.374703515934 at iteration 78\n",
            "loss:1236.36480884552 at iteration 79\n",
            "loss:1239.3848773344064 at iteration 80\n",
            "loss:1234.2460760721347 at iteration 81\n",
            "loss:1237.2906451857234 at iteration 82\n",
            "loss:1237.7329859052386 at iteration 83\n",
            "loss:1237.296257647346 at iteration 84\n",
            "loss:1234.782473009686 at iteration 85\n",
            "loss:1247.8831150449555 at iteration 86\n",
            "loss:1245.953504562378 at iteration 87\n",
            "loss:1246.3506306851848 at iteration 88\n",
            "loss:1248.8306811862521 at iteration 89\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-193-f1df628508ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLBL0hNWr8r-"
      },
      "source": [
        "# def evaluate(model, data_loader,  device='cuda'):\n",
        "#     model.to(device)\n",
        "#     model.eval()\n",
        "#     x_list = []\n",
        "#     y_list = []\n",
        "#     floor_list = []\n",
        "#     prexs_list = []\n",
        "#     preys_list = []\n",
        "#     prefloors_list = []\n",
        "#     for d in tqdm(data_loader):\n",
        "#         data_dict['BSSID_FEATS'] = d['BSSID_FEATS'].to(device).long()\n",
        "#         data_dict['RSSI_FEATS'] = d['RSSI_FEATS'].to(device).float()\n",
        "#         data_dict['site_id'] = d['site_id'].to(device).long()\n",
        "#         x = d['x'].to(device).float()\n",
        "#         y = d['y'].to(device).float()\n",
        "#         floor = d['floor'].to(device).long()\n",
        "#         x_list.append(x.cpu().detach().numpy())\n",
        "#         y_list.append(y.cpu().detach().numpy())\n",
        "#         floor_list.append(floor.cpu().detach().numpy())\n",
        "#         xy, floor = model(data_dict)\n",
        "#         prexs_list.append(xy[:, 0].cpu().detach().numpy())\n",
        "#         preys_list.append(xy[:, 1].cpu().detach().numpy())\n",
        "#         prefloors_list.append(floor.squeeze().cpu().detach().numpy())\n",
        "#     x = np.concatenate(x_list)\n",
        "#     y = np.concatenate(y_list)\n",
        "#     floor = np.concatenate(floor_list)\n",
        "#     prexs = np.concatenate(prexs_list)\n",
        "#     preys =np.concatenate(preys_list)\n",
        "#     prefloors = np.concatenate(prefloors_list)\n",
        "#     eval_score = comp_metric(x, y, floor, prexs, preys, prefloors)\n",
        "#     return eval_score\n",
        "\n",
        "# def get_result(model, data_loader, device='cuda'):\n",
        "#     model.eval()\n",
        "#     model.to(device)\n",
        "#     prexs_list = []\n",
        "#     preys_list = []\n",
        "#     prefloors_list = []\n",
        "#     data_dict = {}\n",
        "#     for d in tqdm(data_loader):\n",
        "#         data_dict['BSSID_FEATS'] = d['BSSID_FEATS'].to(device).long()\n",
        "#         data_dict['RSSI_FEATS'] = d['RSSI_FEATS'].to(device).float()\n",
        "#         data_dict['site_id'] = d['site_id'].to(device).long()\n",
        "#         xy, floor = model(data_dict)\n",
        "#         prexs_list.append(xy[:, 0].cpu().detach().numpy())\n",
        "#         preys_list.append(xy[:, 1].cpu().detach().numpy())\n",
        "#         prefloors_list.append(floor.squeeze(-1).cpu().detach().numpy())\n",
        "#     prexs = np.concatenate(prexs_list)\n",
        "#     preys =np.concatenate(preys_list)\n",
        "#     prefloors = np.concatenate(prefloors_list)\n",
        "#     return prexs, preys, prefloors"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}