{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights from Visualization\n",
    "\n",
    "- Train generator 1 -> Just not enough data to say anything\n",
    "- Train generator 2 -> acce ts based 250ms cutline data. 553753 rows with only 10 sites, smallest wps count for site_floor is 3 with actual records 42, whereas the highest wps count is 835 with actual records 11724. It converges well with good accuracy. -> rmse_x: 0.61 rmse_y: 0.66 rmse_f: 0.017, comp metric at 0.67 -> But has no sites that are in the submission sites, so bad submission score\n",
    "- Train generator 3 -> wps ts based with no cutline. 166681 rows with all 204 sites. It just doesn’t converge though -> rmse_x: 24.6 rmse_y: 21.8 rmse_f: 0.41 with comp metric at 30.1 -> Too large.\n",
    "- Train generator 3M ->modify version 3 to only the 24 sites -> reduced to 75278 rows -> Still doesn’t converge. rmse_x: 23.8 rmse_y: 21.6 rmse_f: 0.36, comp metric at 29.6. -> Too large. Only wps maybe just isn't enough\n",
    "\n",
    "- Train generator 2.1 -> acce_uncali ts based 100ms cutline data. Should cover all 204 site. Reduced to 100ms cutline because memory just won't hold. -> Need a way to convert 3.5G worth of pickle to datatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "from skimage import io\n",
    "from skimage.color import rgba2rgb, rgb2xyz\n",
    "from tqdm import tqdm\n",
    "from dataclasses import dataclass\n",
    "from math import floor, ceil\n",
    "import random\n",
    "\n",
    "# Train data generation\n",
    "import collections\n",
    "import csv\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Any\n",
    "\n",
    "import time\n",
    "import re\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "import pickle\n",
    "\n",
    "import math\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cp -r ../input/indoorlocationgithub/* ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # kaggle notebook\n",
    "# from io_f import read_data_file\n",
    "# from compute_f import compute_step_positions, compute_steps, \\\n",
    "# compute_headings, compute_stride_length, compute_step_heading, compute_rel_positions, split_ts_seq\n",
    "\n",
    "#gcp\n",
    "import compute_f\n",
    "import io_f\n",
    "import visualize_f\n",
    "import main\n",
    "from io_f import read_data_file\n",
    "from compute_f import compute_step_positions, compute_steps, \\\n",
    "compute_headings, compute_stride_length, compute_step_heading, compute_rel_positions, split_ts_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -la -h ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train2 had better score even if it covered only 10 sites\n",
    "# create similar dataset to train2 but with all the sites\n",
    "# but maybe we just only got 10 sites for a reason (no acce_uncali etc)\n",
    "\n",
    "# train_file_name = \"../input/indoorfulltestgroupedtrain/indoor_train_2_site_group.pkl\"\n",
    "# train_file_name = \"../input/indoor2ndtrain/indoor_train_2.pkl\"\n",
    "# train_file_name = \"../input/indoor3rdtrain/indoor_train_3.pkl\"\n",
    "train_file_name = \"./indoor_train_4.pkl\"\n",
    "# test_file_name = \"../input/indoorfulltestgroupedtrain/indoor_test_2_250ms.pkl\"\n",
    "# dir_path = \"../input/indoorpkl/\"\n",
    "\n",
    "# Load data it back in\n",
    "with open(train_file_name, \"rb\") as file:\n",
    "    df_train = pickle.load(file)\n",
    "\n",
    "# with open(test_file_name, \"rb\") as file:\n",
    "#     df_test = pickle.load(file)\n",
    "\n",
    "# Uncomment below for making train 3M\n",
    "# Get submission file\n",
    "sub_df = pd.read_csv(\"./input/sample_submission.csv\")\n",
    "sub_df[[\"site\", \"file\", \"timestamp\"]] = sub_df[\"site_path_timestamp\"].apply(lambda x: pd.Series(x.split(\"_\")))\n",
    "\n",
    "# Filter train data by the site_id of submission file\n",
    "test_site_ids = sub_df[\"site\"].unique()\n",
    "print(test_site_ids)\n",
    "df_train = df_train[df_train[\"site_id\"].isin(test_site_ids)]\n",
    "print(len(df_train))\n",
    "print(df_train[\"site_id\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # set the index for test data\n",
    "# df_test = df_test.set_index(\"site_path_timestamp\")\n",
    "# display(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train info\n",
    "print(\"df len: \", len(df_train), \"\\n\")\n",
    "print(\"df column len: \", len(df_train.columns), \"\\n\")\n",
    "print(\"site_id nunique: \", df_train[\"site_id\"].nunique(), \"\\n\")\n",
    "print(\"file_id nunique: \", df_train[\"file_id\"].nunique(), \"\\n\")\n",
    "print(\"x nunique: \", df_train[\"x\"].nunique(), \"\\n\")\n",
    "print(\"y nunique: \", df_train[\"y\"].nunique(), \"\\n\")\n",
    "print(\"event ts nunique: \", df_train[\"ts\"].nunique(), \"\\n\")\n",
    "print(\"start ts nunique: \", df_train[\"start_ts\"].nunique(), \"\\n\") # should be same length as file_id\n",
    "print(\"diff_ts_wp_ts nunique: \", df_train[\"diff_ts_wp_ts\"].nunique(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # Test info\n",
    "# print(\"df len: \", len(df_test), \"\\n\")\n",
    "# print(\"df column len: \", len(df_test.columns), \"\\n\")\n",
    "# print(\"site_id nunique: \", df_test[\"site_id\"].nunique(), \"\\n\")\n",
    "# print(\"file_id nunique: \", df_test[\"file_id\"].nunique(), \"\\n\")\n",
    "# print(\"x nunique: \", df_test[\"x\"].nunique(), \"\\n\")\n",
    "# print(\"y nunique: \", df_test[\"y\"].nunique(), \"\\n\")\n",
    "# print(\"event ts nunique: \", df_test[\"ts\"].nunique(), \"\\n\")\n",
    "# print(\"start ts nunique: \", df_test[\"start_ts\"].nunique(), \"\\n\") # should be same length as file_id\n",
    "# print(\"diff_ts_wp_ts nunique: \", df_test[\"diff_ts_wp_ts\"].nunique(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# test_site_id = df_test[\"site_id\"].unique()\n",
    "# train_site_id = df_train[\"site_id\"].unique()\n",
    "# print(test_site_id, \"\\n\")\n",
    "# print(train_site_id, \"\\n\")\n",
    "# a = list(set(test_site_id) & set(train_site_id))\n",
    "# print(len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # print(\"test_df site_id value_counts: \", df_test[\"file_id\"].value_counts(), \"\\n\")\n",
    "# # print(\"sub_df site_id value_counts: \", sub_df[\"file\"].value_counts(), \"\\n\")\n",
    "\n",
    "# # Matching sites: 5d2709d403f801723c32bd39, 5dc8cea7659e181adb076a3f, 5d2709b303f801723c327472\n",
    "# # Missing sites: 5dbc1d84c1eb61796cf7c010, 5da958dd46f8266d0737457b, 5d2709bb03f801723c32852c, 5d27096c03f801723c31e5e0\n",
    "\n",
    "# # Matching files: f4bd7479dbe91f3d18f44c49, 4affd104e0ec7a7806edfa78, 610f2c07b26508790d1cd355\n",
    "# # Missing files: d72ceac4628436a540910d98, 2b4bacedc942ffcb523ff20f, 876cd27fc8f63a2800fc3de8\n",
    "# base_path = \"../input/indoor-location-navigation/test/\"\n",
    "# match_path = \"4affd104e0ec7a7806edfa78\"\n",
    "# missing_path = \"d72ceac4628436a540910d98\"\n",
    "\n",
    "# match_path_full = base_path + match_path + \".txt\"\n",
    "# missing_path_full = base_path + missing_path + \".txt\"\n",
    "\n",
    "# #timestamps in sub_df\n",
    "# sub_df_a = sub_df[sub_df[\"file\"] == match_path]\n",
    "# sub_df_a_ts = sorted(sub_df_a[\"timestamp\"].value_counts().keys())\n",
    "# print(sub_df_a_ts[0])\n",
    "# df_test_match = df_test[(df_test[\"file_id\"] == match_path) & (df_test[\"closest_wp_ts\"] == int(sub_df_a_ts[0]))]\n",
    "# display(df_test_match.head())\n",
    "\n",
    "# sub_df_b = sub_df[sub_df[\"file\"] == missing_path]\n",
    "# sub_df_b_ts = sorted(sub_df_b[\"timestamp\"].value_counts().keys())\n",
    "# # display(sub_df_b.head())\n",
    "\n",
    "# # ts for submission files\n",
    "# print(sub_df_a_ts[:5], \"\\n\")\n",
    "# print(sub_df_b_ts[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric\n",
    "def comp_metric(xhat, yhat, fhat, x, y, f):\n",
    "    intermediate = np.sqrt((xhat - x)**2 + (yhat - y)**2) + 15 * np.abs(fhat-f)\n",
    "    return intermediate.sum() / xhat.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_train.columns))\n",
    "df_train = df_train.dropna(axis=1, how=\"all\")\n",
    "df_train = df_train.dropna(axis=0, how=\"any\")\n",
    "print(len(df_train.columns))\n",
    "\n",
    "null_cols = df_train.columns[df_train.isna().any()].tolist()\n",
    "print(\"Columns with nulls: \", null_cols)\n",
    "\n",
    "def fill_na_mean(df, cols, groupby_col):\n",
    "    for col in cols:\n",
    "        df[col] = df.groupby(groupby_col).transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "# 4 min for 100,000 rows\n",
    "# fill_na_mean(df_train, tqdm(null_cols), \"site_id\")\n",
    "\n",
    "# null_cols = df_train.columns[df_train.isna().any()].tolist()\n",
    "# print(\"Check if nulls are filled: \", null_cols)\n",
    "print(\"Current columns: \", df_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column settings\n",
    "\n",
    "# latter is to drop all the ts related columns\n",
    "# drop_cols = [\"floor_converted\", \"floor\", \"x\", \"y\", \"floor_le\", \"file_id\", \"file_id_le\", \"diff_start_wp_ts\"]\n",
    "# drop_cols = [\"floor_converted\", \"floor\", \"x\", \"y\", \"floor_le\", \"file_id\", \"file_id_le\", \\\n",
    "#              \"ts\", \"start_ts\", \"diff_start_ts\", \"closest_wp_ts\", \"diff_start_wp_ts\", \"diff_ts_wp_ts\", \\\n",
    "#              \"acce_ts\", \"diff_acce_ts\", \"ahrs_ts\", \"diff_ahrs_ts\", \"magn_ts\", \"diff_magn_ts\", \\\n",
    "#              \"gyro_ts\", \"diff_gyro_ts\", \"acce_u_ts\", \"diff_acce_u_ts\", \"magn_u_ts\", \"diff_magn_u_ts\", \\\n",
    "#              \"gyro_u_ts\", \"diff_gyro_u_ts\", \"wifi_ts\", \"diff_wifi_ts\", \"wifi_last_seen_ts\", \\\n",
    "#              \"beacon_ts\", \"diff_beacon_ts\", \"rel_ts\", \"diff_rel_ts\", \"ts_date\", \"ts_day\", \\\n",
    "#              \"ts_hour\", \"ts_minute\", \"wifi_last_seen_ts_date\", \"wifi_last_seen_ts_day\", \\\n",
    "#              \"wifi_last_seen_ts_hour\", \"wifi_last_seen_ts_minute\"\n",
    "#             ]\n",
    "\n",
    "# categorical_features = [\"site_id\", \"within_500ms\", \"within_1000ms\", \"wifi_ssid\", \\\n",
    "#                         \"wifi_bssid\", \"beacon_ssid\"] # train 2\n",
    "# categorical_features = [\"site_id\", \"wifi_ssid\", \"wifi_bssid\", \"beacon_ssid\"] # train 3\n",
    "categorical_features = [\"site_id\", \"within_100ms\", \"within_200ms\", \\\n",
    "                        \"wifi_ssid\", \"wifi_bssid\", \"beacon_ssid\"] # train 4\n",
    "\n",
    "int_features = [\"floor_converted\", \"acce_u_ts\", \"diff_acce_u_ts\", \"acce_u_x\", \"acce_u_y\", \"acce_u_z\",\\\n",
    "                \"gyro_u_ts\", \"diff_gyro_u_ts\", \"gyro_u_x\", \"gyro_u_y\", \"gyro_u_z\",\\\n",
    "                \"wifi_rssi\", \"wifi_ts\", \"diff_wifi_ts\", \"wifi_last_seen_ts\", \n",
    "                \"beacon_rssi\", \"beacon_ts\", \"diff_beacon_ts\", \\\n",
    "                \"ts_date\", \"ts_day\", \"ts_hour\", \"ts_minute\", \\\n",
    "                \"wifi_last_seen_ts_date\", \"wifi_last_seen_ts_day\", \\\n",
    "                \"wifi_last_seen_ts_hour\", \"wifi_last_seen_ts_minute\"]\n",
    "\n",
    "# convert to category from object dtype\n",
    "for col in categorical_features:\n",
    "    df_train[col] = df_train[col].astype(\"category\")\n",
    "\n",
    "# convert to int from datetime64 dtype\n",
    "for col in int_features:\n",
    "    df_train[col] = df_train[col].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_train.dtypes[:50])\n",
    "display(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset prep for training\n",
    "target_x = df_train.iloc[:, 7]\n",
    "target_y = df_train.iloc[:, 8]\n",
    "target_f = df_train.iloc[:, 2]\n",
    "\n",
    "# drop target columns\n",
    "# drop_cols = [\"file_id\", \"floor_converted\", \"floor\", \"x\", \"y\"] # Train 2 test\n",
    "drop_cols = [\"file_id\", \"file_id_le\", \"floor_converted\", \"floor\", \"x\", \"y\", \"floor_le\"] # Train 3\n",
    "# drop_cols = [\"file_id\", \"file_id_le\", \"floor_converted\", \"floor\", \\\n",
    "#              \"floor_converted_le\", \"x\", \"y\"] # Train 2\n",
    "# drop_cols = [\"file_id\", \"file_id_le\", \"floor_converted\", \"floor\", \"floor_converted_le\", \"x\", \"y\"]\n",
    "features = df_train.drop(columns=drop_cols)\n",
    "display(features.head())\n",
    "\n",
    "# set target cols\n",
    "targets = [\"x\", \"y\", \"f\"]\n",
    "target_data = [target_x, target_y, target_f]\n",
    "\n",
    "d = {}\n",
    "for tgt, tgt_data in zip(targets, target_data):\n",
    "    feat_train, feat_val, target_train, target_val = \\\n",
    "    train_test_split(features, tgt_data, test_size = 0.2, random_state = SEED)\n",
    "    feat_train, feat_viz, target_train, target_viz = \\\n",
    "    train_test_split(feat_train, target_train, test_size = 0.2, random_state = SEED)\n",
    "    d[\"feat_train_{}\".format(tgt)] = feat_train\n",
    "    d[\"feat_val_{}\".format(tgt)] = feat_val\n",
    "    d[\"feat_viz_{}\".format(tgt)] = feat_viz\n",
    "    d[\"target_train_{}\".format(tgt)] = target_train\n",
    "    d[\"target_val_{}\".format(tgt)] = target_val\n",
    "    d[\"target_viz_{}\".format(tgt)] = target_viz\n",
    "    d[\"train_{}\".format(tgt)] = lgb.Dataset(data=feat_train, label=target_train, categorical_feature=categorical_features, free_raw_data=False).construct()\n",
    "    d[\"val_{}\".format(tgt)] = lgb.Dataset(data=feat_val, label=target_val, categorical_feature=categorical_features, free_raw_data=False).construct()\n",
    "    print(d[\"feat_train_{}\".format(tgt)].shape)\n",
    "    print(d[\"feat_val_{}\".format(tgt)].shape)\n",
    "    print(d[\"feat_viz_{}\".format(tgt)].shape)\n",
    "    print(d[\"target_train_{}\".format(tgt)].shape)\n",
    "    print(d[\"target_val_{}\".format(tgt)].shape)\n",
    "    print(d[\"target_viz_{}\".format(tgt)].shape)\n",
    "    print(d[\"train_{}\".format(tgt)].get_data().shape)\n",
    "    print(d[\"train_{}\".format(tgt)].get_label().shape)\n",
    "    print(d[\"val_{}\".format(tgt)].get_data().shape)\n",
    "    print(d[\"val_{}\".format(tgt)].get_label().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lgb patams\n",
    "lgb_params = {'objective': 'root_mean_squared_error',\n",
    "              'boosting_type': 'gbdt',\n",
    "              'n_estimators': 50000, # example had 50000\n",
    "              'learning_rate': 0.1,\n",
    "              'num_leaves': 50,\n",
    "              'min_data_in_leaf': 50,\n",
    "              'max_depth': 15,\n",
    "              'colsample_bytree': 0.4,\n",
    "              'subsample': 0.6,\n",
    "              'subsample_freq': 2,\n",
    "              'bagging_seed': SEED,\n",
    "              'reg_alpha': 8,\n",
    "              'reg_lambda': 2,\n",
    "              'random_state': SEED,\n",
    "              'n_jobs': -1\n",
    "              }\n",
    "\n",
    "# train models\n",
    "start = time.time()\n",
    "\n",
    "for tgt in targets:\n",
    "    model = lgb.train(params=lgb_params,\n",
    "                      train_set=d[\"train_{}\".format(tgt)],\n",
    "                      early_stopping_rounds=20,\n",
    "                      valid_sets=d[\"val_{}\".format(tgt)])\n",
    "    d[\"model_{}\".format(tgt)] = model\n",
    "    d[\"pred_target_{}\".format(tgt)] = model.predict(d[\"feat_val_{}\".format(tgt)], \n",
    "                                                    num_iteration=model.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"time to process one train_path\", time.time() - start)\n",
    "print(d.keys())\n",
    "print(len(d[\"target_val_f\"]))\n",
    "print(len(d[\"pred_target_f\"]))\n",
    "# print(np.argwhere(np.isnan(list(d[\"target_val_f\"]))))\n",
    "\n",
    "# the below code should not be there once the model has proper floor_map\n",
    "d[\"target_val_f\"] = [0 if math.isnan(x) else x for x in d[\"target_val_f\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_x = mean_squared_error(d[\"target_val_x\"], d[\"pred_target_x\"])\n",
    "mse_y = mean_squared_error(d[\"target_val_y\"], d[\"pred_target_y\"])\n",
    "mse_f = mean_squared_error(d[\"target_val_f\"], d[\"pred_target_f\"])\n",
    "rmse_x = np.sqrt(mse_x)\n",
    "rmse_y = np.sqrt(mse_y)\n",
    "rmse_f = np.sqrt(mse_f)\n",
    "print(\"rmse_x:\", rmse_x, \"rmse_y:\",rmse_y, \"rmse_f:\",rmse_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_val_x = d[\"target_val_x\"].to_numpy()\n",
    "target_val_y = d[\"target_val_y\"].to_numpy()\n",
    "target_val_f = np.array(d[\"target_val_f\"]).astype(float)\n",
    "#target_val_f = target_val_f\n",
    "print(type(target_val_x[0]))\n",
    "print(type(target_val_y[0]))\n",
    "print(type(target_val_f[0]))\n",
    "\n",
    "comp_metric = comp_metric(d[\"pred_target_x\"], d[\"pred_target_y\"], d[\"pred_target_f\"],\n",
    "                          target_val_x, target_val_y, target_val_f)\n",
    "\n",
    "print(\"comp metric: \", comp_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.plot_importance(d[\"model_x\"], max_num_features=20, grid=False, figsize=(16,8))\n",
    "lgb.plot_importance(d[\"model_y\"], max_num_features=20, grid=False, figsize=(16,8))\n",
    "lgb.plot_importance(d[\"model_f\"], max_num_features=20, grid=False, figsize=(16,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(d[\"model_x\"], open(\"x_model_train_4.pkl\", \"wb\"))\n",
    "# pickle.dump(d[\"model_y\"], open(\"y_model_train_4.pkl\", \"wb\"))\n",
    "# pickle.dump(d[\"model_f\"], open(\"f_model_train_4.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Use the trained model to predict viz data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run prediction against train data\n",
    "print(d[\"feat_viz_x\"].shape)\n",
    "print(d[\"feat_viz_y\"].shape)\n",
    "print(d[\"target_viz_x\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the viz data\n",
    "modelx = d[\"model_x\"]\n",
    "modely = d[\"model_y\"]\n",
    "modelf = d[\"model_f\"]\n",
    "\n",
    "# Make predictions with test data\n",
    "viz_predsx = modelx.predict(d[\"feat_viz_x\"])\n",
    "viz_predsy = modely.predict(d[\"feat_viz_y\"])\n",
    "viz_predsf = modelf.predict(d[\"feat_viz_f\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick check\n",
    "# overlap_check = set(d[\"feat_viz_x\"].index) ^ set(d[\"feat_viz_f\"].index)\n",
    "# print(overlap_check)\n",
    "\n",
    "df_viz = d[\"feat_viz_x\"]\n",
    "df_viz[\"x\"] = d[\"target_viz_x\"]\n",
    "df_viz[\"y\"] = d[\"target_viz_y\"]\n",
    "df_viz[\"f\"] = d[\"target_viz_f\"]\n",
    "df_viz[\"x_pred\"] = viz_predsx\n",
    "df_viz[\"y_pred\"] = viz_predsy\n",
    "df_viz[\"f_pred\"] = viz_predsf\n",
    "df_viz[\"x_diff\"] = abs(df_viz[\"x\"] - df_viz[\"x_pred\"])\n",
    "df_viz[\"y_diff\"] = abs(df_viz[\"y\"] - df_viz[\"y_pred\"])\n",
    "df_viz[\"f_diff\"] = abs(df_viz[\"f\"] - df_viz[\"f_pred\"])\n",
    "\n",
    "# create mix of site_id_le x floor\n",
    "df_viz[\"site_le_f\"] = \"site_\" + df_viz[\"site_id_le\"].astype(str) + \"_floor_\" + df_viz[\"f\"].astype(str)\n",
    "\n",
    "# add difference measurement based on the competition's metric\n",
    "df_viz[\"metric\"] = np.sqrt((df_viz[\"x\"] - df_viz[\"x_pred\"])**2 + (df_viz[\"y\"] - df_viz[\"y_pred\"])**2) + (15 * abs(df_viz[\"f\"] - df_viz[\"f_pred\"]))\n",
    "\n",
    "display(df_viz.head())\n",
    "print(len(viz_predsx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set sites with most/mid/least counts\n",
    "site_le_f_counts = df_viz[\"site_le_f\"].value_counts()\n",
    "site_most_count = site_le_f_counts.idxmax()\n",
    "site_least_count = site_le_f_counts.idxmin()\n",
    "site_mid_count = int(len(site_le_f_counts) / 2)\n",
    "site_count_list = df_viz[\"site_le_f\"].value_counts().index.tolist()\n",
    "\n",
    "print(\"site_floor with most count: \", site_most_count, \"->\", site_le_f_counts[site_most_count])\n",
    "print(\"site_floor with mid count: \", site_count_list[site_mid_count], \"->\", site_le_f_counts[site_count_list[site_mid_count]])\n",
    "print(\"site_floor with least count: \", site_least_count, \"->\", site_le_f_counts[site_least_count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_max = df_viz[\"x\"].max()\n",
    "x_min = df_viz[\"x\"].min()\n",
    "y_max = df_viz[\"y\"].max()\n",
    "y_min = df_viz[\"y\"].min()\n",
    "\n",
    "# Plot predictions against ground truths\n",
    "def plot_gt_pred(site, scale=True):\n",
    "    df_viz_a = df_viz[df_viz[\"site_le_f\"] == site] # most counts\n",
    "    x = df_viz_a[\"x\"]\n",
    "    y = df_viz_a[\"y\"]\n",
    "    x_pred = df_viz_a[\"x_pred\"]\n",
    "    y_pred = df_viz_a[\"y_pred\"]\n",
    "\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    fig.patch.set_facecolor(\"white\")\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    ax1.scatter(x_pred, y_pred, s=10, c=\"g\", marker=\"o\", label=\"predicted\", alpha=0.3)\n",
    "    ax1.scatter(x, y, s=10, c=\"r\", marker=\"s\", label=\"true values\")\n",
    "    ax1.scatter(x, y, s=10, c=\"r\", marker=\"s\", label=\"true values\")\n",
    "    if scale == True:\n",
    "        ax1.set_xlim([x_min, x_max])\n",
    "        ax1.set_ylim([y_min, y_max])\n",
    "    ax1.set_title(site)\n",
    "    plt.legend(loc='upper left');\n",
    "    plt.show()\n",
    "\n",
    "plot_gt_pred(site_most_count, scale=False)\n",
    "plot_gt_pred(site_count_list[site_mid_count], scale=False)\n",
    "plot_gt_pred(site_least_count, scale=False)\n",
    "\n",
    "# plot_gt_pred(site_most_count, scale=True)\n",
    "# plot_gt_pred(site_count_list[site_mid_count], scale=True)\n",
    "# plot_gt_pred(site_least_count, scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take difference of truth - predicted -> which has the largest difference\n",
    "display(df_viz.head())\n",
    "print(len(df_viz))\n",
    "print(df_viz[\"ts\"].nunique())\n",
    "\n",
    "# # train 2\n",
    "# df_viz_grouped = df_viz.groupby(\"site_le_f\").agg({\"site_le_f\": \"count\", \\\n",
    "#                                                   \"closest_wp_ts\": lambda x: x.nunique(), \\\n",
    "#                                                   \"x_diff\": \"mean\", \"y_diff\": \"mean\", \\\n",
    "#                                                   \"f_diff\": \"mean\", \"metric\": \"mean\"\n",
    "#                                                  })\n",
    "# df_viz_grouped = df_viz_grouped.sort_values(by=[\"closest_wp_ts\"], ascending=False)\n",
    "\n",
    "# train 3\n",
    "df_viz_grouped = df_viz.groupby(\"site_le_f\").agg({\"site_le_f\": \"count\", \\\n",
    "                                                  \"ts\": lambda x: x.nunique(), \\\n",
    "                                                  \"x_diff\": \"mean\", \"y_diff\": \"mean\", \\\n",
    "                                                  \"f_diff\": \"mean\", \"metric\": \"mean\"\n",
    "                                                 })\n",
    "df_viz_grouped = df_viz_grouped.sort_values(by=[\"ts\"], ascending=False)\n",
    "print(len(df_viz_grouped))\n",
    "display(df_viz_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supposed_comp_metric = df_viz_grouped[\"metric\"].mean()\n",
    "print(\"supposed_comp_metric: \", supposed_comp_metric)\n",
    "\n",
    "# Visualize count and comp metric\n",
    "a = df_viz_grouped[\"site_le_f\"]\n",
    "b = df_viz_grouped[\"metric\"]\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "fig.patch.set_facecolor(\"white\")\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.scatter(a, b, s=10, c=\"r\", marker=\"s\", label=\"Count x Metric mean\")\n",
    "plt.legend(loc='upper left');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try seeing other sites with high metric mean\n",
    "metric_higest = df_viz_grouped[\"metric\"].idxmax()\n",
    "metric_lowest = df_viz_grouped[\"metric\"].idxmin()\n",
    "\n",
    "plot_gt_pred(metric_higest, scale=False)\n",
    "plot_gt_pred(metric_lowest, scale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ground truth and predictions on actual map\n",
    "# Low metric mean -> waypoints are scattered, and intervals seem sparce\n",
    "# Set scales right for all graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Making Quick Prediction\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize differences between test 2 and test 3\n",
    "# !ls -la -h ../input/indoorfulltestgroupedtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_2 = \"../input/indoorfulltestgroupedtrain/indoor_test_2_250ms.pkl\"\n",
    "test_3 = \"./indoor_test_3.pkl\"\n",
    "\n",
    "# with open(test_2, \"rb\") as file:\n",
    "#     df_test_2 = pickle.load(file)\n",
    "\n",
    "with open(test_3, \"rb\") as file:\n",
    "    df_test_3 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Visualization: Diff timestamp distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # Check if either is missing some data that should be there\n",
    "# test2_ts_id = df_test_2[\"site_path_timestamp\"].unique()\n",
    "# test3_ts_id = df_test_3[\"site_path_timestamp\"].unique()\n",
    "# print(\"len of test2_ts_id\", len(test2_ts_id))\n",
    "# print(\"len of test3_ts_id\", len(test3_ts_id), \"\\n\")\n",
    "# no_overlap_ts = set(test2_ts_id) ^ set(test3_ts_id)\n",
    "# print(\"not overlapping ts\", no_overlap_ts)\n",
    "\n",
    "# # Check columns are the same\n",
    "# print(len(df_test_2))\n",
    "# print(len(df_test_3))\n",
    "# no_overlap_col = set(df_test_2.columns) ^ set(df_test_3.columns)\n",
    "# print(\"not overlapping columns\", no_overlap_col)\n",
    "\n",
    "# # Check the diff timestamps -> check if we're not picking up something that are just too far away from ts\n",
    "# def print_minmax(df, cols):\n",
    "#     for col in cols:\n",
    "#         print(\"col: \", col)\n",
    "#         print(\"max: \", df[col].max())\n",
    "#         print(\"min: \", df[col].min())\n",
    "\n",
    "# check_diff_cols = [\"diff_acce_ts\", \"diff_ahrs_ts\", \"diff_magn_ts\", \\\n",
    "#                    \"diff_gyro_ts\", \"diff_acce_u_ts\", \"diff_magn_u_ts\", \\\n",
    "#                    \"diff_gyro_u_ts\", \"diff_wifi_ts\", \"diff_beacon_ts\", \\\n",
    "#                    \"diff_rel_ts\"]\n",
    "\n",
    "# print(\"~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "# print(\"test 2 range: \")\n",
    "# print_minmax(df_test_2, check_diff_cols)\n",
    "# print(\"~~~~~~~~~~~~~~~~~~~~~~~~\", \"\\n\")\n",
    "\n",
    "# print(\"~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "# print(\"test 3 range: \")\n",
    "# print_minmax(df_test_3, check_diff_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def bin_plot(df, col, title, x_label, y_label):\n",
    "#     min_v = pd.to_numeric(df[col]).min()\n",
    "#     max_v = pd.to_numeric(df[col]).max()\n",
    "#     diff = max_v - min_v\n",
    "#     fig = plt.figure(figsize=(16.0, 4.0))\n",
    "#     fig.patch.set_facecolor(\"white\")\n",
    "#     ax = fig.add_subplot(1,1,1)\n",
    "#     ax.hist(df[col], bins=30)\n",
    "#     ax.set_title(title)\n",
    "#     # ax.set_xlabel(x_label)\n",
    "#     ax.text(0.01, 0.99, \"min is {}, max is {}, diff is {}\".format(min_v, max_v, diff), verticalalignment='top', transform=ax.transAxes)\n",
    "#     ax.set_ylabel(y_label)\n",
    "#     plt.xticks(rotation=90)\n",
    "#     fig.show()\n",
    "\n",
    "\n",
    "# check_diff_cols = [\"diff_acce_ts\", \"diff_ahrs_ts\", \"diff_magn_ts\", \\\n",
    "#                    \"diff_gyro_ts\", \"diff_acce_u_ts\", \"diff_magn_u_ts\", \\\n",
    "#                    \"diff_gyro_u_ts\", \"diff_wifi_ts\", \"diff_beacon_ts\", \\\n",
    "#                    \"diff_rel_ts\"]\n",
    "\n",
    "# df_test_2.name = \"df_test_2\"\n",
    "# df_test_3.name = \"df_test_3\"\n",
    "\n",
    "# for df in [df_test_2, df_test_3]:\n",
    "#     for col in check_diff_cols:\n",
    "#         df_title = \"df_test_2\" if df.name == \"df_test_2\" else \"df_test_3\"\n",
    "#         bin_plot(df, col, f\"{df_title} --- {col}\", f\"{col}\", \"freq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # Prune the outliers -> For acce etc @ ±200ms, for wifi&rel @ ±2500ms, for beacon @\n",
    "# # print(len(df_test_3))\n",
    "# a = df_test_3[abs(df_test_3[\"diff_acce_ts\"]) > 200]\n",
    "# b = df_test_3[abs(df_test_3[\"diff_wifi_ts\"]) > 2500]\n",
    "# c = df_test_3[abs(df_test_3[\"diff_beacon_ts\"]) > 10000]\n",
    "# d = df_test_3[abs(df_test_3[\"diff_rel_ts\"]) > 2500]\n",
    "# print(df_test_3[\"diff_acce_ts\"].mean())\n",
    "# print(df_test_3[\"diff_wifi_ts\"].mean())\n",
    "# print(df_test_3[\"diff_beacon_ts\"].mean())\n",
    "# print(df_test_3[\"diff_rel_ts\"].mean())\n",
    "# print(\"\\n\")\n",
    "# print(df_test_3[\"diff_acce_ts\"].std())\n",
    "# print(df_test_3[\"diff_wifi_ts\"].std())\n",
    "# print(df_test_3[\"diff_beacon_ts\"].std())\n",
    "# print(df_test_3[\"diff_rel_ts\"].std())\n",
    "# print(\"\\n\")\n",
    "# print(len(a))\n",
    "# print(len(b))\n",
    "# print(len(c))\n",
    "# print(len(d))\n",
    "# df_test_3.info()\n",
    "# # df_test_3[\"diff_beacon_ts\"]\n",
    "# # df_test_3[\"diff_rel_ts\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ↑Til here, so don't delete these cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_test_3.head())\n",
    "display(features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test_3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train 4 & Test 3 Specific stuff\n",
    "\n",
    "# Drop any column that is not in the features\n",
    "\n",
    "# Fill \"within\" columns with True\n",
    "df_test_3[\"within_250ms\"] = df_test_3[\"within_250ms\"].fillna(True)\n",
    "df_test_3[\"within_500ms\"] = df_test_3[\"within_500ms\"].fillna(True)\n",
    "df_test_3 = df_test_3.rename({\"within_250ms\": \"within_100ms\", \"within_500ms\": \"within_200ms\"}, axis=1)\n",
    "\n",
    "# Drop the columns with all null values\n",
    "df_test_3 = df_test_3.dropna(axis=1, how='all')\n",
    "\n",
    "# get the column names that are still in the df_test but not features\n",
    "no_test_col_overlap = set(features.columns) ^ set(df_test_3.columns)\n",
    "# a = list(set(features.columns) & set(test_features.columns))\n",
    "print(no_test_col_overlap)\n",
    "\n",
    "categorical_features = [\"site_id\", \"within_100ms\", \"within_200ms\", \\\n",
    "                        \"wifi_ssid\", \"wifi_bssid\", \"beacon_ssid\"]\n",
    "int_features = [\"ts_date\", \"ts_day\", \"ts_hour\", \"ts_minute\", \\\n",
    "                \"wifi_last_seen_ts_date\", \"wifi_last_seen_ts_day\", \\\n",
    "                \"wifi_last_seen_ts_hour\", \"wifi_last_seen_ts_minute\"]\n",
    "\n",
    "# convert to category from object dtype\n",
    "for col in categorical_features:\n",
    "    df_test_3[col] = df_test_3[col].astype(\"category\")\n",
    "\n",
    "# convert to int from datetime64 dtype\n",
    "for col in int_features:\n",
    "    df_test_3[col] = df_test_3[col].astype(int)\n",
    "\n",
    "# drop cols\n",
    "drop_cols = ['floor_le', 'file_id', 'file_id_le']\n",
    "df_test_3 = df_test_3.drop(columns=drop_cols)\n",
    "test_features = df_test_3.set_index(\"site_path_timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_test_col_overlap = set(features.columns) ^ set(df_test_3.columns)\n",
    "# a = list(set(features.columns) & set(test_features.columns))\n",
    "print(no_test_col_overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train 3/3M & Test 3 Specific stuff\n",
    "\n",
    "# # Drop any column that is not in the features\n",
    "\n",
    "# # Drop the columns with all null values\n",
    "# df_test_3 = df_test_3.dropna(axis=1, how='all')\n",
    "\n",
    "# # get the column names that are still in the df_test but not features\n",
    "# no_test_col_overlap = set(features.columns) ^ set(df_test_3.columns)\n",
    "# # a = list(set(features.columns) & set(test_features.columns))\n",
    "# print(no_test_col_overlap)\n",
    "\n",
    "# categorical_features = [\"site_id\", \"wifi_ssid\", \"wifi_bssid\", \"beacon_ssid\"]\n",
    "# int_features = [\"ts_date\", \"ts_day\", \"ts_hour\", \"ts_minute\", \\\n",
    "#                 \"wifi_last_seen_ts_date\", \"wifi_last_seen_ts_day\", \\\n",
    "#                 \"wifi_last_seen_ts_hour\", \"wifi_last_seen_ts_minute\"]\n",
    "\n",
    "# # convert to category from object dtype\n",
    "# for col in categorical_features:\n",
    "#     df_test_3[col] = df_test_3[col].astype(\"category\")\n",
    "\n",
    "# # convert to int from datetime64 dtype\n",
    "# for col in int_features:\n",
    "#     df_test_3[col] = df_test_3[col].astype(int)\n",
    "\n",
    "# # drop cols\n",
    "# drop_cols = ['file_id_le', 'diff_ts_wp_ts', 'diff_start_wp_ts', 'floor_le', 'closest_wp_ts', 'file_id']\n",
    "# df_test_3 = df_test_3.drop(columns=drop_cols)\n",
    "# test_features = df_test_3.set_index(\"site_path_timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train 2 & Test 3 Specific stuff\n",
    "\n",
    "# # Drop any column that is not in the features\n",
    "\n",
    "# # Fill \"within\" columns with True\n",
    "# df_test_3[\"within_250ms\"] = df_test_3[\"within_250ms\"].fillna(True)\n",
    "# df_test_3[\"within_500ms\"] = df_test_3[\"within_500ms\"].fillna(True)\n",
    "# df_test_3 = df_test_3.rename({\"within_250ms\": \"within_500ms\", \"within_500ms\": \"within_1000ms\"}, axis=1)\n",
    "\n",
    "# # Drop the columns with all null values\n",
    "# df_test_3 = df_test_3.dropna(axis=1, how='all')\n",
    "\n",
    "# # get the column names that are still in the df_test but not features\n",
    "# no_test_col_overlap = set(features.columns) ^ set(df_test_3.columns)\n",
    "# # a = list(set(features.columns) & set(test_features.columns))\n",
    "# print(no_test_col_overlap)\n",
    "\n",
    "# categorical_features = [\"site_id\", \"within_500ms\", \"within_1000ms\", \"wifi_ssid\", \"wifi_bssid\", \"beacon_ssid\"]\n",
    "# int_features = [\"ts_date\", \"ts_day\", \"ts_hour\", \"ts_minute\", \\\n",
    "#                 \"wifi_last_seen_ts_date\", \"wifi_last_seen_ts_day\", \\\n",
    "#                 \"wifi_last_seen_ts_hour\", \"wifi_last_seen_ts_minute\"]\n",
    "\n",
    "# # convert to category from object dtype\n",
    "# for col in categorical_features:\n",
    "#     df_test_3[col] = df_test_3[col].astype(\"category\")\n",
    "\n",
    "# # convert to int from datetime64 dtype\n",
    "# for col in int_features:\n",
    "#     df_test_3[col] = df_test_3[col].astype(int)\n",
    "\n",
    "# # drop cols\n",
    "# drop_cols = ['file_id_le', 'floor_le', 'file_id']\n",
    "# df_test_3 = df_test_3.drop(columns=drop_cols)\n",
    "# test_features = df_test_3.set_index(\"site_path_timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(len(df_test_3.columns))\n",
    "# # # df_test = df_test.dropna(axis=1, how='all')\n",
    "# # df_test_3 = df_test_3.dropna(axis=1, how='all')\n",
    "# # df_test_3 = df_test_3.dropna(axis=0, how='any')\n",
    "# # print(len(df_test.columns))\n",
    "\n",
    "# null_cols = df_test_3.columns[df_test_3.isna().any()].tolist()\n",
    "# print(\"Columns with nulls: \", null_cols)\n",
    "\n",
    "# # def fill_na_mean(df, cols, groupby_col):\n",
    "# #     for col in cols:\n",
    "# #         df[col] = df.groupby(groupby_col).transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "# # 4 min for 100,000 rows\n",
    "# # fill_na_mean(df_test, tqdm(null_cols), \"site_id\")\n",
    "\n",
    "# # null_cols = df_test.columns[df_test.isna().any()].tolist()\n",
    "# # print(\"Check if nulls are filled: \", null_cols)\n",
    "\n",
    "\n",
    "# # column settings\n",
    "# # rename within_250ms and within_500ms first\n",
    "# # df_test = df_test.rename({\"within_250ms\": \"within_100ms\", \"within_500ms\": \"within_200ms\"}, axis=1)\n",
    "\n",
    "# # latter is to drop all the ts related columns\n",
    "# # drop_cols = [\"floor_converted\", \"floor\", \"x\", \"y\", \"floor_le\", \"file_id\", \"file_id_le\", \"diff_start_wp_ts\"]\n",
    "# # drop_cols = [\"floor_converted\", \"floor\", \"x\", \"y\", \"floor_le\", \"file_id\", \"file_id_le\", \\\n",
    "# #              \"ts\", \"start_ts\", \"diff_start_ts\", \"closest_wp_ts\", \"diff_start_wp_ts\", \"diff_ts_wp_ts\", \\\n",
    "# #              \"acce_ts\", \"diff_acce_ts\", \"ahrs_ts\", \"diff_ahrs_ts\", \"magn_ts\", \"diff_magn_ts\", \\\n",
    "# #              \"gyro_ts\", \"diff_gyro_ts\", \"acce_u_ts\", \"diff_acce_u_ts\", \"magn_u_ts\", \"diff_magn_u_ts\", \\\n",
    "# #              \"gyro_u_ts\", \"diff_gyro_u_ts\", \"wifi_ts\", \"diff_wifi_ts\", \"wifi_last_seen_ts\", \\\n",
    "# #              \"beacon_ts\", \"diff_beacon_ts\", \"rel_ts\", \"diff_rel_ts\", \"ts_date\", \"ts_day\", \\\n",
    "# #              \"ts_hour\", \"ts_minute\", \"wifi_last_seen_ts_date\", \"wifi_last_seen_ts_day\", \\\n",
    "# #              \"wifi_last_seen_ts_hour\", \"wifi_last_seen_ts_minute\"\n",
    "# #             ]\n",
    "\n",
    "# # categorical_features = [\"site_id\", \"within_100ms\", \"within_200ms\", \"wifi_ssid\", \"wifi_bssid\", \"beacon_ssid\"]\n",
    "# categorical_features = [\"site_id\", \"within_250ms\", \"within_500ms\", \"wifi_ssid\", \"wifi_bssid\", \"beacon_ssid\"]\n",
    "# int_features = [\"acce_u_ts\", \"diff_acce_u_ts\", \"acce_u_x\", \"acce_u_y\", \"acce_u_z\",\\\n",
    "#                 \"gyro_u_ts\", \"diff_gyro_u_ts\", \"gyro_u_x\", \"gyro_u_y\", \"gyro_u_z\",\\\n",
    "#                 \"wifi_rssi\", \"wifi_ts\", \"diff_wifi_ts\", \"wifi_last_seen_ts\", \n",
    "#                 \"beacon_rssi\", \"beacon_ts\", \"diff_beacon_ts\", \\\n",
    "#                 \"ts_date\", \"ts_day\", \"ts_hour\", \"ts_minute\", \\\n",
    "#                 \"wifi_last_seen_ts_date\", \"wifi_last_seen_ts_day\", \\\n",
    "#                 \"wifi_last_seen_ts_hour\", \"wifi_last_seen_ts_minute\"]\n",
    "\n",
    "# # convert to category from object dtype\n",
    "# for col in categorical_features:\n",
    "#     df_test[col] = df_test[col].astype(\"category\")\n",
    "\n",
    "# # convert to int from datetime64 dtype\n",
    "# for col in int_features:\n",
    "#     df_test[col] = df_test[col].astype(int)\n",
    "\n",
    "# # drop cols\n",
    "# drop_cols = [\"file_id\", \"floor_le\"]\n",
    "# df_test = df_test.drop(columns=drop_cols)\n",
    "# test_features = df_test.set_index(\"site_path_timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_test_3))\n",
    "print(\"site_id nunique: \", df_test_3[\"site_id\"].nunique(), \"\\n\")\n",
    "display(test_features.head())\n",
    "print(len(features.columns))\n",
    "print(len(test_features.columns))\n",
    "no_overlap = set(features.columns) ^ set(test_features.columns)\n",
    "print(no_overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_features.info()\n",
    "# features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "modelx = d[\"model_x\"]\n",
    "modely = d[\"model_y\"]\n",
    "modelf = d[\"model_f\"]\n",
    "\n",
    "# Make predictions with test data\n",
    "test_predsx = modelx.predict(test_features)\n",
    "test_predsy = modely.predict(test_features)\n",
    "test_predsf = modelf.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds = pd.DataFrame(np.stack((test_features.index, test_predsf, test_predsx, test_predsy))).T\n",
    "df_preds.columns = [\"site_path_timestamp\", \"floor\", \"x\", \"y\"]\n",
    "# test_preds = test_preds.set_index(\"site_path_timestamp\")\n",
    "print(\"df_preds before groupby: \")\n",
    "display(df_preds.head())\n",
    "\n",
    "# groupby to take the average\n",
    "# convert to float from object\n",
    "for col in [\"floor\", \"x\", \"y\"]:\n",
    "    df_preds[col] = df_preds[col].astype(float)\n",
    "\n",
    "df_pred_grouped = df_preds.groupby([\"site_path_timestamp\"]).mean()\n",
    "df_pred_grouped = df_pred_grouped.reset_index()\n",
    "\n",
    "# round floor value to integer\n",
    "df_pred_grouped[\"floor\"] = df_pred_grouped[\"floor\"].round(decimals=0)\n",
    "\n",
    "print(\"len of df_pred_grouped: \", len(df_pred_grouped)) # should be same as sub_df length, but not yet\n",
    "print(\"df_pred_grouped after groupby: \")\n",
    "display(df_pred_grouped.head())\n",
    "\n",
    "# find the missing site_path_timestamp and fill it with average\n",
    "# get submission file\n",
    "sub_df = pd.read_csv(\"./input/sample_submission.csv\")\n",
    "print(\"sub_df: \")\n",
    "display(sub_df.head())\n",
    "\n",
    "subdf_site_id = sub_df[\"site_path_timestamp\"].unique()\n",
    "pred_site_id = df_pred_grouped[\"site_path_timestamp\"].unique()\n",
    "print(\"len of subdf_site_id\", len(subdf_site_id), \"\\n\")\n",
    "print(\"len of pred_site_id\", len(pred_site_id), \"\\n\")\n",
    "no_overlap = set(subdf_site_id) ^ set(pred_site_id)\n",
    "print(\"no overlap\", no_overlap)\n",
    "\n",
    "# missing timestamps -> fill in with average value for now\n",
    "# '5dbc1d84c1eb61796cf7c010_67bf4b03fc22542bb6d51daf_0000000000011'\n",
    "# '5d2709e003f801723c32d896_e3455e53350336857caf08f0_0000000119903'\n",
    "floor_avg = round(df_pred_grouped[\"floor\"].mean())\n",
    "x_avg = df_pred_grouped[\"x\"].mean()\n",
    "y_avg = df_pred_grouped[\"y\"].mean()\n",
    "print(\"avg values for floor, x, y\", floor_avg, x_avg, y_avg)\n",
    "\n",
    "for i, ts in enumerate(list(no_overlap)):\n",
    "    row = [ts, floor_avg, x_avg, y_avg]\n",
    "    row_num = len(df_pred_grouped)\n",
    "    df_pred_grouped.loc[row_num + i] = row\n",
    "\n",
    "print(\"len of pred_grouped\", len(df_pred_grouped))\n",
    "print(\"tail of df_pred_grouped to check missing two rows are appended: \")\n",
    "display(df_pred_grouped.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv for submission\n",
    "df_pred_grouped.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
